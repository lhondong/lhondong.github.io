# 基础知识

## 损失函数

1. 说一下你了解的损失函数？⭐⭐⭐⭐⭐
2. 说说你平时都用过什么损失函数，各自什么特点？⭐⭐⭐⭐⭐
3. 交叉熵函数与最大似然函数的联系和区别？⭐⭐⭐⭐⭐
4. 在用 sigmoid 作为激活函数的时候，为什么要用交叉熵损失函数，而不用均方误差损失函数？⭐⭐⭐⭐⭐
5. 关于交叉熵损失函数（Cross-entropy）和 平方损失（MSE）的区别？⭐⭐⭐⭐⭐
6. 推导交叉熵损失函数？⭐⭐⭐⭐⭐
7. 为什么交叉熵损失函数有 log 项？⭐⭐⭐⭐⭐
8. 说说 adaboost 损失函数⭐⭐⭐⭐
9. 说说 SVM 损失函数⭐⭐⭐⭐
10. 简单的深度神经网络（DNN）的损失函数是什么？⭐⭐⭐⭐
11. 说说 KL 散度⭐⭐⭐⭐
12. 说说 Yolo 的损失函数⭐⭐⭐⭐⭐
13. 交叉熵的设计思想是什么⭐⭐⭐⭐⭐
14. 说说 iou 计算⭐⭐⭐⭐⭐
15. 手写 miou 计算⭐⭐⭐⭐⭐

## 激活函数

1. 说一下你了解的激活函数？分别应用于什么场景？⭐⭐⭐⭐⭐
2. 说说你平时都用过什么激活函数，各自什么特点？⭐⭐⭐⭐⭐
3. 写一下 leaky ReLU 的公式，跟 ReLU 比有什么优势？⭐⭐⭐⭐⭐
4. 了解 ReLU6 吗？⭐⭐⭐⭐⭐
5. sigmoid 有什么缺点，有哪些解决办法？⭐⭐⭐⭐⭐
6. relu 在零点可导吗，不可导如何进行反向传播？⭐⭐⭐⭐⭐
7. 推导 sigmoid 求导公式⭐⭐⭐⭐⭐
8. Softmax 公式，溢出怎么处理⭐⭐⭐⭐⭐
9. Softmax 公式求导⭐⭐⭐⭐⭐

## 优化函数

1. 说一下你了解的优化函数？⭐⭐⭐⭐⭐
2. SGD 和 Adam 谁收敛的比较快？谁能达到全局最优解？⭐⭐⭐⭐⭐
3. 说说常见的优化器以及优化思路，写出他们的优化公式⭐⭐⭐⭐⭐
4. 深度学习中的优化算法总结 Optimizer⭐⭐⭐⭐⭐
5. adam 用到二阶矩的原理是什么⭐⭐⭐⭐⭐
6. Batch 的大小如何选择，过大的 batch 和过小的 batch 分别有什么影响⭐⭐⭐⭐⭐
7. 梯度下降的思想⭐⭐⭐⭐⭐

## 正则化

1. 解决模型训练过拟合有哪些思路？⭐⭐⭐⭐⭐
2. 如何判断过拟合？⭐⭐⭐⭐⭐
3. 正则化 L1（lasso）和 L2（ridge）的区别？⭐⭐⭐⭐⭐
4. L1 有什么缺点？⭐⭐⭐⭐⭐
5. L1 正则为什么可以达到模型的稀疏性⭐⭐⭐⭐⭐
6. 说说 BN（Batch Normolization）的原理⭐⭐⭐⭐⭐
7. 知道 BN 吗？公式写一下，有什么作用与优势？BN 的计算过程。⭐⭐⭐⭐⭐
8. BN 训练和测试有什么不同？⭐⭐⭐⭐⭐
9. 介绍一下 BN 和 LN？有什么差异？LN 是在哪个维度上进行归一化？⭐⭐⭐⭐⭐
10. 要同时使用 BN 和 dropout 该如何使用？⭐⭐⭐⭐⭐
11. BN 的 gama labada 意义⭐⭐⭐⭐⭐
12. 数据增强的方法⭐⭐⭐⭐⭐
13. 两个正则化的参数分布⭐⭐⭐⭐⭐
14. 在预测的时候，是使用 dropout 训练出的权重还是要乘以 keep-prib 呢，为什么？⭐⭐⭐⭐⭐
15. 为什么 Lasso 可以筛选变量？⭐⭐⭐⭐⭐
16. L1 正则化为什么能缓解过拟合⭐⭐⭐⭐⭐
17. BN+CONV 融合公式及作用⭐⭐⭐⭐⭐

## 初始化方法

1. 说说初始化方法有哪些？⭐⭐⭐⭐⭐
2. 理想的参数初始化方法是什么？⭐⭐⭐⭐⭐
3. 说说你用过的初始化方法，都有哪些优缺点⭐⭐⭐⭐⭐
4. 网络参数初始化为 0 可以吗？⭐⭐⭐⭐⭐
5. 随机初始化参数有什么问题？⭐⭐⭐⭐⭐
6. 手推梯度消失和梯度爆炸问题⭐⭐⭐⭐⭐
7. 怎么缓解梯度消失⭐⭐⭐⭐⭐
8. 梯度消失的根本原因⭐⭐⭐⭐⭐
9. 说说归一化方法⭐⭐⭐⭐⭐

## 卷积与池化

1. 说说有哪些卷积⭐⭐⭐⭐⭐
2. 卷积实现原理？⭐⭐⭐⭐⭐
3. 卷积基本计算公式，padding⭐⭐⭐⭐⭐
4. 卷积操作后的特征图大小⭐⭐⭐⭐⭐
5. 常规卷积和深度可分离卷积的计算量⭐⭐⭐⭐⭐
6. 反卷积是怎么做的， unpooling 中 maxPooling 怎么实现？⭐⭐⭐⭐⭐
7. 什么是空洞卷积？⭐⭐⭐⭐⭐
8. 知道哪些卷积类型？请介绍一下⭐⭐⭐⭐⭐
9. 为什么 Depthwise 卷积后还要进行 pointwise 卷积⭐⭐⭐⭐⭐
10. 卷积的底层实现/加速技巧⭐⭐⭐⭐⭐
11. 1x1 卷积有什么作用⭐⭐⭐⭐⭐
12. CNN 有什么特点和优势⭐⭐⭐⭐⭐
13. 说说你了解的 pooling 方法⭐⭐⭐⭐⭐
14. pooling 层的作用⭐⭐⭐⭐⭐
15. 常用的 pooling 方法有哪些，那个更好？⭐⭐⭐⭐⭐
16. 说一下 ROI Pooling⭐⭐⭐⭐⭐
17. 说一下 maxpooling 的反向传播怎么处理⭐⭐⭐⭐⭐
18. 语义分割上采样的方法⭐⭐⭐⭐⭐

## 技术发展

1. 说说分类网络的发展⭐⭐⭐⭐
2. 为什么要设计残差连接⭐⭐⭐⭐⭐
3. 说说语义分割网络的发展⭐⭐⭐⭐
4. deeplabV3 有什么改进，具体讲一下⭐⭐⭐⭐⭐
5. vgg16 同期还有哪些网络，inception 网络有什么特点⭐⭐⭐⭐⭐
6. 什么是感受野？⭐⭐⭐⭐⭐
7. 讲一下 mobileNet 系列，ResNet 系列⭐⭐⭐⭐⭐
8. 说说目标检测的发展⭐⭐⭐⭐⭐
9. 讲一下目标检测 one stage， two stage，讲一下 yoloV1⭐⭐⭐⭐⭐
10. yolo 实现，损失函数⭐⭐⭐⭐⭐
11. Faster R-CNN 的具体流程⭐⭐⭐⭐⭐
12. Faster R-CNN 训练和测试的流程有什么不一样⭐⭐⭐⭐⭐
13. YOLOv3 和 Faster R-CNN 的差异⭐⭐⭐⭐⭐
14. YOLO 系列有几个版本，YOLOv4 用到了哪优化方法⭐⭐⭐⭐⭐
15. 除了聚类，还有哪些 anchor 的设计⭐⭐⭐⭐⭐
16. anchor 的理解⭐⭐⭐⭐⭐
17. Anchor-free 的优势在哪里⭐⭐⭐⭐⭐
18. 介绍比赛中的有用的 trick 有哪些⭐⭐⭐⭐
19. 手写 nms⭐⭐⭐⭐⭐

## 评价指标

1. 说说机器学习评价指标⭐⭐⭐⭐⭐
2. AUC 是什么？AUC 是否对正负样本比例敏感？⭐⭐⭐⭐⭐
3. 分类模型如何评价⭐⭐⭐⭐⭐
4. 准确率与精准率的区别⭐⭐⭐⭐⭐
5. AUC 的意义和两种计算方法⭐⭐⭐⭐⭐
6. 讲讲分类，回归，推荐，搜索的评价指标⭐⭐⭐⭐⭐
7. AB test 的原理⭐⭐⭐⭐⭐

## 线性回归与逻辑回归

1. 逻辑回归 LR 详细推导⭐⭐⭐⭐⭐
2. 回归和分类的区别⭐⭐⭐⭐⭐
3. 逻辑回归特征是否归一化⭐⭐⭐⭐⭐
4. 什么样的模型需要特征归一化⭐⭐⭐⭐⭐
5. 如何提升 LR 的模型性能？⭐⭐⭐⭐⭐
6. 逻辑回归为啥要做特征离散化⭐⭐⭐⭐⭐
7. LR 的详细过程，如何优化⭐⭐⭐⭐⭐
8. 知道什么损失函数，lr 公式推导⭐⭐⭐⭐⭐
9. 最小二乘法在什么条件下与极大似然估计等价？⭐⭐⭐⭐⭐
10. 逻辑回归为什么不用平方损失函数？⭐⭐⭐⭐⭐

## SVM

1. 推导 SVM⭐⭐⭐⭐⭐
2. LR 和 SVM 联系与区别⭐⭐⭐⭐⭐
3. svm 介绍一下⭐⭐⭐⭐⭐
4. 讲一下 SVM 的原理⭐⭐⭐⭐⭐
5. 如果特征比较多，用 LR 还是 SVM?⭐⭐⭐⭐⭐
6. 介绍 SVM⭐⭐⭐⭐⭐
7. SVM 是否可以用随机梯度下降⭐⭐⭐⭐⭐
8. SVM 优缺点⭐⭐⭐⭐⭐
9. 为什么要将求解 SVM 的原始问题转换为其对偶问题⭐⭐⭐⭐⭐
10. 为什么 SVM 对缺失数据敏感⭐⭐⭐⭐⭐
11. SVM 怎么防止过拟合 ?⭐⭐⭐⭐⭐

## KNN

1. KNN 介绍一下⭐⭐⭐⭐
2. KNN 优缺点⭐⭐⭐⭐
3. KNN 的 K 值怎么选⭐⭐⭐⭐
4. KNN 数据需要归一化吗？⭐⭐⭐⭐
5. KNN 三要素说一下⭐⭐⭐⭐
6. 欧式距离与曼哈顿距离区别⭐⭐⭐⭐
7. knn 的 k 设置的过大会有什么问题⭐⭐⭐⭐

## 聚类

1. k-means 介绍一下⭐⭐⭐⭐⭐
2. k-means 优缺点⭐⭐⭐⭐⭐
3. k-means 的簇怎么选⭐⭐⭐⭐⭐
4. k-means 如何调优⭐⭐⭐⭐⭐
5. 知道哪些聚类模型⭐⭐⭐⭐⭐
6. K-means 的过程⭐⭐⭐⭐⭐
7. K-means 如何选取 K 值⭐⭐⭐⭐⭐
8. kmeans 聚类如何选择初始点⭐⭐⭐⭐⭐
9. kmeans 聚类，聚的是特征还是样本？特征的距离如何计算？⭐⭐⭐⭐⭐
10. 聚类算法知道哪些⭐⭐⭐⭐⭐
11. Kmeans 算法和 EM 算法的关系⭐⭐⭐⭐⭐
12. 写 Kmeans 代码⭐⭐⭐⭐⭐

## 决策树

1. 决策树介绍一下⭐⭐⭐⭐⭐
2. 决策树优缺点⭐⭐⭐⭐⭐
3. 决策树的划分标准是什么⭐⭐⭐⭐⭐
4. ID3 和 C4.5 的区别⭐⭐⭐⭐⭐
5. 树模型对离散特征怎么处理的⭐⭐⭐⭐⭐
6. 树模型怎么决定一个叶子结点是否要分裂⭐⭐⭐⭐⭐
7. 决策树出现过拟合的原因及解决办法⭐⭐⭐⭐⭐
8. 如何对决策树进行剪枝？⭐⭐⭐⭐⭐
9. 决策树需要进行归一化处理吗⭐⭐⭐⭐⭐
10. 决策树与逻辑回归的区别⭐⭐⭐⭐⭐
11. 说下决策树的损失函数⭐⭐⭐⭐⭐

## 集成学习、Adaboost、随机森林、GBDT、XgBoost、LightGBM

1. LightGBM 和 xgBoost、GBDT 的区别⭐⭐⭐⭐⭐
2. xgBoost 和 gbdt 的区别⭐⭐⭐⭐⭐
3. xgBoost 的 block 结构⭐⭐⭐⭐⭐
4. XGBoost 的优缺点⭐⭐⭐⭐⭐
5. 集成学习 Bagging Boosting⭐⭐⭐⭐⭐
6. RF 和 GBDT 的区别⭐⭐⭐⭐⭐
7. GBDT 是否适合于处理大规模的 ID 特征⭐⭐⭐⭐⭐
8. LightGBM 的直方图 排序后会比 xgboost 的效果差吗，为什么⭐⭐⭐⭐⭐
9. xgboost 正则化项和什么有关⭐⭐⭐⭐⭐
10. 随机森林哪两个随机⭐⭐⭐⭐⭐
11. bootstrap 怎么做的⭐⭐⭐⭐⭐
12. 介绍 GBDT 的详细计算过程⭐⭐⭐⭐⭐
13. xgb 的正则项是什么⭐⭐⭐⭐⭐
14. xgboost 缺失值处理方法⭐⭐⭐⭐⭐
15. 为什么 xgboost 要二阶展开？⭐⭐⭐⭐⭐
16. 集成学习的方法有哪些⭐⭐⭐⭐⭐
17. 泰勒公式求 e 的近似值⭐⭐⭐⭐⭐
18. XGBoost 如果损失函数没有二阶导，该怎么办⭐⭐⭐⭐⭐
19. GBDT 的 G 梯度的向量长度为多少⭐⭐⭐⭐⭐

## NLP

1. LSTM 与 transform 的区别⭐⭐⭐⭐⭐
2. 讲一下 Bert 原理，Bert 好在哪里？⭐⭐⭐⭐⭐
3. cbow 与 skip-gram 的区别和优缺点⭐⭐⭐⭐⭐
4. Bert 的 MLM 预训练任务 mask 的目的是什么⭐⭐⭐⭐⭐
5. CRF 原理⭐⭐⭐⭐
6. Bert 采用哪种 Normalization 结构，LayerNorm 和 BatchNorm 区别，LayerNorm 结构有参数吗，参数的作用？⭐⭐⭐⭐⭐
7. 如何优化 BERT 效果⭐⭐⭐⭐⭐
8. BERT self-attention 相比 lstm 优点是什么？⭐⭐⭐⭐⭐
9. 说说循环神经网络⭐⭐⭐⭐⭐
10. 说说 LSTM⭐⭐⭐⭐⭐
11. LSTM 的结构⭐⭐⭐⭐⭐
12. LSTM 的三个门怎么运作的，写一下三个门的公式⭐⭐⭐⭐⭐
13. LSTM 为什么可以解决长期依赖，LSTM 会梯度消失吗⭐⭐⭐⭐⭐
14. LSTM 相较于 RNN 的优势⭐⭐⭐⭐⭐
15. 讲一下 LSTM，LSTM 相对于 RNN 有哪些改进？LSTM 为什么可以解决长期问题，相对与 RNN 改进在哪
16. 讲一下 LSTM 吧，门都是怎么迭代的⭐⭐⭐⭐⭐
17. RNN 为什么难以训练，LSTM 又做了什么改进⭐⭐⭐⭐⭐
18. wide & deep 模型 wide 部分和 deep 部分分别侧重学习什么信息⭐⭐⭐⭐⭐
19. deepfm 一定优于 wide & deep 吗⭐⭐⭐⭐⭐
20. Bert 的输入是什么？⭐⭐⭐⭐⭐
21. Bert 的词向量的 embedding 怎么训练得到的？⭐⭐⭐⭐⭐
22. self-attention 理解和作用，为什么要除以根号 dk？⭐⭐⭐⭐⭐
23. BERT 中并行计算体现在哪儿⭐⭐⭐⭐⭐
24. 翻译中 Q\K\V 对应的是什么⭐⭐⭐⭐⭐
25. attention 和 self attention 的区别⭐⭐⭐⭐⭐
26. 介绍 transformer 以及讲优势⭐⭐⭐⭐⭐
27. Transformer encoder 和 decoder 的介绍⭐⭐⭐⭐⭐
28. BERT 模型怎么做的？大致的网络架构是怎么样的？⭐⭐⭐⭐⭐
29. transformer 的 position embedding 和 BERT 的 position embedding 的区别⭐⭐⭐⭐⭐

## 模型优化

1. 若 CNN 网络很庞大，在手机上运行效率不高，对应模型压缩方法有了解吗⭐⭐⭐⭐⭐
2. 介绍一下模型压缩常用的方法？为什么用知识蒸馏？⭐⭐⭐⭐⭐
3. 知道模型蒸馏吗？谈下原理⭐⭐⭐⭐⭐
4. 做过模型优化吗？模型蒸馏和模型裁剪？⭐⭐⭐⭐⭐
5. squeezeNet 的 Fire Module 有什么特点？⭐⭐⭐⭐
6. 降低网络复杂度但不影响精度的方法⭐⭐⭐⭐⭐
7. 如果让模型速度提高一倍，有什么解决方案？⭐⭐⭐⭐⭐

## 朴素贝叶斯

1. 朴素贝叶斯介绍一下⭐⭐⭐⭐⭐
2. 朴素贝叶斯优缺点⭐⭐⭐⭐⭐
3. 贝叶斯公式⭐⭐⭐⭐⭐
4. 朴素贝叶斯中的“朴素”怎么理解？⭐⭐⭐⭐⭐
5. 什么是拉普拉斯平滑法？⭐⭐⭐⭐⭐
6. 朴素贝叶斯中有没有超参数可以调？⭐⭐⭐⭐⭐
7. 你知道朴素贝叶斯有哪些应用吗？⭐⭐⭐⭐⭐
8. 朴素贝叶斯对异常值敏不敏感？⭐⭐⭐⭐⭐
9. 频率学派与贝叶斯学派的差别⭐⭐⭐⭐
10. 概率与期望的公式⭐⭐⭐⭐
11. 先验概率与后验概率⭐⭐⭐⭐

## PCA 与 LDA

1. PCA 介绍一下⭐⭐⭐⭐⭐
2. PCA 算法步骤⭐⭐⭐⭐⭐
3. PCA 原理⭐⭐⭐⭐⭐
4. PCA 降维之后的维度怎么确定⭐⭐⭐⭐⭐
5. 说说 PCA 的优缺点⭐⭐⭐⭐⭐
6. 推导一下 PCA⭐⭐⭐⭐⭐
7. 降维方法有哪些？⭐⭐⭐⭐⭐
8. LDA 介绍一下⭐⭐⭐⭐⭐
9. LDA 的中心思想是什么⭐⭐⭐⭐⭐
10. LDA 的优缺点⭐⭐⭐⭐⭐
11. 说说 LDA 的步骤⭐⭐⭐⭐⭐
12. 推导一下 LDA⭐⭐⭐⭐⭐
13. PCA 和 LDA 有什么区别⭐⭐⭐⭐⭐
14. 偏差与方差⭐⭐⭐⭐
15. SVD 懂么⭐⭐⭐⭐⭐
16. 方差和协方差的理解⭐⭐⭐⭐
17. 伯努利分布和二项分布的区别⭐⭐⭐⭐

## GAN

1. GAN 是用来干什么的，怎么用的，介绍一下⭐⭐⭐⭐⭐
2. GANs 的优缺点是什么？⭐⭐⭐⭐⭐
3. GAN 为什么不好收敛⭐⭐⭐⭐⭐
4. 为什么 GAN 中的优化器不常用 SGD⭐⭐⭐⭐⭐
5. 生成对抗网络在哪里用到的，起什么作用，损失函数是什么⭐⭐⭐⭐⭐
6. 训练 GAN 的一些技巧⭐⭐⭐⭐⭐
7. 说说 GAN 的训练过程⭐⭐⭐⭐⭐
8. Pix2pix 和 cycleGan 的区别⭐⭐⭐⭐⭐

## 特征工程

1. 特征工程有哪些⭐⭐⭐⭐⭐
2. 遇到缺值的情况，有哪些处理方式⭐⭐⭐⭐⭐
3. 样本不均衡的处理办法⭐⭐⭐⭐⭐
4. 训练时样本不平衡问题如何解决；小样本问题如何解决⭐⭐⭐⭐⭐
5. 常见的筛选特征的方法有哪些？⭐⭐⭐⭐⭐
6. 数据怎么清洗，缺失值怎么填充⭐⭐⭐⭐⭐
7. 出现 Nan 的原因⭐⭐⭐⭐⭐
8. 特征筛选，怎么找出相似性高的特征并去掉⭐⭐⭐⭐⭐
9. 对于不同场景机器学习和深度学习你怎么选择，你更习惯机器学习还是深度学习？⭐⭐⭐⭐⭐
10. 包含百万、上亿特征的数据在深度学习中怎么处理⭐⭐⭐⭐⭐
11. 类别型数据你是如何处理的？比如游戏品类，地域，设备⭐⭐⭐⭐
12. 计算特征之间的相关性方法有哪些？⭐⭐⭐⭐

## 传统算法

1. 傅里叶变换公式及其推导⭐⭐⭐
2. 边缘检测算法⭐⭐⭐
3. 牛顿法的推导过程⭐⭐⭐
4. 了解哪些插值算法⭐⭐⭐
5. SIFT 的整个详细流程⭐⭐⭐
6. SIFT 和 SURF 的区别⭐⭐⭐
7. 牛顿法和拟牛顿法⭐⭐⭐
8. FFT 和 DFT 的区别⭐⭐⭐
9. 双线性差值的操作过程⭐⭐⭐

## Python

1. python 深拷贝与浅拷贝⭐⭐⭐⭐⭐
2. python 多线程能用多个 cpu 么？⭐⭐⭐⭐⭐
3. python 垃圾回收机制⭐⭐⭐⭐⭐
4. python 里的生成器是什么⭐⭐⭐⭐⭐
5. 迭代器和生成器的区别⭐⭐⭐⭐⭐
6. 装饰器⭐⭐⭐⭐⭐
7. python 有哪些数据类型⭐⭐⭐⭐⭐
8. Python 中列表（ List ）中的 del，remove，和 pop 等的用法和区别⭐⭐⭐⭐⭐
9. python yeild 和 return 的区别⭐⭐⭐⭐⭐
10. python set 底层实现⭐⭐⭐⭐⭐
11. python 字典和 set() 的区别⭐⭐⭐⭐⭐
12. 怎么对字典的值进行排序？⭐⭐⭐⭐⭐
13. init 和 new 和 call 的区别⭐⭐⭐⭐⭐
14. import 常用库⭐⭐⭐
15. python 的 lamda 函数⭐⭐⭐⭐⭐
16. Python 内存管理⭐⭐⭐⭐⭐
17. python 在内存上做了哪些优化？⭐⭐⭐⭐⭐
18. Python 中类方法和静态方法的区别⭐⭐⭐⭐⭐
19. python 多线程怎么实现⭐⭐⭐⭐⭐
20. 点积和矩阵相乘的区别？⭐⭐⭐⭐
21. Python 中错误和异常处理⭐⭐⭐⭐
22. Python 的传参是传值还是传址？⭐⭐⭐⭐
23. 什么是猴子补丁？⭐⭐⭐⭐
24. 当退出 Python 时是否释放所有内存分配？⭐⭐⭐⭐
25. Python 中的 is 和 == 有什么区别？⭐⭐⭐⭐
26. gbk 和 utf8 的区别⭐⭐⭐⭐
27. 遍历字典可以用什么方法⭐⭐⭐⭐
28. 反转列表的方法⭐⭐⭐⭐
29. python 元组中元组转为字典⭐⭐⭐⭐
30. range 在 python2 和 python3 里的区别⭐⭐⭐⭐
31. __init__.py 文件的作用以及意义⭐⭐⭐⭐