# 字节跳动-博士生-计算机视觉研究员面经

## 一面：技术面

首先是比较常规的介绍一下自己博士期间的科研工作和科研成果，期间面试官问了一些跟研究成果有关的问题，然后就是技术问题了。

### 计算机视觉和机器学习问题：

#### 1. 用 numpy 实现一下 bicubic 插值。
   
这个问题一上来就把我干蒙圈了，bicubic 插值虽然特别常用，但是插值公式我只记得是个分三段的分段函数，具体的数学表达式我是真的不记得了，后来面试官退而求其次，让我写 bilinear，这个就比较好写了。

答案参考：[双线性和双三次插值](https://blog.csdn.net/weixin_42463482/article/details/82830628)。 

#### 2. 阐述常见的边缘提取算子，并介绍一下 CANNY 算子的具体步骤。

拉普拉斯算子、CANNY 算子、索贝尔算子等，然后 CANNY 算子的具体流程我记得不是特别清楚了，只回答了计算梯度-二值化-非极大值抑制这三步。

答案参考：[Canny 边缘检测方法](https://blog.csdn.net/saltriver/article/details/80545571)。 

#### 3. 机器学习中 Overfitting 的常用解决方法。

按照模型层面、优化层面、数据集层面三个角度列举了一些解决方法。
- 模型层面
  - 减少参数量
  - 加入 BN 和 Dropout 等网络层
- 优化层面
  - 加入正则项，如针对问题设计的正则化算子、常见的 L1 正则等
- 数据集层面
  - 加大数据量
  - 数据增广等

#### 4. BN 的原理和具体实现，用 PyTorch 实现一下 BN 层。

这个还是比较简单的，虽然超分辨率问题中几乎没用过 BN，但是没吃过猪肉还是见过猪跑的。面试官在我写 BN 代码的时候还问了一下 BN 的训练和测试的区别，这个也属于原理性的东西了，BN 训练的时候，均值和方差的统计量都是在 batch 维度上统计得到的，但是测试的时候 batch size 一般是 1，没办法得到统计量，因此一般会保存最后一个训练批次得到的统计量，或者对最后几个批次的统计量进行 moving average，用于最后的测试。以上是我的回答。参考：[Batch normalization 相关资料](https://zhuanlan.zhihu.com/p/34879333)。 

#### 5. Dropout 前传和后传的差异。

这个我当时回答的时候有点忘了，主要还是不常用啊 QAQ，当时回答的是按照概率选择一些 weight 不计算，其实这个回答很含糊。正确答案是按照概率将输出的 feature 置零，就可以同时解决前传和反传了。 

#### 6. BN 和 Dropout 一起用的时候会出现什么问题？

这个实在没用过，我当时一脸懵逼，完全不晓得咋回答。其实主要是 Dropout 会使得 BN 要用的统计量产生误差，因此 Dropout 直接在 BN 前面用会有问题，具体的可以参考链接 BN 和 Dropout 一起用的问题。 

### 编程题与数学题

#### 1. 用较快的办法找到一个未排序数组第 k 大的数字。

当时我还没有复习到排序算法，这道题答得非常以及极其的拉跨，随后面试官看我不太会，就问我知道多少种，哪些是 O(n) 的复杂度，哪些是 O(logn) 的复杂度，这里我还是答得非常差劲，主要是没复习啊啊啊。其实用冒泡排序就行了，冒 k 次就可以找到第 k 大的数字，给一个经典排序算法的链接：[十大经典排序算法](https://www.runoob.com/w3cnote/ten-sorting-algorithm.html)。 

#### 2. 用均匀分布随机整数生成器 rand(7) 来实现 rand(10)。

这个问题一开始我还有点小蒙圈，面试官稍微提示了一下我就知道了，应该用两个 rand(7)，构成一个二维的平面，然后将其中的一些点均分成 10 份，每一份代表 1-10 中的一个数字，就实现 rand(10) 了。参考：这是 leetcode 里面的一道中等难度题目，[Leetcode-470](https://leetcode-cn.com/problems/implement-rand10-using-rand7/)。 

#### 3. 计算机中一般常见的是均匀分布的（伪）随机数，如果要用正态分布，就需要用均匀分布去生成，那么如何用均匀分布生成正态分布？或者给出数学推导。

这个我真的是完全没有了解过，直接 GG。其实上一问给出了一点提示的，可以通过类似的拒绝采样的方式来求解，不过在计算机编程语言中比较常用的还是 Box-Muller 方法，参考链接：[均匀分布构造其他分布的方法](https://ziyunge1999.github.io/blog/2020/09/06/constructNormalDistribution/)。 

### 小结

到这里字节跳动的一面就结束了，除了介绍自己科研成果时的问题我可以引经据典、对答如流，后面的一些问题有相当大一部分是回答得不太好的，主要原因还是当时正在实习，没有太多时间复习，很多基础的东西（如排序算法、BN、Dropout 等）没有复习，就印象不深刻，很难回答得很流利，还是要多复习呀！不过可能是因为博士招聘科研成果相关内容占比比较高，一面我还是通过了。

## 二面：技术面

二面是由部门中做图像生成技术的面试官来进行的，首先还是常规的介绍自己科研经历的过程，然后就是问题环节，问的问题主要都是计算机视觉的问题和编程题。

### 计算机视觉问题

#### 1. 用过 GAN 吗？用过什么样的 GAN？目前在用的 GAN 是什么？

由于是智能创作部门，对 GAN 的研究比较多，所以面试官问了很多 GAN 的问题，我就都如实回答了。 

#### 2. 你对网络结构的设计有什么心得？

我当时的回答具体什么样记不太清了，大概的回答就是，要么就借鉴最新的、来自其他领域的、被证明了有效的框架和模块，如 ResBlock、Channel Attention 之类的，要么就根据当前任务的数据结构、图像模式、图像特征进行专门化的模块设计。 

#### 3. 怎么做网络轻量化？

我当时的回答是有三种方法，一种是设计轻量化的模块和结构，一种是对模型进行剪枝或者量化，一种是利用知识蒸馏技术用大模型教育小模型。随后他问了一下我了解过的轻量化模块，我提了一下超分辨率里面用过的 IMDB，他就让我介绍了一下 IMDB 的设计思路。

#### 4. 你对 attention 机制的理解是什么？attention 机制的优势和劣势分别在哪里？

我当时的回答是，我认为 attention 机制是对卷积局部性、位移不变性这两种特性的补充，通过全局的 attention 计算来实现较大的感受野。attention 机制的优势是能够以较大的感受野来实现任务性能的提升，可以解决卷积的一些暂时不好解决的问题，但是它的劣势也比较明显，一来是计算量的问题，二来是不一定所有任务都需要 attention，它也不是万能的东西。 

#### 5. 视频超分与图像超分之间的区别？

图像超分主要利用的是单张图像内部的局部、非局部特性作为约束和信息补充的渠道，而视频超分则在此基础上还要用到来自其他帧的信息，具体方法上二者的区别也体现在此，视频超分往往致力于怎么去更好地利用各帧之间的关系。

### 编程题

#### 1. 给定一个整数数组和一个目标值，返回数组中了两数之和等于目标值的数的下标。

当时我是用 python，通过建立字典来做的，最后是新建了一个字典来去重，面试官觉得我建立新字典太耗费空间，我说可以通过 merge 字典的方式来避免新建，他提议可以双重遍历。 

### 小结

二面由于大部分都是计算机视觉的内容，就没啥太大问题，然后可能面试官也知道我编程刷题刷得不多，所以编程题也问了一道不那么难的。

## 三面：技术面（主管）

三面是一个部门的技术主管对我进行面试，首先还是介绍了一下自己的科研经历，然后主管问了我一些问题。

#### 1. 如果想给抖音的一个视频做封面，可以怎么设计算法，让我讲两种不同的思路。

当时我的回答一个是根据视频内容，利用视频总结的方法 (video summarization) 提取出关键帧作为封面，第二个是根据大众的喜好，从视频中选取最容易引起高点击率的帧作为封面。 

#### 2. 有 100 盏灯，一开始都是亮的，第一次隔 1 盏灯按一下开关，第二次隔两盏，第 99 次隔 99 盏，问 99 次之后哪些灯是亮的。

这个我思考了一下，从整数的因数角度回答了出来。这个其实是 leetcode 的一道中等难度的编程题，[Leetcode-319](https://leetcode-cn.com/problems/bulb-switcher/)。 

随后就是一些工作岗位相关问题的互相提问和解答，这里就不再赘述了。

## 四面：HR 面

HR 面试主要问的都是一些常规问题，当然由于不是技术面，就没有介绍自己科研经历的环节了，这里简单记录一下 HR 小姐姐问的问题。

1. 方向问题：去字节想做什么方向？有什么职业规划？对字节的期待是什么？
2. 每次面试之后会做复盘吗？怎么做的？
3. 实习期间遇到了什么问题和困难，怎么解决的？
4. 科研和工作时碰到技术瓶颈怎么解决？
5. 对于不太懂技术的人，比如她自己，请简单地阐述超分辨率和 HDR 重建这两个方向的区别。
