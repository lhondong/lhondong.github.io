# 机器学习基础

## 一、Kmeans

### 1. 算法思想

对于给定的样本集，按照样本之间的距离大小，将样本集划分为 K 个簇。让簇内的点尽量紧密的连在一起，而让簇间的距离尽量的大。

步骤：
1. 输入样本集，聚类的簇树 k，最大迭代次数 N
2. 随机选择 k 个样本作为 k 类所对应的质心
3. 分别求样本中所有点到这两个质心的距离
4. 标记样本为和该样本距离最小的质心的类别，由此我们得到了所有样本点的第一轮迭代后的类别。
5. 对当前 k 个类别分别求其新的质心。
6. 重复上述步骤，直到所有的 k 个质心向量都没有发生变化
7. 输出簇划分

### 2. 算法要点 

#### k 值的选择

一般来说，根据对数据的先验经验选择一个合适的 k 值，如果没有什么先验知识，则可以通过交叉验证选择一个合适的 k 值。

k 个初始化的质心的位置选择对最后的聚类结果和运行时间都有很大的影响，因此需要选择合适的 k 个质心，最好这些质心不能太近。

### 3. 优缺点

优点：

1. 原理比较简单，实现也是很容易，收敛速度快。
2. 聚类效果较优。
3. 算法的可解释度比较强。
4. 主要需要调参的参数仅仅是簇数 k。

缺点：

1. K 值的选取不好把握（改进：可以通过在一开始给定一个适合的数值给 k，通过一次 K-means 算法得到一次聚类中心。对于得到的聚类中心，根据得到的 k 个聚类的距离情况，合并距离最近的类，因此聚类中心数减小，当将其用于下次聚类时，相应的聚类数目也减小了，最终得到合适数目的聚类数。可以通过一个评判值 E 来确定聚类数得到一个合适的位置停下来，而不继续合并聚类中心。重复上述循环，直至评判函数收敛为止，最终得到较优聚类数的聚类结果）。
2. 只能发现球状的簇。在 k-means 中，我们用单个点对 cluster 进行建模，这实际上假设了各个 cluster 的数据是呈高维球型分布的，但是在生活中出现这种情况的概率并不算高。例如，每一个 cluster 是一个一个的长条状的，k-means 的则根本识别不出来这种类别（这种情况可以用 GMM）。实际上，k-means 是在做凸优化，因此处理不了非凸的分布。
3. 如果各隐含类别的数据不平衡，比如各隐含类别的数据量严重失衡，或者各隐含类别的方差不同，则聚类效果不佳。
4. 采用迭代方法，得到的结果只是局部最优。
5. 对噪音和异常点比较的敏感（改进 1：离群点检测的 LOF 算法，通过去除离群点后再聚类，可以减少离群点和孤立点对于聚类效果的影响；改进 2：改成求点的中位数，这种聚类方式即 K-Mediods 聚类（K 中值）)。
6. 初始聚类中心的选择（改进 1：k-means++; 改进 2：二分 K-means)。
7. 初始值影响较大，可能每次聚类结果不同

### 4. 高维稀疏数据

高维空间中不建议直接使用 kmeans 聚类，因为高维空间中样本的分布范围往往比较分散，这时再用样本之间的距离来度量相似性往往不具有很强的说服力，常用的做法是先考虑使用 PCV 降维，然后再考虑聚类。

## 二、激活函数

激活函数应有的性质：

1. 可微（多元函数）：函数可微保证使用梯度下降优化的可计算性。
2. 单调性：保证梯度方向相对稳定。
3. 输出值范围：当输出有限，由于特征表示受有限权值影响，基于梯度的优化方法会更加稳定；当输出无限，特征表示不受影响，但由于高梯度需要小学习率。
4. 非饱和性：激活函数饱和会造成梯度值接近 0，导致梯度消失使模型无法收敛。

### Sigmoid

Sigmoid 激活函数具有“连续可微”，“单调性”，“输出值有限”。通过查看导函数图像，Sigmoid 激活函数最大的问题就是两端饱和，造成梯度消失（解决办法：使用 ReLU 激活函数，BN 等），此外输出不以 0 中心（以 0 中心的好处是可以加快模型收敛）。
目前 Sigmoid 激活函数多使用在二分类问题（对于大于二分类问题，如果类别之间存在相互关系使用 Sigmoid，反之使用 Softmax），门控机制的判断等。

### Softmax 激活函数

### ReLU

ReLU 与线性单元的区别是在其一半的定义域上输出为 0，这使得它易于优化，计算。ReLU 激活函数的梯度不仅大，而且一致，更重要的是它没有 Sigmoid，tanh 激活函数的饱和性，有效缓解了梯度消失问题。目前，ReLU 激活函数是神经网络隐藏层的首选。
但是，它最大的问题是当输入小于 0 时，输出值为 0，此时神经元将无法学习。

优点：

1. 当输入为正时，不存在梯度饱和问题。
2. ReLU 函数中只存在线性关系，因此它的计算速度比 Sigmoid 和 tanh 更快。

缺点：
1. 当输入为负时，ReLU 完全失效，在正向传播过程中，这不是问题。有些区域很敏感，有些则不敏感。但是在反向传播过程中，如果输入负数，则梯度将完全为零，sigmoid 函数和 tanh 函数也具有相同的问题；
2. ReLU 函数不是以 0 为中心的函数。

ReLU 激活函数在零点是否可导？

答：不可导，而 ReLU 左导数等于 0，右导数等于 1，因此不可导间断点的求导按左导数来计算。也就是默认情况下（negative_slope=0），间断点处的导数认为是 0。

#### Leaky ReLU 

1. Leaky ReLU 通过把 x 的非常小的线性分量给予负输入（0.01x）来调整负值的零梯度（zero gradients）问题；
2. Leaky ReLU 激活函数一个缺点就是它有些近似线性，导致在复杂分类中效果不好。

### tanh

tanh 激活函数输出区间 [-1,1]，输出值以 0 为中心，与 sigmoid 激活函数相比具有更大的梯度值，再加上输出值以 0 为中心，模型收敛更快。不过它依然存在两端饱和，梯度消失问题还是存在，tanh 激活函数在 RNN 模型中应用较多。

## 三、损失函数

损失函数都是平方形式，原因：

1. 误差的平方形式是正的。这样正的误差和负的误差不会相互抵消。这就是为什么不用一次方，三次方的原因。
2. 误差的绝对值也是正的，为什么不用绝对值呢。所有还有第二个重要原因是：平方形式对大误差的惩罚大于小误差。

### 交叉熵

#### 熵：

$$
H(X)=-\sum p\log p(x)
$$

#### KL 散度（相对熵）：

$$
KL=\sum p(x) \log \frac{p(x)}{q(x)}
$$

#### 交叉熵：

$$
H(P,Q)=H(P)+ KL(P \Vert Q)
$$

### 均方差损失（Mean Squared Error Loss）（L2 loss）

### 平均绝对误差损失（Mean Absolute Error Loss）（L1 loss）

MAE MSE 优劣
1. MSE 比 MAE 能够更快收敛：当使用梯度下降算法时，MSE 损失的梯度为 $-y_i$，而 MAE 损失的梯度为 -1。所以。MSE 的梯度会随着误差大小发生变化，而 MAE 的梯度一直保持为 1，这不利于模型的训练

2. MAE 对异常点更加鲁棒：从损失函数上看，MSE 对误差平方化，使得异常点的误差过大；从两个损失函数的假设上看，MSE 假设了误差服从高斯分布，MAE 假设了误差服从拉普拉斯分布，拉普拉斯分布本身对于异常点更加鲁棒。

### 合页损失 Hinge Loss

# 深度学习基础

## 1. RNN

RNN 缺点：

1. 梯度消失与梯度爆炸原因
2. 梯度消散并不是指梯度就没有，而是远距离位置的梯度值变得越来越微弱，无法对序列中长距离的依赖性进行建模。

### LSTM

为什么 LSTM 解决梯度消失？

梯度消失的原因是使用多个激活函数偏导乘积的形式来计算梯度时，如果梯度权重小于 1，多次相乘后会趋近于 0。

LSTM 的 memory 值 C 是将 memory 值和 input 累加的，传统 RNN 每次都会把之前的 memory 直接清空。

LSTM 有门控机制，在 forget 门关闭的情况下，memory 的值是不更新的

1. cell state 传播函数中的“加法”结构确实起了一定作用，它使得导数有可能大于 1；
2. LSTM 中逻辑门的参数可以一定程度控制不同时间步梯度消失的程度。

### RNN 与 GRU，LSTM 区别

1. RNN 没有细胞状态；LSTM 通过细胞状态记忆信息。
2. RNN 激活函数只有 tanh；LSTM 通过输入门、遗忘门、输出门引入 sigmoid 函数并结合 tanh 函数，添加求和操作，减少梯度消失和梯度爆炸的可能性。
3. RNN 只能够处理短期依赖问题；LSTM 既能够处理短期依赖问题，又能够处理长期依赖问题。
4. LSTM 含有更多的参数需要学习，从而导致 LSTM 的学习速度大大降低

GRU：重置门与更新门

## 2. 卷积

### 池化

1. 保留主要特征的同时减少参数和计算量，防止过拟合。
2. invariance（不变性），这种不变性包括 translation（平移），rotation（旋转），scale（尺度）。

Pooling 层说到底还是一个特征选择，信息过滤的过程。也就是说我们损失了一部分信息，这是一个和计算性能的一个妥协，随着运算速度的不断提高，这个妥协会越来越小。

## 3. 数据增强

数据增强主要指在计算机视觉领域中对图像进行数据增强，从而弥补训练图像数据集不足，达到对训练数据扩充的目的。

数据增强是一种数据扩充方法，可分为同类增强（如：翻转、旋转、缩放、移位、模糊等）和混类增强（如 mixup）两种方式。

单一样本数组增强
多样本数据增强

#### 数据不平衡的解决方法

- 对较多类别进行欠采样 (under-sampling)，舍弃一部分数据，使其与较少类别的数据相当。
  - 缺点：浪费数据，丢失重要信息
- 对较少类别进行过采样 (over-sampling)，生成一部分数据，使其与较多类别的数据相当。
  - 缺点：对大规模且高度不平衡的数据集，过采样可能会生成大量的少数类样本，这会增大训练集的样本数量，增大计算开销，减慢训练速度，并可能导致过拟合。
- 随机森立模型+合理阈值调整（threshold moving），将原本默认为 0.5 的阈值调整到较少类别/（较少类别+较多类别）即可
  - 这个方法核心思想是：通过组合/集成方法解决样本不均衡，它指的是在每次生成训练集时使用所有分类中的小样本量，同时从分类中的大样本量中随机抽取数据来与小样本量合并构成训练集，这样反复多次会得到很多训练集和训练模型。最后在应用时，使用组合方法（例如投票、加权投票等）产生分类预测结果。这种解决问题的思路类似于随机森林。在随机森林中，虽然每个小决策树的分类能力很弱，但是通过大量的“小树”组合形成的“森林”具有良好的模型预测能力。
  - 优点：集成学习降低过拟合风险，使用阈值调整规避和采样问题，同时选择合适的评估手段以防止偏见，准确率较高。
  - 缺点：计算量大。

## 3. Transformer

### Transformer 与 CNN

Transformer 是动态闭环的，比静态好

Transformer 关注两者之间关系，因此对离群点容错性较高，不关注自身 value，但是 CNN 具备 scale 平移不变形，Transformer 不具备

### position encoding

1. 最简单的位置编码就是计数，但是这样这个序列是没有上界的。一段很长的文本，最后一个字的位置编码非常大，这是很不合适的：
1. 它比第一个字的编码大太多，和词嵌入合并以后难免会出现特征在数值上的倾斜；
2. 它比一般的词嵌入的数值要大，难免会抢了字嵌入的「风头」，对模型可能有一定的干扰。

从这里，我们知道位置编码最好具有一定的值域范围。使用文本长度对每个位置作归一化。这样使得所有位置编码都落入一定区间，但是问题也是显著的：不同长度文本的位置编码步长是不同的，在较短的文本中紧紧相邻的两个字的位置编码差异，会和长文本中相邻数个字的两个字的位置编码差异一致。这显然是不合适的，我们关注的位置信息，最核心的就是相对次序关系，尤其是上下文中的次序关系，如果使用这种方法，那么在长文本中相对次序关系会被「稀释」。

重新审视一下位置编码的需求：

1. 需要体现同一个单词在不同位置的区别；
2. 需要体现一定的先后次序关系，并且在一定范围内的编码差异不应该依赖于文本长度，具有一定不变性。

一种思路是使用有界的周期性函数。如果我们放弃对绝对位置的追求，转而要求位置编码仅仅关注一定范围内的相对次序关系，那么使用一个 sin/cos 函数就是很好的选择，因为 sin/cos 函数的周期变化规律非常稳定，所以编码具有一定的不变性。简单的构造可以使用下面的形式

$$
PE(pos)=sin(\frac{pos}{\alpha})
$$

但是，周期函数的引入是为了复用位置编码函数的值域，但是这种 [-1,1] 的映射，还是太单调：如果 $/alpha$ 比较大，相邻字符之间的位置差异体现得不明显；如果比较小，在长文本中还是可能会有一些不同位置的字符的编码一样，这是因为 [-1,1] 空间的表现范围有限。既然字嵌入的维度是 $d_{model}$，自然也可以使用一个 $d_{model}$ 维向量来表示某个位置编码。

在不同维度上应该用不同的函数操纵位置编码，这样高维的表示空间才有意义。可以为位置编码的每一维赋予不同的 $/alpha$；甚至在一些维度将 sin 替换为 cos:

$$
\begin{gathered}
PE(pos,2i)=\sin(\frac{pos}{10000^{2i/d_{model}}})\\
PE(pos,2i+1)=\cos(\frac{pos}{10000^{2i/d_{model}}})
\end{gathered}
$$

这里不同维度上 sin/cos 的波长从 $2pi$ 到 $10000*2pi$ 都有；区分了奇偶数维度的函数形式。这使得每一维度上都包含了一定的位置信息，而各个位置字符的位置编码又各不相同

## 4. Resnet

### 解决的问题：（退化）

从经验来看，当增加网络层数后，理论上可以取得更好的结果。但是实际上深度网络存在退化问题（Degradation problem）：网络深度增加时，网络准确度出现饱和，甚至出现下降。

### 特点：（残差链接/短路连接）

对于一个堆积层结构当输入为 $x$ 时其学习到的特征记为 $H(x)$，现在我们希望其可以学习到残差 $F(x) = H(x)-x$，这样其实原始的学习特征是 $F(x)+x$。这是因为残差学习相比原始特征直接学习更容易。当残差为 0 时，此时堆积层仅仅做了恒等映射，至少网络性能不会下降，实际上残差不会为 0，这也会使得堆积层在输入特征基础上学习到新的特征，从而拥有更好的性能。这有点类似与电路中的“短路”，所以是一种短路连接。

### 原理：
加入线性变换

<div align=center><img src="/assets/ResNet-2022-01-23-22-41-47.png" alt="ResNet-2022-01-23-22-41-47" style="zoom:50%;" /></div>

1. 自适应深度：网络退化问题就体现了多层网络难以拟合恒等映射这种情况，也就是说 $H(x)$ 难以拟合 $x$，但使用了残差结构之后，拟合恒等映射变得很容易，直接把网络参数全学习到为 0，只留下那个恒等映射的跨层连接即可。于是当网络不需要这么深时，中间的恒等映射就可以多一点，反之就可以少一点。
2. “差分放大器”：假设最优 $H(x)$ 更接近恒等映射，那么网络更容易发现除恒等映射之外微小的波动
3. 缓解梯度消失：针对一个残差结构对输入 $x$ 求导就可以知道，由于跨层连接的存在，总梯度在 $F(x)$ 对 $x$ 的导数基础上还会加 1。

对于短路连接，当输入和输出维度一致时，可以直接将输入加到输出上。但是当维度不一致时（对应的是维度增加一倍），有两种策略：

1. 采用 zero-padding 增加维度，此时一般要先做一个 downsamp（降采样），可以采用 stride=2 的 pooling，这样不会增加参数；
2. 采用新的映射（projection shortcut），一般采用 1x1 的卷积，这样会增加参数，也会增加计算量。

## 5. 梯度消失与梯度爆炸

### 产生原因

目前优化神经网络的方法都是根据损失函数计算的误差通过梯度反向传播指导深度网络权值的更新优化。其中将误差从末层往前传递的过程需要链式法则（Chain Rule）的帮助，而链式法则是一个连乘的形式，所以当层数越深的时候，梯度将以指数形式传播。梯度消失问题和梯度爆炸问题一般随着网络层数的增加会变得越来越明显。在更新时，得到的梯度值接近 0 或特别大，也就是梯度消失或爆炸。梯度消失或梯度爆炸在本质原理上其实是一样的。

### 梯度消失

原因：一是深层网络，二是采用了不合适的损失函数，比如 sigmoid。

现象：当梯度消失发生时，接近于输出层的隐藏层由于其梯度相对正常，所以权值更新时也就相对正常，但是当越靠近输入层时，由于梯度消失现象，会导致靠近输入层的隐藏层权值更新缓慢或者更新停滞。这就导致在训练时，只等价于后面几层的浅层网络的学习。

### 梯度爆炸

原因：深层网络和权值初始化值太大的情况。

现象：在深层神经网络或循环神经网络中，误差的梯度可在更新中累积相乘。如果网络层之间的梯度值大于 1.0，那么重复相乘会导致梯度呈指数级增长，梯度变的非常大，然后导致网络权重的大幅更新，并因此使网络变得不稳定。

梯度爆炸会伴随一些细微的信号，如：

1. 模型不稳定，导致更新过程中的损失出现显著变化；
2. 训练过程中，在极端情况下，权重的值变得非常大，以至于溢出，导致模型损失变成 NaN 等等。

#### 深层网络

如果接近输出层的激活函数求导后梯度值大于 1，那么层数增多的时候，最终求出的梯度很容易指数级增长，就会产生梯度爆炸；相反，如果小于 1，那么经过链式法则的连乘形式，也会很容易衰减至 0，就会产生梯度消失。

另外不同的层学习的速度差异很大，表现为网络中靠近输出的层学习的情况很好，靠近输入的层学习的很慢，有时甚至训练了很久，前几层的权值和刚开始随机初始化的值差不多。因此，梯度消失、爆炸，其根本原因在于反向传播训练法则，属于先天不足。

#### 激活函数

如果使用 sigmoid 作为损失函数，其梯度是不可能超过 0.25 的，而我们初始化的网络权值通常都小于 1，因此对于链式求导，层数越多，求导结果越小，因而很容易发生梯度消失。

#### 初始权重过大

当初始权重比较大的情况。根据链式相乘（反向传播）可得，则前面的网络层比后面的网络层梯度变化更快，很容易发生梯度爆炸的问题。

### 解决方法

梯度消失和梯度爆炸问题都是因为网络太深，网络权值更新不稳定造成的，本质上是因为梯度反向传播中的连乘效应。解决梯度消失、爆炸主要有以下几种方法：

#### pre-training+fine-tunning

每次训练一层隐节点，训练时将上一层隐节点的输出作为输入，而本层隐节点的输出作为下一层隐节点的输入，此过程就是逐层“预训练”（pre-training）；在预训练完成后，再对整个网络进行“微调”（fine-tunning）。此思想相当于是先寻找局部最优，然后整合起来寻找全局最优。

#### 梯度剪切：对梯度设定阈值

梯度剪切这个方案主要是针对梯度爆炸提出的，其思想是设置一个梯度剪切阈值，然后更新梯度的时候，如果梯度超过这个阈值，那么就将其强制限制在这个范围之内。这可以防止梯度爆炸。

#### 权重正则化

正则化主要是通过对网络权重做正则来限制过拟合。如果发生梯度爆炸，那么权值就会变的非常大，反过来，通过正则化项来限制权重的大小，也可以在一定程度上防止梯度爆炸的发生。

#### 选择 ReLU 等梯度大部分落在常数上的激活函数

ReLU 函数的导数在正数部分是恒等于 1 的，因此在深层网络中使用 ReLU 激活函数就不会导致梯度消失和爆炸的问题。

#### batch normalization

BN 就是通过对每一层的输出规范为均值和方差一致的方法，消除了权重参数放大缩小带来的影响，进而解决梯度消失和爆炸的问题，或者可以理解为 BN 将输出从饱和区拉倒了非饱和区。

#### 残差网络的捷径（shortcut）

残差中有很多跨层连接结构，这样的结构在反向传播中具有很大的好处，可以避免梯度消失。

#### LSTM 的“门（gate）”结构

LSTM 通过它内部的“门”可以在接下来更新的时候“记住”前几次训练的”残留记忆“。

## 6. 过拟合

过拟合定义：模型在训练集上的表现很好，但在测试集和新数据上的表现很差。

### 原因

1. 模型复杂度过高，参数过多
2. 训练数据比较小
3. 训练集和测试集分布不一致
   - 样本里面的噪声数据干扰过大，导致模型过分记住了噪声特征，反而忽略了真实的输入输出特征
   - 训练集和测试集特征分布不一样（如果训练集和测试集使用了不同类型的数据集会出现这种情况）

## 解决方案

1. 增加数据量
2. 数据增强
3. early stopping
4. 正则化
5. drop out
6. 多任务学习

## 7. 优化器

### BGD（全梯度下降）

$$
\theta = \theta-\eta\nabla_\theta J(\theta)
$$

全梯度下降计算梯度根据整个数据集合。

优点：梯度是在全部数据集上计算出的，因此每次迭代都是向着整体的最优化方向。
缺点：
1. 每更新一次参数，就要遍历全部数据集，计算起来非常慢。
2. 容易陷入极小值点，因为在极小值点（鞍点）梯度为 0，所以参数不会更新。

### SGD（随机梯度下降）

SGD 每次更新时对随机选择一个样本进行梯度更新。

优点：

1. 与全梯度下降相比，更新参数时速度快。
2. 与全梯度相比，SGD 可能会跳出局部极小值点，因为在极小值（鞍点）的时候它计算梯度是随机选择的一个样本，这个梯度未必是 0
缺点：

1. SGD 每次的更新并不是向着整体最优化方向，虽然速度快，准确度下降，并不是全局最优。虽然具有随机性，但是从期望上看，它是等于正确的导数。
2. Learning rate 选择比较困难

### 动量

当前时刻的梯度是从开始时刻到当前时刻的梯度指数加权平均，并给这个梯度的指数加权值取了个名字速率 v, 既有方向也有大小。

$$
\begin{gathered}
v_t = \gamma v_{t-1}+\eta\nabla_\theta J(\theta)\\
\theta= \theta-v_t
\end{gathered}
$$

优点：
1. 与梯度下降相比，下降速度快，因为如果方向是一直下降的，那么速度将是之前梯度的和，所以比仅用当前梯度下降快。
2. 对于窄长的等梯度图，会减轻梯度下降的震荡程度，因为考虑了当前时刻是考虑了之前的梯度方向，加快收敛

### Adagrad (Adaptive gradient algorithm)

可以对低频的参数做较大的更新，对高频的做较小的更新，也因此，对于稀疏的数据它的表现很好，很好地提高了 SGD 的鲁棒性，例如识别 Youtube 视频里面的猫，训练 GloVe word embeddings，因为它们都是需要在低频的特征上有更大的更新。

$$
\theta_{t+1, i}=\theta_{t, i}-\frac{\eta}{\sqrt{G_{t, i i}+\epsilon}} \cdot g_{t, i}
$$

其中 $g$ 为 $t$ 时刻参数 $\theta_i$ 的梯度

$$
g_{t, i}=\nabla_{\theta} J\left(\theta_{i}\right)
$$

如果是普通的 SGD， 那么 $\theta_i$ 在每一时刻的梯度更新公式为：

$$
\theta_{t+1, i}=\theta_{t, i}-\eta \cdot g_{t, i} 
$$

但这里的 learning rate $\eta$ 也随 $t$ 和 $i$ 而变：

$$
\theta_{t+1, i}=\theta_{t, i}-\frac{\eta}{\sqrt{G_{t, i i}+\epsilon}} \cdot g_{t, i}
$$

其中 $G_t$ 是个对角矩阵， (i,i) 元素就是 $t$ 时刻参数 $\theta_i$ 的梯度平方和。

Adagrad 的优点是减少了学习率的手动调节

超参数设定值：一般 $eta$ 选取 0.01。$$

缺点：

它的缺点是分母会不断积累，这样学习率就会收缩并最终会变得非常小。

### Adam

SGD 算法中的学习率都是固定不变的，Adam 是对学习率自适应调整。

Adam 不仅存储了过去梯度的平方的指数衰减平均值，还向 Monentum 一样保持了过去提取的指数衰减平均值：

优点：学习率自适应修正，不用手动调整。

除了像 Adadelta 和 RMSprop 一样存储了过去梯度的平方 $v_t$ 的指数衰减平均值 ，也像 momentum 一样保持了过去梯度 $m_t$ 的指数衰减平均值：

$$
\begin{gathered}
m_{t}=\beta_{1} m_{t-1}+\left(1-\beta_{1}\right) g_{t} \\
v_{t}=\beta_{2} v_{t-1}+\left(1-\beta_{2}\right) g_{t}^{2} 
\end{gathered}
$$

如果 $m_t$ 和 $v_t$ 被初始化为 0 向量，那它们就会向 0 偏置，所以做了偏差校正，通过计算偏差校正后的 $m_t$ 和 $v_t$ 来抵消这些偏差：

$$
\begin{gathered}
\hat{m}_{t}=\frac{m_{t}}{1-\beta_{1}^{t}} \\
\hat{v}_{t}=\frac{v_{t}}{1-\beta_{2}^{t}} 
\end{gathered}
$$

梯度更新规则：

$$
\theta_{t+1}=\theta_{t}-\frac{\eta}{\sqrt{\hat{v}_{t}}+\epsilon} \hat{m}_{t}
$$

## 8. 归一化

### 为什么要做归一化处理？

神经网络学习过程的本质就是为了学习数据分布，如果我们没有做归一化处理，那么每一批次训练数据的分布不一样，从大的方向上看，神经网络则需要在这多个分布中找到平衡点，从小的方向上看，由于每层网络输入数据分布在不断变化，这也会导致每层网络在找平衡点，显然，神经网络就很难收敛了。当然，如果我们只是对输入的数据进行归一化处理（比如将输入的图像除以 255，将其归到 0 到 1 之间），只能保证输入层数据分布是一样的，并不能保证每层网络输入数据分布是一样的，所以也需要在神经网络的中间层加入归一化处理
 
BN、LN、IN 和 GN 这四个归一化的计算流程几乎是一样的，可以分为四步：

1. 计算出均值
2. 计算出方差
3. 归一化处理到均值为 0，方差为 1
4. 变化重构，恢复出这一层网络所要学到的分布
 
### BN(batch normalization)

1. BN 的计算就是把每个通道的 NHW 单独拿出来归一化处理
2. 针对每个 channel 我们都有一组 $\gamma,\beta$ ，所以可学习的参数为 $2C$
3. 当 batch size 越小，BN 的表现效果也越不好，因为计算过程中所得到的均值和方差不能代表全局

优点：
1.	加速模型训练
2.	缓解梯度消失
3.	防止过拟合
4.	简化网络调参负担，网络更稳定

### Layer normalization
 
1. LN 的计算就是把每个 CHW 单独拿出来归一化处理，不受 batchsize 的影响
2. 常用在 RNN 网络，但如果输入的特征区别很大，那么就不建议使用它做归一化处理

### Instance Normalization
1. IN 的计算就是把每个 HW 单独拿出来归一化处理，不受通道和 batchsize 的影响
2. 常用在风格化迁移，但如果特征图可以用到通道之间的相关性，那么就不建议使用它做归一化处理

### Group Normalization

1. GN 的计算就是把先把通道 C 分成 G 组，然后把每个 gHW 单独拿出来归一化处理，最后把 G 组归一化之后的数据合并成 CHW
2. GN 介于 LN 和 IN 之间，当然可以说 LN 和 IN 就是 GN 的特列，比如 G 的大小为 1 或者为 C

### Switchable Normalization

1. 将 BN、LN、IN 结合，赋予权重，让网络自己去学习归一化层应该使用什么方法
2. 集万千宠爱于一身，但训练复杂

