# 三维视觉

在自动驾驶、机器人、数字城市以及虚拟/混合现实等应用的驱动下，三维视觉在近年来得到了广泛的关注。三维视觉研究主要围绕深度图像获取、视觉定位与制图、三维建模及三维理解等问题而展开。

## 整体框架

- 深度图像获取
  - 立体匹配
  - 单目深度估计
- 视觉定位与制图
  - 大场景下的视觉定位
  - 同步定位与地图构建
- 三维建模
  - 三维几何建模
  - 人体动态重建
- 三维理解
  - 点云语义理解

单目深度估计是通过单幅亮度图像和相关先验恢复深度信息的过程，这种深度信息通常表示为深度图，即以二维数组表示每个图像像素所对应的深度值。深度图是三维模型的主要表征形式之一，能够应用于自动驾驶 (Zhang 等，2019a;Liao 等，2020)、虚拟视频生成 (Wang 等，2020h;Zhu 等，2018c) 和增强现实等多个领域，具有重大的研究意义和应用价值。

双目立体视觉技术模仿人眼视觉系统对现实世界进行三维感知，通过两幅不同视角下的图像进行立体匹配获取视差/深度信息。相比于主动式感知技术（激光扫描、结构光扫描等）, 双目立体视觉技术具有设备简单、成本低和效率高的优势，因此双目立体匹配技术在数十年里一直是计算机视觉领域中的热点问题，并且获得了一系列的进展。目前双目立体视觉技术在实际中有着广泛的应用，包括智能机器人导航 (Schmid 等，2013)、目标识别 (Helmer 和 Lowe,2010)、遥感技术 (Shean 等，2016) 和自动驾驶 (Menze 和 Geiger,2015)。

相机定位是三维计算机视觉的一个基本问题，它的任务是根据相机拍摄的图像估计相机在某个坐标系下的位置和朝向，即相机的姿态。相机定位在诸多领域，如：机器人、自动驾驶、增强现实和虚拟现实等，都有重要的应用价值，也一直是三维计算机视觉中的一个核心问题。视觉定位分为 3D 模型已知的定位和 3D 模型未知的定位 (Wu 等，2018b)。本文大场景下的视觉定位部分阐述端到端的视觉定位和 3D 模型已知的视觉定位。同步定位与地图构建部分阐述模型未知的视觉定位。

同步定位与地图构建 (simultaneous localization and mapping, SLAM) 技术可以实时恢复移动设备的位姿，同时重建环境的三维信息，是增强现实、自动驾驶和移动机器人等应用领域中的关键技术 (Ca-dena 等，2016)。早期的移动定位主要依靠专用硬件设备来实现，随着带有摄像头的移动设备的普及以及其计算能力的提高，基于低成本视觉传感器和 IMU(inertial measurement unit) 的视觉惯性 SLAM 取得了重大突破，并已在一些产品上落地 (Qin 等，2018; Campos 等，2020)。随着传感器、网络和云计算的迅速发展，SLAM 应用的场景规模也在不断扩大 (Lynen 等，2015), 通过 SLAM 技术实现基于低成本传感器的城市级甚至地球级的移动定位将有望成为现实。

三维数字内容是虚拟仿真、混合现实等的基本构成要素。创建三维内容的核心是三维几何建模，它是计算机图形学的重要基本问题。人工三维建模操作困难、繁琐，严重依赖于专业人员的技能和经验，未经训练的普通用户往往难以胜任。如何让普通大众方便快捷地创作和编辑三维内容，实现所谓“大众建模”, 突破“三维内容生成瓶颈”, 从而推动三维数据的规模化增长，一直是图形学领域的一个核心目标和关键挑战。

点云语义分割是指根据点云内部的空间几何结构和形状信息将点云分成具有不同语义标签的点集，而实例分割要求进一步对点云场景中的不同实例进行区分。相比而言，点云实例分割既要将具有不同语义标签的点进行区分，还要区分具有相同语义标签的不同实例，因而相比点云语义分割更具挑战性。点云的语义分割和实例分割是实现三维场景理解的重要基础，在视觉导航与定位、自动驾驶和增强现实 (augmentedreality, AR)/虚拟现实 (virtual reality, VR) 等许多领域有广泛应用前景。

## 一、立体匹配

### 1.1 非端到端立体匹配

对于非端到端的立体匹配算法，卷积神经网络 (convolutional neural network, CNN) 通常用来代替传统匹配算法中的一部分或者多个部分。Žbontar 和 LeCun(2015) 首先使用卷积神经网络 MC-CNN 来计算匹配代价。这一深度孪生网络由数个卷积层与全连接层组成，用来计算两个图像分块之间的相似度。这一方法在当年的 KITTI(Karlsruhe Institute of Technology and Toyota Technological Institute at Chicago) 双目数据集上达到了最好的效果，证明了通过卷积神经网络提取到的图像特征比手工设计的特征算子更加准确。

受此启发，大量的立体视觉工作 (Gidaris 和 Komodakis,2017;Barron 和 Poole,2016;Brandao 等，2019;Kim 和 Kim,2016;Taniai 等，2018) 利用卷积神经网络来计算匹配代价。Zagoruyko 和 Komodakis(2015) 探索并提出了大量不同结构的卷积神经网络来表示两个图像分块之间的相似度测量函数并提升了最终效果。尽管这些方法 (Žbontar 和 LeCun,2015;Zagoruyko 和 Komodakis,2015) 在一些双目数据集上，比如 KITTI, 取得了巨大的进步，但是这些方法往往需要耗费非常多的计算资源且十分耗时。Luo 等人 (2016) 将立体匹配问题当做一个多类别的分类问题进行处理，使得模型可以通过学习在所有的候选视差值上的概率分布来隐性学习到不同视差下图像分块之间的差异。在这些方法中，通常会使用一些非学习的后处理技术来进一步优化通过神经网络得到的初始匹配代价，比如交叉特征聚合，半全局匹配和左右一致性检测、滤波等。

在传统立体视觉流程中除了匹配代价生成以外的部分也可以由神经网络取代。基于视差图局部平滑的假设，一些方法直接将平滑约束用在网络学习过程中。Seki 和 Pollefeys(2017) 提出了 SGM-Net(semi-globalmatchingwithneuralnetwork) 框架来预测传统 SGM 算法中的惩罚代价。其提出了一种新型的代价函数，包括路径惩罚项和相邻惩罚项，该新型代价函数使得神经网络可以充分利用到实际中采集到的稀疏视差图标签，比如通过激光雷达采集到的稀疏视差图。然而，为了获取 SGM 惩罚代价的标签值需要复杂的处理过程，因此使得训练 SGM-Net 非常复杂并且耗时。

Knöbelreiter 等人 (2017) 提出了一个神经网络和条件随机场结合的混合模型，并加入了平滑惩罚项。Gidaris 和 Komodakis(2017) 使用了一个三阶段的网络来取代手工设计的视差优化函数。这一网络可以检测不正确的视差估计值，使用新的估计值替代错误的，然后再次优化新的视差值。然而这一检测、替代和优化的步骤需要额外的计算资源。因为大多数的立体匹配技术在反射和无纹理表面很难通过局部约束正确恢复出视差值。Güney 和 Geiger(2015) 提出了 Displets 模型，利用物体的先验信息来解决反射和无纹理表面上视差估计的不确定性问题。该方法通过引入汽车的三维模型作为先验信息，其取得了当年 KITTI 双目视差估计数据集上的第 1 名。然而，引入三维模型极大增加了模型的计算负担。

这些非端到端的估计方法，相比传统方法有较大的效果提升，但其或多或少都依赖于手工设计的约束方程和后处理步骤来实现较好的结果。这些方法的效果受制于较高的计算负担、有限的感受野和缺乏图像全局信息等问题，逐渐被端到端的立体视觉方法所替代。

### 1.2 端到端立体匹配

端到端的视差估计网络可以无缝地结合立体视觉流程中的所有步骤，可以直接从双目图像中估计出完整且稠密的视差图。自从 Mayer 等人 (2016) 首先提出了端到端的视差估计网络，大量的后续工作都采用了这一结构并取得了优异的结果。一般而言，视差估计网络的结构可以分为两类：

1. 二维卷积层组成的编码器—解码器的层级优化结构；
2. 三维卷积层组成的正则化网络结构。

一般而言，二维卷积网络的运行速度更快，而三维卷积网络的预测精度更高。

Mayer 等人 (2016) 首先提出了一个光流和视差联合估计的网络。对于视差估计，该网络使用一维的相关性估计层沿着视差扫描线方向进行匹配代价计算，然后使用编码器—解码器的网络进行视差回归。这一端到端的网络结构使得完整视差图的估计过程变得简单，并且可以节省大量计算资源。Dispnet 与其拓展工作使用二维卷积网络对获取的匹配代价进行正则化与优化，再对视差值进行回归。Kendall 等人 (2017) 提出了 GC-Net(globalcontextnetwork), 首先使用三维卷积网络对匹配代价进行聚合，并取得了当时最先进的结果。GC-Net 的成功证明了三维卷积网络在匹配代价的聚合与正则化上，相对二维卷积网络有更好的泛化能力和更高的精度。由于额外的视差维度的引入，使用三维卷积网络的代价聚合过程更加规则化，有利于视差维度上不同体素之间的聚合。

然而，基于学习的视差估计网络往往在无纹理或弱纹理的区域表现较差。一些方法基于 Kusupati 等人 (2020) 提出的局部平面的先验假设，引入了额外的法线向量约束 (normalconstraint), 使得视差/深度估计网络在无纹理区域也能有合理的估计值。Poggi 和 Mattoccia(2017) 提出了一个置信度估计网络来衡量估计的视差值的可信度。Kim 等人 (2018) 也使用卷积神经网络来联合估计视差值以及其对应的置信度。Badki 等人 (2020) 将立体匹配问题重构为一个二值分类 (binaryclassification) 问题而不是直接回归视差值。

目前，端到端的立体匹配算法已经取代了非端到端的立体匹配算法成为主流。尽管端到端的立体匹配算法能够同时结合局部信息与图像的全局信息进行视差估计，但是这些算法依旧很难在无纹理区域、物体边缘和细小结构上取得令人满意的效果。另一方面，采用三维卷积网络的立体匹配算法需要占用巨量的 GPU(graphicsprocessingunit) 资源，限制了其在实际中的使用价值。近年来，一些算法试图改善这些情况，比如 Guo 等人 (2019) 使用群卷积来减少代价体的特征通道数，Lu 等人 (2018) 使用稀疏代价体替代稠密代价体，Gu 等人 (2020) 使用级联多代价体代替完整单一代价体。但是这些算法依旧依赖于三维卷积网络，因此高 GPU 显存消耗的问题并没有得到明显改善。同时，为了使得网络具有较好的性能与泛化性，这类端到端的立体匹配网络需要大量的视差/深度标签进行训练，但获得大量标签是非常昂贵的。