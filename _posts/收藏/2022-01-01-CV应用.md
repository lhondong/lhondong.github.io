---
title: "深度学习在计算机视觉领域的应用一览"
subtitle: "深度学习在 CV 的应用"
layout: post
author: "L Hondong"
header-img: "img/post-bg-5.jpg"
tags:
  - CV
---

收藏自知乎[深度学习在计算机视觉领域（包括图像，视频，3-D 点云，深度图）的应用一览](https://zhuanlan.zhihu.com/p/55747295)，黄浴老师对 CV 应用全领域的总结，目前我所读过的最全的 CV 应用综述，每次读都有新的感悟，常读常新。

引用黄浴老师的话：

> 在工业界和学术界都待过，工业界也待过多个领域，做的项目范围比较宽，深度学习之后，平时也就在有过经历的方向上注意进展。有自己的知识架构，可以不时地往里面填内容。

# 深度学习在计算机视觉领域（包括图像，视频，3-D 点云，深度图）的应用一览

[原文](https://zhuanlan.zhihu.com/p/55747295)

计算机视觉不是深度学习最早看到突破的领域，真正让大家大吃一惊的颠覆传统方法的应用领域是语音识别，做出来的公司是微软，而不是当时如日中天的谷歌。计算机视觉应用深度学习堪称突破的成功点是 2012 年 ImageNet 比赛，采用的模型是 CNN，而不是 Hinton 搞的 RBM 和 DBN 之类，就是 Hinton 学生做出来以他命名的 AlexNet。

（注：顺便提一下，2010 年的 ImageNet 冠军是余凯/林元庆领导的 NEC 和 UIUC Tom Huang 组的合作团队，当时采用的方法是基于 sparse coding+SVM。）

当然，真正一直在研究 CNN 的专家是 Yann LeCun，小扎后来拉他去 FB 做 AI research 的头。第一个 CNN 模型就是他搞出来的，即 LeNet，原来就是做图像数字识别。不得不说，CNN 非常适合 2-D 信号的处理任务，RNN 呢，是时域上的拓展。

现在 CNN 在计算机视觉应用的非常成功，传统机器学习方法基本被弃之不用。其中最大的一个原因就是，图像数据的特征设计，即特征描述，一直是计算机视觉头痛的问题，在深度学习突破之前 10 多年，最成功的图像特征设计 (hand crafted feature) 是 SIFT，还有著名的 Bag of visual words，一种 VQ 方法。后来大家把 CNN 模型和 SIFT 比较，发现结构还蛮像的：），之后不是也有文章说 RNN 和 CRF 很像吗。

CNN 从 AlexNet 之后，新模型如雨后春笋，每半年就有新发现。这里随便列出来就是，ZFNet （也叫 MatNet)，VGGNet， NIN， GoogleNet (Inception)， Highway Network， ResNet， DenseNet，SE-Net（Squeeze and Excitation Net），基本上都是在 ImageNet 先出名的：）。

简单回顾一下：

- AlexNet 应该算第一个深度 CNN；
- ZFNet 采用 DeconvNet 和 visualization 技术可以监控学习过程；
- VGGNet 采用小滤波器 3X3 去取代大滤波器 5X5 和 7X7 而降低计算复杂度；
- GoogleNet 推广 NIN 的思路定义 Inception 基本模块（采用多尺度变换和不同大小滤波器组合，即 1X1，3X3，5X5）构建模型；
- Highway Networks 借鉴了 RNN 里面 LSTM 的 gaiting 单元；
- ResNet 是革命性的工作，借鉴了 Highway Networks 的 skip connection 想法，可以训练大深度的模型提升性能，计算复杂度变小；
- Inception-V3/4 用 1X7 和 1X5 取代大滤波器 5X5 和 7X7，1X1 滤波器做之前的特征瓶颈，这样卷积操作变成像跨通道（cross channel）的相关操作；
- DenseNet 主要通过跨层链接解决 vanishing gradient 问题；
- SE-Net 是针对特征选择的设计，gating 机制还是被采用；
- 前段时间流行的 Attention 机制也是借鉴于 LSTM，实现 object-aware 的 context 模型。

在具体应用领域也出现了不少成功的模型，比如
- detection 问题的 R-CNN，fast RCNN，faster RCNN，SSD，YOLO，RetinaNet，CornerNet 等，
- 解决 segmentation 问题的 FCN，DeepLab，Parsenet，Segnet，Mask R-CNN，RefineNet，PSPNet，U-Net 等，
- 处理激光雷达点云数据的 VoxelNet，PointNet，BirdNet，LMNet，RT3D，PIXOR，YOLO3D 等，
- 实现激光雷达和图像融合的 PointFusion，RoarNet，PointRCNN，AVOD 等，
- 做图像处理的 DeHazeNet，SRCNN (super-resolution)，DeepContour，DeepEdge 等，
- 2.5 D 视觉的 MatchNet，DeepFlow，FlowNet 等，
- 3-D 重建的 PoseNet，VINet，Perspective Transformer Net，SfMNet，CNN-SLAM，SurfaceNet，3D-R2N2，MVSNet 等，
- 以及解决模型压缩精简的 MobileNet，ShuffleNet，EffNet，SqueezeNet，

## 一、图像/视频处理

先说图像/视频处理（计算机视觉的底层，不低级）。

图像处理，还有视频处理，曾经是很多工业产品的基础，现在电视，手机还有相机/摄像头等等都离不开，是技术慢慢成熟了（传统方法），经验变得比较重要，而且芯片集成度越来越高，基本上再去研究的人就少了。经典的 ISP，A3，都是现成的，当然做不好的也很难和别人竞争，成本都降不下来。

这是一个典型成像处理的流程图：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-19-53-50.png" alt="CV应用-2022-01-11-19-53-50" style="zoom:50%;" /></div>

经典的 ISP 流程图如下：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-19-55-17.png" alt="CV应用-2022-01-11-19-55-17" style="zoom:50%;" /></div>

图像处理，根本上讲是基于一定假设条件下的信号重建。这个重建不是我们说的 3-D 重建，是指恢复信号的原始信息，比如去噪声，内插。这本身是一个逆问题，所以没有约束或者假设条件是无解的，比如去噪最常见的假设就是高斯噪声，内插实际是恢复高频信号，可以假设边缘连续性和灰度相关性，著名的 TV（total variation）等等。

以前最成功的方法基本是信号处理，机器学习也有过，信号处理的约束条件变成了贝叶斯规则的先验知识，比如 sparse coding/dictionary learning，MRF/CRF 之类，现在从传统机器学习方法过渡到深度学习也正常吧。

### 1. 去噪/去雾/去模糊/去鬼影

先给出一个 encoder-decoder network 的 AR-CNN 模型（AR=Artifact Reduction）：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-19-56-23.png" alt="CV应用-2022-01-11-19-56-23" style="zoom:30%;" /></div>

这是一个图像处理通用型的模型框架：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-19-57-10.png" alt="CV应用-2022-01-11-19-57-10" style="zoom:50%;" /></div>

### 2. 增强/超分辨率（SR）

Bilateral filter 是很有名的图像滤波器，这里先给出一个受此启发的 CNN 模型做图像增强的例子：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-19-58-41.png" alt="CV应用-2022-01-11-19-58-41" style="zoom:50%;" /></div>

前面说过内插的目的是恢复失去的高频信息，这里一个做 SR 的模型就是在学习图像的高频分量：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-19-59-42.png" alt="CV应用-2022-01-11-19-59-42" style="zoom:50%;" /></div>

### 3. 修补/恢复/着色

用于修补的基于 GAN 思想的 Encoder-Decoder Network 模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-00-14.png" alt="CV应用-2022-01-11-20-00-14" style="zoom:50%;" /></div>

用于灰度图像着色（8 比特的灰度空间扩展到 24 比特的 RGB 空间）的模型框架：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-00-58.png" alt="CV应用-2022-01-11-20-00-58" style="zoom:50%;" /></div>

## 二、计算机视觉的预处理（2-D）

计算机视觉需要图像预处理，比如特征提取，包括特征点，边缘和轮廓之类。以前做跟踪和三维重建，首先就得提取特征。特征点以前成功的就是 SIFT/SURF/FAST 之类，现在完全可以通过 CNN 形成的特征图来定义。

边缘和轮廓的提取是一个非常 tricky 的工作，细节也许就会被过强的图像线条掩盖，纹理（texture）本身就是一种很弱的边缘分布模式，分级（hierarchical）表示是常用的方法，俗称尺度空间（scale space）。以前做移动端的视觉平台，有时候不得不把一些图像处理功能关掉，原因是造成了特征畸变。现在 CNN 这种天然的特征描述机制，给图像预处理提供了不错的工具，它能将图像处理和视觉预处理合二为一。

### 1. 特征提取

LIFT（Learned Invariant Feature Transform）模型，就是在模仿 SIFT：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-02-08.png" alt="CV应用-2022-01-11-20-02-08" style="zoom:50%;" /></div>

### 2. 边缘/轮廓提取

一个轮廓检测的 encoder-decoder network 模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-02-25.png" alt="CV应用-2022-01-11-20-02-25" style="zoom:50%;" /></div>

### 3. 特征匹配

这里给出一个做匹配的模型 MatchNet：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-02-52.png" alt="CV应用-2022-01-11-20-02-52" style="zoom:30%;" /></div>

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-06-56.png" alt="CV应用-2022-01-11-20-06-56" style="zoom:30%;" /></div>

## 三、2.5-D 计算机视觉部分（不是全 3-D）

涉及到视差或者 2-D 运动的部分一般称为 2.5-D 空间。这个部分和前面的 2-D 问题是一样的，作为重建任务它也是逆问题，需要约束条件求解优化解，比如 TV，GraphCut。一段时间（特别是 Marr 时代）计算机视觉的工作，就是解决约束条件下的优化问题。

后来，随机概率和贝叶斯估计大行其事，约束条件变成了先验知识（prior），计算机视觉圈里写文章要是没有 P (Probability) 和 B (Bayes)，都不好意思发。像 SVM， Boosting，Graphical Model，Random Forest，BP（Belief Propagation），CRF（Conditional Random Field），Mixture of Gaussians，MCMC，Sparse Coding 都曾经是计算机视觉的宠儿，现在轮到 CNN 出彩：）。

可以说深度学习是相当“暴力”的，以前分析的什么约束呀，先验知识呀在这里统统扔一边，只要有图像数据就可以和传统机器学习方法拼一把。

### 1. 运动/光流估计

传统的方法包括局部法和全局法，这里 CNN 取代的就是全局法。
这里是一个光流估计的模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-07-31.png" alt="CV应用-2022-01-11-20-07-31" style="zoom:50%;" /></div>

### 2. 视差/深度图估计

深度图估计和运动估计是类似问题，唯一不同的是单目可以估计深度图，而运动不行。
这里是一个双目估计深度图的模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-08-24.png" alt="CV应用-2022-01-11-20-08-24" style="zoom:50%;" /></div>

而这个是单目估计深度图的模型：巧妙的是这里利用双目数据做深度图估计的非监督学习

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-09-08.png" alt="CV应用-2022-01-11-20-09-08" style="zoom:30%;" /></div>

另外一个单目深度估计的模型：也是利用双目的几何约束做非监督的学习

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-09-58.png" alt="CV应用-2022-01-11-20-09-58" style="zoom:50%;" /></div>

### 3. 视频去隔行/内插帧

Deinterlacing 和 Framerate upconversion 视频处理的经典问题，当年 Sony 和 Samsung 这些电视生产商这方面下了很大功夫，著名的 NXP（从 Philips 公司 spin-off）当年有个牛逼的算法在这个模块挣了不少钱。
基本传统方法都是采用运动估计和补偿的方法，俗称 MEMC，所以我把它归类为 2.5-D。前面运动估计已经用深度学习求解了，现在这两个问题自然也是。
首先看一个做 MEMC 的模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-11-15.png" alt="CV应用-2022-01-11-20-11-15" style="zoom:50%;" /></div>

这是做 Deinterlacing 的一个模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-11-37.png" alt="CV应用-2022-01-11-20-11-37" style="zoom:50%;" /></div>

这是 Nvidia 的 Framerate Upconversion 方面模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-12-08.png" alt="CV应用-2022-01-11-20-12-08" style="zoom:50%;" /></div>

因为它采用 optic flow 方法做插帧，另外附上它的 flow estimation 模型：就是一个沙漏（hourglass）模式

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-12-43.png" alt="CV应用-2022-01-11-20-12-43" style="zoom:30%;" /></div>

### 4. 新视角图像生成

刚才介绍单目估计深度图的时候，其实已经看到采用 Inverse warping 方法做新视角生成的例子，在 IBR 领域这里有一个分支叫 Depth Image-based Rendering （DIBR）。

和上个问题类似，采用深度图学习做合成图像，也属于 2.5-D 空间。在电视领域，曾经在 3-D 电视界采用这种方法自动从单镜头视频生成立体镜头节目。以前也用过机器学习，YouTube 当年采用 image search 方法做深度图预测提供 2D-3D 的内容服务，但性能不好。现在感觉，大家好像不太热衷这个了。

这是一个产生新视角的模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-13-59.png" alt="CV应用-2022-01-11-20-13-59" style="zoom:50%;" /></div>

而这个是从单镜头视频生成立体视频的模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-14-14.png" alt="CV应用-2022-01-11-20-14-14" style="zoom:50%;" /></div>

有做编码/解码的，也是采用运动或者相似变换为基础，但性能不如传统方法，这里忽略。

## 四、3-D 计算机视觉

下面谈谈 3-D，基于多视角（MVS）/运动（SFM）的重建，后者也叫 SLAM。

这部分就是经典的计算机视觉问题：3-D 重建。

基本上可以分成两种路径：一是多视角重建，二是运动重建。前一个有一个经典的方法 MVS（multiple view stereo），就是多帧匹配，是双目匹配的推广，这样采用 CNN 来解决也合理。当年 CMU 在 Superbowl 展示的三维重建和视角转化，轰动一时，就是基于此路径，但最终没有被产品化（技术已经转让了）。

后一个在机器人领域成为 SLAM，有滤波法和关键帧法两种，后者精度高，在稀疏特征点的基础上可以采用 BA（Bundle Adjustment），著名的方法如 PTAM，ORB-SLAM1/2，LSD-SLAM，KinectFusion（RGB-D），LOAM 和 Velodyne SLAM（LiDAR）等。如今 SLAM 已经成为 AR 产业的瓶颈，看看 MagicLeap 和 HoloLens，大家不能总是在平面检测基础上安一个虚拟物体吧，真正的虚实结合是在一个普通的真实环境里才行。

想想像特征点匹配，帧间运动估计，Loop Closure 检测这些模块都可以采用 CNN 模型解决，那么 SLAM/SFM/VO 就进入 CNN 的探索区域。

### 1. 标定

Calibration 是计算机视觉的经典问题，摄像头作为传感器的视觉系统首要任务就是要确定自己观测数据和 3-D 世界坐标系的关系，即标定。摄像头标定要确定两部分参数，一是内参数，二是外参数。对于有多个传感器的视觉系统，比如深度测距仪，以前有 Kinect RGB-D，现在有 Velodyne 激光雷达，它们相互之间的坐标系关系是标定的任务。

外参数标定的完成帮助是校准数据，比如激光雷达的点云，RGB-D 的深度图，还有摄像头的图像像素集，它们一定存在一个最佳匹配标准，这就可以通过数据训练 NN 模型来完成。而标定参数就是 NN 模型回归输出的结果。

这里是一个激光雷达和摄像头标定的系统框图：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-15-03.png" alt="CV应用-2022-01-11-20-15-03" style="zoom:50%;" /></div>

它的模型 CalibNet 结构视图：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-15-50.png" alt="CV应用-2022-01-11-20-15-50" style="zoom:50%;" /></div>

### 2. Visual Odometry（VO）

VO 属于 SLAM 的一部分，只是估计自身运动和姿态变化吧。VO 是特斯拉的前 Autopilot2.0 负责人 David Nister 创立的，他之前以两帧图像计算 Essential Matrix 的“5 点算法”而出名，现在是 Nvidia 的自动驾驶负责人，公司 VP。

这里是一个和惯导数据结合的 VIO（Visual-Inertial Odometry）NN 模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-16-11.png" alt="CV应用-2022-01-11-20-16-11" style="zoom:50%;" /></div>

这是著名的 AR 创业公司 MagicLeap 提出的 VO 模型：两部分组成，即特征提取和匹配（Homography）。

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-16-46.png" alt="CV应用-2022-01-11-20-16-46" style="zoom:50%;" /></div>

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-16-59.png" alt="CV应用-2022-01-11-20-16-59" style="zoom:50%;" /></div>

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-17-24.png" alt="CV应用-2022-01-11-20-17-24" style="zoom:50%;" /></div>

顺便加一个，激光雷达数据做 Odometry 的 CNN 模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-17-43.png" alt="CV应用-2022-01-11-20-17-43" style="zoom:50%;" /></div>

### 3. SLAM (Mono, Stereo, RGB-D, LiDAR)/SFM

运动恢复结构是基于背景不动的前提，计算机视觉的同行喜欢 SFM 这个术语，而机器人的 peers 称之为 SLAM。SLAM 比较看重工程化的解决方案，SFM 理论上贡献大。

先看一个单摄像头的 SFM 系统框图：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-17-57.png" alt="CV应用-2022-01-11-20-17-57" style="zoom:30%;" /></div>

它的 NN 模型 SFM-Net，包括 Motion 和 Structure 两部分：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-19-02.png" alt="CV应用-2022-01-11-20-19-02" style="zoom:50%;" /></div>

再附上一个 SLAM 的模型 CNN-SLAM：主要是加上一个单目深度图估计的 CNN 模块。

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-19-25.png" alt="CV应用-2022-01-11-20-19-25" style="zoom:50%;" /></div>

这是一个用 CNN 的基于 Lidar 的 localization 方法：不仅需要点云数据，还输入反射值灰度图。

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-19-40.png" alt="CV应用-2022-01-11-20-19-40" style="zoom:50%;" /></div>

图像像素运动是 Optic flow，而 3-D 场景的运动称之为 Scene flow，如果有激光雷达的点云数据，后者的估计可以通过 ICP 实现，这里给出一个 CNN 模型的实现方法 FlowNet3D，是 PointNet 的扩展：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-20-08.png" alt="CV应用-2022-01-11-20-20-08" style="zoom:50%;" /></div>

### 4. MVS

MVS 的传统方法可以分成两种：region growing 和 depth-fusion，前者有著名的 PMVS，后者有 KinectFusion，CNN 模型求解 MVS 的方法就是基于此。

先看看一个做 MVS 任务的基于 RNN 中 LSTM 的 3D-R2N2 模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-20-18.png" alt="CV应用-2022-01-11-20-20-18" style="zoom:50%;" /></div>

它的系统框图如下：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-21-09.png" alt="CV应用-2022-01-11-20-21-09" style="zoom:30%;" /></div>

UIUC/Facebook 合作的 DeepMVS 模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-21-46.png" alt="CV应用-2022-01-11-20-21-46" style="zoom:50%;" /></div>

这是他们的系统框图：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-21-53.png" alt="CV应用-2022-01-11-20-21-53" style="zoom:50%;" /></div>

现在看到的是 Berkeley 分校 Malik 组提出的 LSM（Learnt Stereo Machine）模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-22-09.png" alt="CV应用-2022-01-11-20-22-09" style="zoom:50%;" /></div>

下面是最近香港权龙教授组提出的 MVSNet 模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-22-46.png" alt="CV应用-2022-01-11-20-22-46" style="zoom:50%;" /></div>

## 五、计算机视觉核心：环境理解

核心部分是计算机视觉的高层：环境理解。

这部分是深度学习在计算机视觉最先触及，并展示强大实力的部分。出色的工作太多，是大家关注和追捧的，而且有不少分析和总结文章，所以这里不会重复过多，只简单回顾一下。

### 1. 语义分割/实例分割（Semantic/Instance Segmentation）

语义分割最早成功应用 CNN 的模型应该是 FCN（Fully Convolution Network），由 Berkeley 分校的研究人员提出。它是一种 pixel2pixel 的学习方法，之后各种演变模型，现在都可以把它们归类于 Encoder-Decoder Network。

这里是去年 CVPR 的一篇论文在总结自动驾驶的实时语义分割算法时给出的框图：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-23-08.png" alt="CV应用-2022-01-11-20-23-08" style="zoom:50%;" /></div>

其中 Encoder 部分特别采用了 MobileNet 和 ShuffleNet。

实例分割是特殊的语义分割，结合了目标检测，可以说是带有明确轮廓的目标检测，其代表作就是 Mask R-CNN，应该是何凯明去 FB 之后的第一个杰作。

这是一个借鉴目标检测算法 SSD 的实例分割模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-23-33.png" alt="CV应用-2022-01-11-20-23-33" style="zoom:50%;" /></div>

而下面这个是从目标检测算法 Faster-RCNN 演变的实例分割模型 MaskLab，论文发表在去年 CVPR‘18：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-23-51.png" alt="CV应用-2022-01-11-20-23-51" style="zoom:50%;" /></div>

这是它修正 Mask 的方法示意图：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-24-00.png" alt="CV应用-2022-01-11-20-24-00" style="zoom:50%;" /></div>

这是一个基于 3-D 点云的语义分割 NN 模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-24-11.png" alt="CV应用-2022-01-11-20-24-11" style="zoom:50%;" /></div>

### 2. 检测/识别（特别例子：人脸）

目标检测的开拓性工作应该是 Berkeley 分校 Malik 组出来的，即两步法的 R-CNN（Region-based CNN），借用了传统方法中的 Region Proposal。之后不断改进的有 fast RCNN 和 faster RCNN，每次都有新点子，真是“群星闪耀”的感觉。

一步法的工作，有名的就是 SSD（Single Shot Detection）和 YOLO（You Only Look Once)，期间何凯明针对 one-stage 和 two-stage 方法的各自优缺点引进一个 Focal Loss，构建的新方法叫 RetinaNet，而后来 YOLO3 基本也解决了精度低的弱点。

这里我画了一个算法发展草图（其实还有一些方法没有包括在里面，比如 densebox，deepbox，R-FCN，FPN 等等）。

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-24-26.png" alt="CV应用-2022-01-11-20-24-26" style="zoom:50%;" /></div>

ImageNet 本身就是一个 1000 多种物体识别比赛，一般公布的是 top 5 的结果（可见最早精度有多低）。CNN 在 ImageNet 的发展史，就是它在图像识别的一段近 5 年的历史了：）。

激光雷达点云数据的处理，无论识别还是分割，有 PointNet 以及改进的 CNN 模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-25-07.png" alt="CV应用-2022-01-11-20-25-07" style="zoom:50%;" /></div>

基于点云做目标识别的例子有 Apple 公司研究人员发表的 VoxelNet 模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-25-15.png" alt="CV应用-2022-01-11-20-25-15" style="zoom:50%;" /></div>

将点云和 RGB 图像结合的目标检测 CNN 模型例子如下：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-25-41.png" alt="CV应用-2022-01-11-20-25-41" style="zoom:50%;" /></div>

这里顺便提一下人脸识别，因为是对人脸的个体属性判别，所以这个课题应该算 fine grained recognition。就好像对狗或者马这种动物继续判别它的品种，都是细分的。

请注意，人脸识别分人脸验证（face verification）和人脸确认（face identification）；前者是指两个人是不是同一个人，1-to-1 mapping，而后者是确定一个人是一群人中的某个，1-to-many ampping。以前经常有报道机器的人脸识别比人强了，都是指前者，假如后者的话，那谁能像机器一样识别上万人的人脸数据库呢？何况中国公安部的数据高达亿的数量级。

一个完整的人脸识别系统，需要完成人脸检测和人脸校准（face alignment），而后者是需要人脸关键点（facial landmarks）的检测，也是可以基于 CNN 模型来做。这里以 FB 的 DeepFace 模型为例吧，给出一个人脸识别的系统框图：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-26-09.png" alt="CV应用-2022-01-11-20-26-09" style="zoom:50%;" /></div>

这是不久前刚刚提出的人脸检测模型：Selective Refinement Network

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-26-24.png" alt="CV应用-2022-01-11-20-26-24" style="zoom:50%;" /></div>

而这里给出一个基于 facial landmarks 做校准的模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-27-52.png" alt="CV应用-2022-01-11-20-27-52" style="zoom:50%;" /></div>

顺便提一下旷世科技的 Pyramid CNN 模型和商汤科技的 DeepID2 模型（一共发布过 4 个 DeepID 版本）依次如图：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-28-05.png" alt="CV应用-2022-01-11-20-28-05" style="zoom:50%;" /></div>

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-28-18.png" alt="CV应用-2022-01-11-20-28-18" style="zoom:50%;" /></div>

### 3. 跟踪（特别例子：人体姿态/骨架）

目标跟踪是一个递推估计问题，根据以前的图像帧目标的信息推算当前目标的位置甚至大小/姿态。有一阵子，跟踪和检测变得浑为一体，即所谓 tracking by detection，跟踪也可以看出一个目标分割（前后景而言）/识别问题。

跟踪是短时（short term）邻域的检测，而一般的检测是长时（long term）大范围的检测。跟踪的困难在于目标的遮挡（分部分还是全部），背景复杂（相似目标存在），快速（fast）以及突变（agile）运动等等。比如，跟踪人脸，当转 90 度成侧脸时就会有以上这些问题。

跟踪方法有一个需要区分的点，多目标（MOT）还是单目标（SOT）跟踪器。单目标不会考虑目标之间的干扰和耦合，而多目标跟踪会考虑目标的出现，消失以及相互交互和制约，保证跟踪各个目标的唯一性是算法设计的前提。

跟踪目标是多样的，一般是考虑刚体还是柔体，是考虑单刚体还是铰接式（articulated），比如人体或者手指运动，需要确定 skeleton 模型。跟踪可以是基于图像的，或者激光雷达点云的，前者还要考虑目标在图像中大小的变化，姿态的变化，难度更大。

基于以上特点，跟踪可以用 CNN 或者 RNN 模型求解，跟踪目标的描述本身就是 NN 模型的优势，检测也罢，分割或者识别也罢，都不是问题。运动特性的描述也可以借鉴 RNN 模型，不过目前看到的结果这部分不比传统方法好多少。

先看一个单目标跟踪的 CNN 模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-29-14.png" alt="CV应用-2022-01-11-20-29-14" style="zoom:50%;" /></div>

这个展示的模型是一个基于 R-CNN 检测模型扩展的单目标跟踪方法：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-29-22.png" alt="CV应用-2022-01-11-20-29-22" style="zoom:50%;" /></div>

多目标跟踪模型有这么一个例子：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-29-54.png" alt="CV应用-2022-01-11-20-29-54" style="zoom:50%;" /></div>

下面是一个基于 RNN 的多目标跟踪模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-30-03.png" alt="CV应用-2022-01-11-20-30-03" style="zoom:50%;" /></div>

补充一个基于 RGB 图像和 3-D 点云的目标跟踪 NN 模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-30-13.png" alt="CV应用-2022-01-11-20-30-13" style="zoom:50%;" /></div>

顺便谈一下人体姿态和骨架跟踪问题。以前传统方法在人体姿态估计花了很大力气但效果不好，提出了 part-based 目标模型，比如 constellation model, pictorial structure, implicit shape model, deformable model 等等。

最近 CMU 提出一个方法，基于 Part Affinity Fields（PAF）来估计人体姿态和骨架，速度非常快。PAF 是一个非参数描述模型，用来将图像像素和人体各肢体相关起来，看它的架构如图，采用的是 two branch CNN 结构，联合学习各肢体的相关性和位置。

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-30-24.png" alt="CV应用-2022-01-11-20-30-24" style="zoom:50%;" /></div>

下面这个是其中双部图形匹配 (Bipartie matching) 算法的示意图。

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-31-36.png" alt="CV应用-2022-01-11-20-31-36" style="zoom:50%;" /></div>

这种多目标快速姿态跟踪的实现对人体行为的理解是非常重要的工具。

## 六、计算机视觉的推广

最后讲一下计算机视觉的推广领域，这里我选了 4 个计算机视觉的应用谈谈深度学习对这些领域的推动，在 CNN 或者 RNN“火”之前，这些应用已经存在，但在识别分类任务上性能有限罢了。自动驾驶的应用在另外文章已经提过了，在此忽略。

### 1. 内容检索

CBIR（Content-based Image Retrieval）有两波人搞，一波是计算机科学的，把这个问题当数据库看待；另一波人是电子过程的，认为是图像匹配问题。刚开始大家也是对这个问题的 semantic gap 比较头疼，用了一些 feature，比如颜色，纹理，轮廓，甚至 layout，效果真不咋样。

后来有了 SIFT，用了 Information Retrieval 的概念 Bag of Words，加上 inverted Indexing，TF-IDF（term frequency–inverse document frequency），hashing 之类的技术变得好多了，每年 ACM MM 会议上一堆的 paper。深度学习进来，主要就是扮演特征描述的角色。

这是一个 CBIR 采用 CNN 的框架：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-32-23.png" alt="CV应用-2022-01-11-20-32-23" style="zoom:50%;" /></div>

这个展示的是 image matching 用于 CBIR 的 CNN 模型：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-34-23.png" alt="CV应用-2022-01-11-20-34-23" style="zoom:50%;" /></div>

### 2. 增强现实

AR 一开始就不好做，不说 VR 那部分的问题，主要是实时性要求高，无论识别还是运动/姿态估计，精度都不好。现在计算机硬件发展了，计算速度提高了，加上深度学习让识别变得落地容易了，最近越来越热，无论是姿态估计还是特征匹配（定位），都变得容易些了。希望这次能真正对社会带来冲击，把那些 AR 的梦想都实现。

这个框架是 Google Glass 的 AR 应用平台，其中几个模块都可以基于 CNN 实现：

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-34-49.png" alt="CV应用-2022-01-11-20-34-49" style="zoom:50%;" /></div>

下面给出的是 camera motion 的 encoder-decoder network 框架：三个模型串联，其中一个有迭代。

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-34-58.png" alt="CV应用-2022-01-11-20-34-58" style="zoom:50%;" /></div>

下面的模型展示了特征提取和描述的作用，AR 中直接可以用做 re-localization。

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-35-07.png" alt="CV应用-2022-01-11-20-35-07" style="zoom:50%;" /></div>

### 3. 内容加注/描述

Captioning 是计算机视觉和 NLP 的结合。你可以把它当成一个“检索”任务，也可以说是一个“翻译”工作。深度学习，就是来帮助建立一个语言模型并取样产生描述。

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-35-17.png" alt="CV应用-2022-01-11-20-35-17" style="zoom:50%;" /></div>

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-35-33.png" alt="CV应用-2022-01-11-20-35-33" style="zoom:50%;" /></div>

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-35-46.png" alt="CV应用-2022-01-11-20-35-46" style="zoom:50%;" /></div>

### 4. 内容问答（Q&A）

Q&A 也是计算机视觉和 NLP 的结合，其实质是在图像描述和语言描述之间建立一个桥梁。有人说，Q&A 是一个 Turing Test 的好问题，这里深度学习就是在帮助理解图像的描述，问题的组成，以及它们模式之间的交互。

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-36-05.png" alt="CV应用-2022-01-11-20-36-05" style="zoom:50%;" /></div>

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-36-18.png" alt="CV应用-2022-01-11-20-36-18" style="zoom:50%;" /></div>

<div align=center><img src="https://cdn.jsdelivr.net/gh/lhondong/Assets/Images/CV应用-2022-01-11-20-36-25.png" alt="CV应用-2022-01-11-20-36-25" style="zoom:50%;" /></div>

有些 CNN 的应用还是需要进一步改进模型，性能并没有达到满意。不过，大家高兴地看到深度学习已经进来了，以后随着研究的深入性能会越来越好。
