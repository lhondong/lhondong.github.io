# Elf: accelerate high-resolution mobile deep vision with content-aware parallel offloading

用一个神经网络识别视频中的重点区域，从而将高分辨率图像中的内容切分出来分给多个服务器并行识别。

使用LSTM+注意力机制预测目标可能存在的位置，将两帧间大小和位置变化不大的帧标记为同一目标，定期给服务器发低清帧识别新出现的目标，使用历史数据估计服务器的资源余量，按照服务器数量和资源余量将目标块打包发给服务器识别。

### 低清图有损识别精度

一张高清图很大，传给服务器识别耗带宽，本地识别耗算力，模型内部的计算输入和输出都是图，分布式传输占大带宽，最好是服务器直接传回识别结果，一张图直接平均切容易把目标切半导致识别不出来，本文首次提出了一个能将一个图按照内容切成几个图进行分布式识别的方法。

- 怎么识别重点区域
- 怎么切重点区域保证覆盖住要识别的对象
- 怎么按照服务器可用资源把重点区域打包识别

## 为提升推断速度做出的努力

- 模型裁剪
  - 量化神经网络 QNN
  - 知识蒸馏
  - 网络架构搜索
  - 缺点：精度下降
- 硬件研究
  - GPU
  - FPGA
  - ASIC
  - 缺点：能耗高
- 服务器推断
  - AWS Wavelength 用 5G 把图像发到附件的服务器推断
  - 缺点：网速只够发低清图
  - 缺点：单个服务器资源无限，没考虑多用户多服务器优化
  - 缺点：没有 GPU 共享，浪费计算时间

## 应用领域

- 专注于使用现有 CNN 模型的应用
- 专注于高分辨率多目标识别应用

## 本文方案

将推断任务切成多个小片发给多个服务器同时计算：

1. 一个 CNN 切出图像的重点区域，每个区域包含一个目标
2. 一个 CNN 对切分出的目标进行识别

## 设计要点

1. 如何切分计算？
   - 模型并行：以模型中的层为单位进行并行计算（传输量大、同步复杂）
   - 数据并行：以图像中的部分为单位进行并行计算（智能切分）
2. 如何分配计算？
   - 依据：图中待识别对象数量、识别对象的资源需求、服务器的资源余量
   - 调整：卸载策略
   - 最小化：计算时间、客户端负载

## 挑战和解决方案

1. 如何识别图中目标区域？
   - 用 LSTM 根据之前帧的识别结果预测目标分布位置 (Region Proposal, RP)
   - 标记帧间相同目标
   - 低分辨率图用于识别新出现的目标
2. 如何切分和分配目标区域？
   - 内容敏感：用 AutoFocus 切掉不需要的部分
   - 计算开销敏感：估计切出的 RP 的计算开销
   - 计算资源敏感：估计服务端的资源余量，基于分块的资源需求和服务器资源余量进行切分

## 本文的核心技术点之一——基于 LSTM 的 RP 预测

LSTM 的输入序列为前 N 帧的识别结果（RP 位置），输出为新一帧的识别结果；识别结果包括左上角和右下角坐标和面积。

其所使用的 LSTM 就是一个常规的注意力 LSTM 模型。对于每一帧，都要输入前 N 帧序列进行一次计算。

**注意，这并不是一个基于内容的方法**

## 本文的核心技术点之二——RP 标记

显然，LSTM 输入的 RP 信息时，同一个目标在不同帧的标记必须统一，不然就无法获取 RP 位置的移动信息。

基于位置和面积的 RP 识别方法：
1. 位置：RP 中心点离的近的更可能是相同的 RP
2. 面积：RP 面积差别小的更可能是相同的 RP

具体差多小认为是相同？实验确定的值：
- 位置：$x, y$ 坐标差别小于 0.02
- 面积：面积大小差别小于 0.2

具体过程：
- 在满足面积和位置限制的前提下，优先匹配面积最小的，直到全部匹配完
- 不满足条件的和全部匹配完还没匹配上的，算做新目标

细节问题：RP 盖不住整个目标？根据实际情况扩展 RP 框

## 本文的核心技术点之三——处理新出现的对象：Low Resolution Compensation (LRC)

每隔 N 帧就将低清晰度的帧发给云端，让云端帮忙识别出新出现的目标。

具体隔几帧？trade-off：
- N 小，计算量大
- N 大，新目标识别的延迟高

## RP 切分完成后如何分配

显然，任务的分配过程每帧都要执行一轮，分配计算的目标是要令时间最长的那个任务执行时间$T_k^t$尽可能短。

- 这里的 $T_k^t=T_{rps,k}^t+T_{lrc,k}^t$ 表明 LRC 任务也可能和 RP 识别任务一起分配到服务器。
- $T_{rps,k}^t$ 和 $T_{lrc,k}^t$ 的计算式表明其是直接由计算量除服务器算力估算得到。

### 本文的核心技术点之四——RP 组合为 RPbox

1. 按照可用服务器数量和其各自的资源余量等比例对所有 RP 区域进行纵切
   - 切出的区域数量等于服务器数量
   - 切出的区域宽度之比等于服务器资源余量之比
   - 目的是让各服务器上的计算时间大致相等
2. 扩展所有 RPbox 直至覆盖所有部分包含的 RP，若包含某个 RP 导致其所需的计算时间增加很多就不扩展
   - 具体地，计算时间增加超过一个阈值就不扩，具体阈值多少在实验中体现
3. 扩展完之后，如果还有剩余的 RP，那就将其并入到临近有较强计算能力的 RPbox 中
   - 尽可能使得并入后的 RPbox 所需计算时间不大于 RPbox 最长的计算时间，或使得最长的计算时间增长最小
   - 每次并入后，都重新计算 RPbox 最长的计算时间
4. RP 分配完成后，将 RPbox 边框收缩到恰好包含所有 RP

### LRC 步骤的切分方式

通常，LRC 步骤不用切，但作者在实验中提到了服务器很多的情况，并指出 LRC 步切分一下可以提升速度。

但 LRC 时不知道 RP 的位置，所以只能按比例平均切，即只执行上一节的第一步。

## 如何估计服务端算力和 RPbox 计算消耗

估算服务端算力和 RPbox 计算消耗非本文重点。作者提出的参考方法：
- 估算服务端算力：
  - 直接从服务端查询
  - 基于过去 N 帧的计算延迟和相关网络状况进行估计
- 估算 RPbox 计算消耗
  - 简单方法：面积越大计算消耗越大
  - 高级方法：SACT