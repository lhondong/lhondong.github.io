# Reading List

## Video Compression Baseline

- [ ] [ECCV 2018] Video compression through image interpolation
- [ ] [CVPR 2019] DVC: An End-To-End Deep Video Compression Framework
- [ ] [ICCV 2019] Learned Video Compression
- [ ] [ICCV 2019] Video Compression With Rate-Distortion Autoencoders
- [ ] [ICCV 2019] Neural Inter-Frame Compression for Video Coding
- [ ] [CVPR 2020] HLVC: Learning for Video Compression With Hierarchical Quality and Recurrent Enhancement
- [ ] [CVPR 2020] M-LVC: Multiple Frames Prediction for Learned Video Compression
- [ ] [CVPR 2020] Scale-Space Flow for End-to-End Optimized Video Compression
- [ ] [ECCV 2020] Improving Deep Video Compression by Resolution-adaptive Flow Coding
- [ ] [ECCV 2020] Content Adaptive and Error Propagation Aware Deep Video Compression
- [ ] [NIPS 2019] Deep Generative Video Compression
- [ ] [NIPS 2021] Deep Contextual Video Compression
- [ ] [CVPR 2021] Deep Learning in Latent Space for Video Prediction and Compression
- [ ] [CVPR 2021] FVC: A New Framework towards Deep Video Compression in Feature Space
- [ ] [ICLR 2021] Hierarchical Autoregressive Modeling for Neural Video Compression
- [ ] [ICLR 2022] Transformer-based Transform Coding
- [ ] RLVC: Learning for Video Compression with Recurrent Auto-Encoder and Recurrent Probability Model
- [ ] PLVC: Perceptual Learned Video Compression with Recurrent Conditional GAN
- [ ] Temporal Context Mining for Learned Video Compression

## Transformer

- [ ] [NIPS 2017] Transformer Attention is All you Need
- [ ] [ICLR 2021] Vision Transformer AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE
- [ ] [ICCV 2021] Swin Transformer
- [ ] [NIPS pre] Video Swin Transformer
- [ ] [ICLR 2022] BEIT: BERT PRE-TRAINING OF IMAGE TRANSFORMERS
- [ ] [CVPR 2022] BEVT: BERT Pretraining of Video Transformers
- [ ] VRT: A Video Restoration Transformer
- [ ] [CVPR 2022] MaskGIT: Masked Generative Image Transformer（学习生成模型）
- [ ] [AAAI 2022] Towards End-to-End Image Compression and Analysis with Transformers
- [ ] [NIPS 2021] MST: Masked Self-Supervised Transformer for Visual Representation
- [ ] *SimMIM*: A Simple Framework for Masked Image Modeling