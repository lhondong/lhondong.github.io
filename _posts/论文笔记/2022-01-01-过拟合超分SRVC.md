---
title: "Efficient Video Compression via Content-Adaptive Super-Resolution"
subtitle: "过拟合超分 SRVC"
layout: post
author: "L Hondong"
header-img: "img/post-bg-12.jpg"
mathjax: true
tags:
  - 视频超分
  - 过拟合
---

# 过拟合超分 SRVC

Efficient Video Compression via Content-Adaptive Super-Resolution

MIT

## 摘要

视频压缩。通过小型的、内容自适应的超分模型来增强现有的视频编解码器，从而提高视频质量。

SRVC 编码端将视频编码为两个流：

1. 内容流：使用现有的编解码器压缩下采样的低分辨率视频
2. 模型流：周期性更新，为视频短片段定制的轻量级超分模型。

解码端将低分辨率视频帧解码，然后用（time-varying）时变超分模型重建 HR 帧。

结果表明，达到相同 PSNR 的情况下，SRVC 比 H.265 节省了 20%bpp。而 DVC 仅能减少 3%。

SRVC 在 NVIDIA V100 GPU 上每秒 90 帧。

<div align=center><img src="https://lhondong-pic.oss-cn-shenzhen.aliyuncs.com/img/assets/SRVC-2022-01-12-12-29-45.png" alt="SRVC-2022-01-12-12-29-45" style="zoom:50%;" /></div>

## 一、简介

### 1.1 Motivation

### 1.2 Contributions

## 二、相关工作

### 2.1

### 2.2

## 三、方法

SRVC 将视频压缩为两个流：

1. 内容流

编码器下采样输入视频帧，使用基于区域的下采样。然后使用现成的视频编码器编码 LR 帧。解码器解码出来 LR 帧，然后超分。整个过程有损的。

2. 模型流

第二个比特流，对 SR 模型进行编码。将视频分为短片段，然后为每一段适配 SR 模型。编码器训练 SR 模型以将该段 LR 解码帧映射到高分辨率帧。

编码模型流时，t 时刻使用 t-1 时刻的模型参数 $\Theta_{t-1}$ 初始化 $\Theta_t$，然后编码的时候仅编码 $\Delta_t=\Theta_{t}-\Theta_{t-1}$。

模型流会增大整个传输的比特流，为了减少这个开销，设计了一个非常适合特定内容的 SR 小模型。同时还设计了一个算法，仅训练对 SR 质量有最大影响的一小部分参数，显著降低了模型自适应的开销。

<div align=center><img src="https://lhondong-pic.oss-cn-shenzhen.aliyuncs.com/img/assets/SRVC-2022-01-12-12-32-56.png" alt="SRVC-2022-01-12-12-32-56" style="zoom:50%;" /></div>

### 3.1 轻量化模型架构

轻量级的网络，但是在基于内容的适应方面非常有效。受 bicubic 启发，bicubic 只使用一个卷积层和一个固定的核对整张图像上采样，而这里的轻量化模型使用一样的架构，只是将固定核替换为针对输入帧的不同区域定制的空间自适应核。

将每帧图像分为不同的 patch，为每个 patch 生成不同的空间自适应核，使用浅层 CNN 处理 patch。

具体：

- 使用 space-to-batch 生成不同的 patch，
- patch-specific block（Adaptive Conv Block）计算 3×3 卷积，输入 3 通道，输出 F 通道，2 层 CNN。
- 集合这些特征 patch（batch-to-space），最后使用两层 CNN 和一个 pixel shuffler（depth-to-space）。

<div align=center><img src="https://lhondong-pic.oss-cn-shenzhen.aliyuncs.com/img/assets/SRVC-2022-01-12-12-31-32.png" alt="SRVC-2022-01-12-12-31-32" style="zoom:50%;" /></div>

### 3.2 模型自适应和编码

L2 损失。在训练过程中，在每个维度上随机裁剪样本大小的一半。

为了减少传输的模型的大小，仅更新最重要的参数。梯度最大的参数。

首先，在每个新视频片段的开头保存模型的备份，并对新视频片段中的所有帧迭代训练一次，然后选择一部分（变化最大的）参数在下一次迭代中更新。

编码时，记录索引和模型参数的变化，将模型更新编码为比特流。模型编码是**无损的**。这样压缩下来，对 1080p 视频，仅需要使用 82 Kbits/sec 的码流。Netflix 建议在 1080p 分辨率下的带宽为 5 Mbits/sec，所以码流实际上是很小的。模型可以用有损压缩或者根据场景动态变化选择更少一部分参数，进一步压缩。

问题：训练每分钟视频需要 12 分钟。通过在 V100 GPU 上并行训练 5 组，相当于每分钟视频需要 2.5 分钟。仅对于离线压缩场景可行。

未来一步，通过一些技术（例如，对采样帧而不是所有帧进行训练）和进一步的工程设计，编码速度有很大的提升空间。

## 四、实验

<div align=center><img src="https://lhondong-pic.oss-cn-shenzhen.aliyuncs.com/img/assets/SRVC-2022-01-12-12-33-23.png" alt="SRVC-2022-01-12-12-33-23" style="zoom:50%;" /></div>

<div align=center><img src="https://lhondong-pic.oss-cn-shenzhen.aliyuncs.com/img/assets/SRVC-2022-01-12-12-33-46.png" alt="SRVC-2022-01-12-12-33-46" style="zoom:50%;" /></div>

## 五、总结

