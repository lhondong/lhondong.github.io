---
title: "Efficient Video Restoration on Edge Devices"
subtitle: "EVRNet"
layout: post
author: "L Hondong"
header-img: "img/post-bg-3.jpg"
mathjax: true
tags:
  - 视频超分
  - 轻量化
---

# EVRNet

Efficient Video Restoration on Edge Devices

MM '21

University of Washington，Facebook

## 摘要

三个模块：对齐、差分和融合模块，在网络内部高效地分配参数。参数和 MAC 更少，效果更好。4 倍视频超分，EVRNet 比 EDVR 的参数少 260 倍，MAC 少 958 倍，而其 SSIM 分数仅比 EDVR 少 0.018。

在几个视频恢复任务上都做了实验，deblocking, denoising, and super-resolution，还评估了 EVRNet 在不可见数据集上的多重失真下的性能证明了其在相机移动和对象移动下，对于可变长度序列的建模能力。

## 一、简介

### 1.1 Motivation

EDVR，使用 deformable convolution-based video restoration network，有 21.1 million 参数，需要 9.96 TMACs，仅仅是对 360p 的视频做 4 倍上采样。

越来越多的视频传输应用程序（如视频流和视频会议）运行在边缘设备如智能手机上。这一趋势可能会随着诸如增强和虚拟现实等技术的采用而持续下去。

由于边缘设备计算资源、内存和 energy 有限，因此大型视频恢复网络不适用于此类设备。

另一方面，源视频在有限带宽下传输时往往会进行有损压缩，由于压缩和传输噪声，接收到的视频信号质量会比较低。总的来说，视频恢复任务的神经网络应该轻量、低延迟，同时可以在边缘设备上恢复高质量和时间稳定的视频。

所以提出 EVRNet，高效视频恢复网络，灵感来自于传统计算机视觉方法中的运动估计和图像增强。简单来说，EVRNet 使用对齐模块对齐当前帧和以前的帧，无需光流。

在压缩的过程中经常丢失高频分量，比如移动对象边缘，所以使用了一个差分和融合模块恢复高频分量细节。差分模块学习高频分量对应的表示，融合模块使用这些表示以及输入来产生高质量输出。

EVRNet 使用小型轻型编解码器网络更有效地在每个模块内分配参数和操作。

EVRNet 可以用于恢复单噪声和多噪声，为了证明其简单性和有效性，在大规模 Vimeo-90K 数据集上对三个独立的标准视频恢复任务的性能进行了评估。此外，针对典型的低带宽视频会议系统，视频由于视频编码和噪声传输网络而多重失真，也对 EVRNet 进行了测试。

### 1.2 效果

EVRNet 效果很好，而且参数和 MAC 数量明显减少，例如，在视频去块和去噪任务中，EVRNet 的性能与 ToFlow 相似，但 MAC 和参数分别减少 46 倍和 13.63 倍。在 4 倍视频超分辨率任务中，EVRNet 的 SSIM 分数略低于 EDVR 0.018，但参数少 260 倍，MAC 少 958 倍。

### 1.3 Contributions

1. 提出了一种能在边缘设备上实时运行的新型高效视频恢复网络
2. 单个神经网络 EVRNet，可在单个或多个失真下恢复视频
3. 定性和定量结果，以及在三项视频恢复任务上与最先进方法的比较，证明了 EVRNet 的性能优秀，同时具有显著减少的网络参数和 MAC。

## 二、相关工作

### 2.1 视频恢复

三个主要任务：去块效应，去噪和超分辨率。视频去块旨在消除由于压缩而产生的伪影（例如，棋盘格图案）。视频去噪的目的是消除由于噪声传输通道（如互联网）可能产生的噪声相关伪影。超分辨率旨在从低分辨率视频生成高分辨率视频。

大多数方法都是针对其中一项任务进行研究的，计算成本非常高。例如，ToFlow 有大约 466 个 GMAC 用于对 360p 视频进行去噪（或去块）。与现有方法不同，EVRNet 可用于恢复单个或多个失真的视频。

很多视频恢复方法使用光流，光流是使用深度光流网络计算的，例如 FlowNet、PWCNet 和 SpyNet。使用这些网络计算光流的成本很高，这限制了此类方法的实际适用性，尤其是在资源受限的设备（如智能手机）上。

EVRNet 还使用对准模块中的金字塔结构在连续帧之间进行隐式对准，在没有光流的情况下处理大型运动。重要的是，EVRNet 可以在边缘设备上实时恢复高质量的视频。

### 2.2 高效网络

设计高效的 DNN，旨在通过设计高效的学习层（如 depth-wise 卷积或 dimension-wise 卷积）或量化、压缩、剪枝，来减少网络参数和 MAC。

EVRNet 使用 depth-wise 卷积有效地学习表示。进一步的话可以继续用网络压缩剪枝，量化和蒸馏来提高 EVRNet 的效率。

## 三、方法

EVRNet，在边缘设备中删除伪影并恢复视频，从传统计算机视觉技术中的运动估计和图像增强中得到启发。基于金字塔结构设计了对齐模块，无需显式地使用光流来对运动建模。使用差分和融合模块来恢复失真丢失的高频细节，学习高频分量，然后将其加回到输入图像中以获得清晰的细节。

### 3.1 EVRNet 架构

自回归网络，高效地模拟当前帧 $I_t \in \mathbb R^{3 \times H \times W}$，过去帧 $I_{t-1} \in \mathbb R^{3 \times H \times W}$ 和过去 latent 帧 $H_{t-1} \in \mathbb R^{2 \times H \times W}$ 之间的关系。

$$
O_t,H_t=\mathcal F(I_t,I_{t-1},H_{t-1})
$$

$\mathcal F$ 即为 EVRNet 网络，其中的 $O_t$ 是恢复输出帧，$H_t$ 是当前 latent 帧，类似于 LSTMs 中的单元状态，使信息在不同的时间步中流动。

#### 对齐模块

用当前帧，过去帧和过去 latent 帧生成对齐表示 $A_t \in \mathbb R^{d \times H \times W}$，对齐模块首先使用编码器网络学习金字塔表示。然后解码器将这些表示组合起来，以产生对齐的表示。与现有的学习非常深的金字塔表示的运动估计方法相比，EVRNet 非常轻量，非常浅。

<div align=center><img src="/assets/EVRNet-2022-01-12-13-05-26.png" alt="EVRNet-2022-01-12-13-05-26" style="zoom:50%;" /></div>

使用 pixel-shuffle 用作超分上采样。

<div align=center><img src="/assets/EVRNet-2022-01-12-13-05-43.png" alt="EVRNet-2022-01-12-13-05-43" style="zoom:30%;" /></div>

<div align=center><img src="/assets/EVRNet-2022-01-12-13-06-06.png" alt="EVRNet-2022-01-12-13-06-06" style="zoom:50%;" /></div>

对齐模块关注这些显著区域（optical flow and difference image），说明 EVRNet 隐式运动建模的能力。

<div align=center><img src="/assets/EVRNet-2022-01-12-13-06-17.png" alt="EVRNet-2022-01-12-13-06-17" style="zoom:50%;" /></div>

1. 一个标准的 5 × 5 卷积层
2. 一个标准的 5 × 5 步长为 2 的卷积层
3. 一个 point-wise 的卷积层
4. $N_A$ 个卷积单元

解码器类似于简化的 UNet，最后一个 CU 的输出首先上采样，然后与第一个 5×5 卷积层的输出串联，然后使用逐点卷积对结果输出进行融合，以产生对齐表示 $A_t$。

#### 差分模块

差分模块旨在学习图像中的高频成分，如物体边缘，首先使用 3 × 3 卷积将输入 $I_t$ 映射到与 $A_t$ 相同的维度 $P_t \in \mathbb R^{d\times H \times W}$，然后计算 $P_t$ 和 $A_t$ 之间的逐元素差异。然后将结果送到差分模块进一步细化，产生高频表示 $D_t \in \mathbb R^{d \times H \times W}$。

图 4f 显示了 EVRNet 关注高频成分（例如眼镜和耳朵边缘）。与对齐模块类似，差分模块也采用小型轻型编码器-解码器网络的形式，但 CU 数量不同，有 $N_D$ 个 CU。

#### 融合模块

融合模块结合从差分模块获得的高频表示 $D_t$，和 $I_t$ 的投影表示 $P_t$ 并生成恢复的帧 $O_t$ 和潜在帧 $H_t$。

首先将 D 与 P 相加来增强高频分量，然后将合成的张量输入融合模块，如果输出 O 的维度与 I 不一致（即超分任务），将会用 pixel-shuffle 对 O 进行上采样操作。如果一样，就进行 identity 操作，将所得输出与 3×3 卷积层卷积，以产生 O。

同时，还使用逐点卷积层投影融合模块的输出，以产生潜在帧 H，这样可以在当前和下一时间步之间共享信息，与对齐和差分模块类似，融合模块也是一个高效、轻量级的编码器-解码器网络，有 $N_F$ 个 CU。

差分和融合模块的操作类似于传统的图像增强方法（unsharp mask），首先对输入图像进行平滑以抑制高频分量，然后计算平滑图像和输入图像之间的差值以识别高频分量，然后将高频分量添加回输入以增强高频分量。

### 3.2 Convolutional Unit (CU)

不同视觉识别任务的 CNN 或者使用单个分支卷积单元（ResNet 或 MobileNet），或者使用多个分支卷积单元（InceptionNets 或 ESPNets）。

本文同时使用这两种学习表征的方法，对于在单个尺度上学习表示，使用 7×7 卷积层，对于在多个尺度上学习表示，同时使用三个卷积层（3×3、5×5 和 7×7）。两种方法的有效感受野是相同的，都是 7×7。继最近的高效网络（如 MobileNetv3）之后，还采用 squeeze-excitation 单元（SE 单元）[20] 来模拟信道的相互依赖性。

## 四、实验

三个任务：
1. 视频去块
2. 视频去噪声（例如自适应高斯白噪声 AWGN）
3. 视频超分

### 4.1 数据集

Vimeo-90K

### 4.2 模型设置

L1 loss，ADAM 优化器，50 epoches（大约 50k 次迭代），

### 4.3 视频去块

先使用 JPEG2000 压缩，训练期间在 10-40 之间随机选择量化参数 Q，在评估期间，使用 OpenCV 将 Q 从 15 变化到 90。Q 越小表示压缩率越高，也会有更多的块效应，相同的 EVRNet 可以处理不同的 Q。

在 Q = 15 时，EVRNet 能够分别实现 PSNR = 33 dB 和 SSIM = 0.91（RGB 空间），这表明即使在高压缩下也可以生成高质量的帧。

<div align=center><img src="/assets/EVRNet-2022-01-12-13-06-58.png" alt="EVRNet-2022-01-12-13-06-58" style="zoom:70%;" /></div>

比较 EVRNet 与官方 Vimeo-90K 测试集上最先进的去块方法（ARCNN[6]、DnCNN[62]、V-BM4D[35]、ToFlow[58] 和 DKFN[32]）的性能，EVRNet 与现有方法的性能相似或更好，同时具有显著减少的网络参数和 MAC。例如，EVRNet 的性能与 ToFlow[58] 相似，但 MAC 数量减少 46 倍，参数数量减少 13.64 倍。

### 4.3 视频去噪

三种噪声类型下训练 EVRNet：

1. Additive White Gauss- ian Noise (AWGN)
2. Salt and Pepper noise (S&P)
3. AWGN and S&P 混合

随机选择 AWGN 噪声的 $\sigma^2$ 在 0.05 和 0.4 之间，S&P 噪声的密度 $\rho$ 在 0.05 和 0.3 之间，表示被噪声取代的像素百分比。

只训练一个 EVRNet 网络用于视频去噪，然后在 AWGN、S&P 和混合噪声的不同设置下对其进行评估。图 6 中的定量结果表明，EVRNet 对不同类型和数量的噪声具有鲁棒性。

与其他 sota 方法对比，在 Vid4 数据集上评估，

### 4.4 视频超分

包括 2 倍和 4 倍。

EVRNet 的 SSIM 分数比 EDVR 低 0.018，但参数和 MAC 分别少 260 倍和 958 倍。但是！PSNR 比 EDVR 小 1.6dB，

## 五、总结

视频传输系统在传输到端侧前压缩视频流，以减少网络带宽。在端侧，由于压缩和传输噪声，解码视频流的质量较低，因而需要使用视频恢复方法来恢复。

Vimeo-90K 数据集中的每个序列由 8 帧组成，具有固定的空间分辨率 448 × 256。为了测试 EVRNet 在摄像机和物体运动下对可变长度序列建模的能力，评估了其在使用不同移动设备捕获的六个高清和不同视频序列上的性能。为了便于评估，首先使用 H264 编码对这些视频进行压缩，然后添加混合噪声（AWGN $\sigma ^2$ =0.001，$\rho$ = 0.1 的 S&P)。

定量和定性结果都表明，EVRNet（1）可以对可变长度序列建模，（2）可以推广到看不见的视频。

### 在边缘设备运行时间

通常边设备的处理是 10-15fps，处理 240p 和 360p 视频，这些设备大多由电池驱动，帧速率较高，电池会很快耗尽。在 iPhone Xs 和 iPhone11 上测试 EVRNet，苹果 ML 引擎不支持 PixelShuffle 加速。因此只能在 iPhone 的 CPU 上执行（CPU 占用率为 23%），速度会显著变慢，iPhone 11 上比 iPhone XS 速度更快。

特定于加速器的 PixelShuffle 实现以及硬件技术的进步将进一步提高边缘设备上 EVRNet 的速度。

<div align=center><img src="/assets/EVRNet-2022-01-12-13-07-19.png" alt="EVRNet-2022-01-12-13-07-19" style="zoom:70%;" /></div>

### 消融实验

Effect of different CUs

单尺度和多尺度卷积单元（CU）加上和不加 SE 单元对 AWGN 去噪任务的影响。带有 SE 的多尺度 CU 单元提高了性能。

## 六、思考

虽然宣称实时，但是根本没有真正实时！！
