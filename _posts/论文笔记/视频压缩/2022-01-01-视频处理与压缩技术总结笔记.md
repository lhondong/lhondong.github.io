---
title: "视频处理与压缩技术总结笔记"
subtitle: "视频处理与压缩技术总结"
layout: post
author: "L Hondong"
header-img: "img/post-bg-4.jpg"
mathjax: true
tags:
  - 视频压缩
  - 视频超分
  - 综述
---

# 视频处理与压缩技术总结笔记

视频处理与压缩是多媒体计算与通信领域的核心主题之一，是连接视频采集传输和视觉分析理解的关键桥梁，也是诸多视频应用的基础。本文从**视频处理技术、视频压缩技术、多视点/立体视频压缩以及国内外研究进展**四个方面对视频处理与压缩技术进行了汇总。**主要针对《视频处理与压缩技术》一文进行总结，对其中涉及的论文和相关提案进行了汇总和整理。**

## 引言

- 1940—1950 年是视频技术基础理论发展的关键期：香农以及信息论三大定理；
- 20 世纪 70 年代是视频技术研究的快速发展时期，伴随着 CCD 与 CMOS 成像技术的发展，具备了坚实的硬件基础；
- 20 世纪 80 年代是视频处理领域发展的萌芽期：CCITT 于 1984 年颁布了首个视频压缩国际标准 H.120；
- 20 世纪 90 年代至 21 世纪初是视频压缩标准研究的黄金时代：ISO/IEC,ITU-T 先后发布 H.26X 标准；

## 1. 视频处理技术

### 1.1 视频超分辨

视频超分辨率算法分为传统基于信号处理的方法和基于深度学习的方法。

下面从是否使用对齐类方法的角度介绍视频超分辨的研究现状。

#### 1.1.1 对齐超分辨算法

对齐视频超分辨算法通过网络提取运动信息，使相邻帧与目标帧进行对齐，然后再进行后续重构。该类方法主要采用运动补偿和可变形卷积两种常用的帧间对齐技术。

国外视频超分辨率对齐方法大多采用运动补偿和运动估计技术。运动估计采用光流方法，运动估计的目的是提取帧间的运动信息，而运动补偿是根据帧间的运动信息进行帧间的矫正操作，使一帧与另一帧对齐。大部分运动估计技术是使用光流方法 (Dosovitskiy 等，2015) 完成的。

- Kappeler 等人 (2016) 提出的视频超分网络 (video super resolution network，VSRnet) 由 3 个卷积层组成，除最后一个外，每个卷积层后面都有一个非线性激活单元 (rectified linear unit，ReLU)。VSRnet 使用多个连续帧，这些连续帧都是补偿帧。目标帧与补偿帧之间的运动信息由 Druleas 算法计算得出 (Drulea  Nedevschi, 2011)。此外，VSRnet 提出了滤波器对称增强 (filter symmetric enhancement，FSE) 机制和自适应运动补偿机制，分别用于加速训练和减少冗余的补偿帧影响，从而提高视频的超分辨率性能。
- Caballero 等人 (2017) 提出的视频子像素卷积网络 (video efficient sub-pixel convolutional neural network，VESPCN) 设计了一种空间运动补偿变压器 (motion compensation transformer，MCT) 模块用于运动估计和补偿，并将补偿后的帧送入一系列卷积层进行特征提取和融合，最后通过亚像素卷积层得到超分辨率结果。MCT 模块采用卷积神经网络提取运动信息，进行运动补偿，使用由粗到细的方法来计算图像序列的光流。
- Sajjadi 等人 (2018 ) 提出了 FRVSR(frame-recurrent video super-resolution) 网络，主要特点在于帧间的对齐方式，该网络不会直接矫正目标帧的前一帧（低分辨率帧） ，而是扭曲矫正前一帧对应的高分辨率帧。
- 受反投影算法 (Haris 等，2018; Irani 和 Peleg，1991，1993) 的启发，Haris 等人 (2019) 提出了递归反投影网络 (recursive back projection network，RBPN) ，由特征提取模块、投影模块和重构模块组成。特征提取模块包含提取目标帧特征和提取相邻帧特征两个操作，并计算从相邻帧到目标帧的光流，然后进行隐式地对齐。
- Bare 等人 (2019) 提出实时视频超分辨率 (real time video super resolution，RTVSR)，通过运动卷积核估计网络，使用编解码结构估计目标框架与相邻帧之间的运动，产生一对与当前目标帧和相邻帧对应的 1 维卷积核，然后利用估计的卷积核对相邻帧进行矫正，使其与目标帧对齐。

##### 运动补偿

- Tao 等人 (2017) 提出面向细节增强的深度视频超分网络 (detail-revealing deep video super-resolution，DRVSR)，提出一种亚像素运动补偿层 (subpixel motion compensation，SPMC)，可以根据估计的光流信息对相邻输入帧同时进行上采样和运动补偿操作。此外，融合模块采用卷积长短期记忆单元 (convolutional long-short term memory，ConvLSTM) 模块 (Shi 等，2015) 来处理时空信息。
- Wang 等人 (2018b) 提出光流超分的视频分辨率提升网络 (super-resolving optical flow for video super resolution，SOFVSR)，采用一种由粗到细包含光流网络 (optical flow network，OFNet) 的方法估计帧间的光流，得到高分辨率光流。然后通过转换机制 space-to-depth 将高分辨率 ( high resolution，HR) 光流转换为低分辨率 (low resolution，LR) 光流。相邻帧通过 LR 光流矫正，与目标帧对齐。
- Xue 等人 (2019) 提出面向任务驱动的光流网络 (task-oriented flow，TOFlow) ，将光流估计网络与重构网络相结合，共同进行训练，采用空域金字塔网络 (spatial pyramid network，SpyNet)(Ranjan 和 Black, 2017) 作为光流估计网络，然后采用空间变换网络根据计算出的光流对相邻帧进行变形。不足：使用最先进的光流估计网络也不容易获得足够高质量的运动估计；使用精确的运动场，运动补偿也会在图像结构周围产生伪影，这些伪影可能会传播到最终重建的 HR 帧中。

##### 可变形卷积

可变形卷积网络最早由 Dai 等人 (2017a) 提出，随后 Zhu 等人 (2019b) 提出了改进版本。采用可变形卷积的超分辨方法主要有香港中文大学提出的增强可变卷积网络 (enhanced deformable convolutional networks，EDVR)(Wang 等，2019d)、华南理工大学提出的可变形非局部网络 (deformable non local network，DNLN)(Wang 等，2019a) 以及清华大学和美国罗切斯特大学提出的时间形变对齐网络 (time deformable alignment network，TDAN)(Tian 等，2020)。

- EDVR 方法由对齐模块、融合模块和重建模块 3 部分组成。对齐模块对输入帧进行对齐，然后通过融合模块将对齐后的帧进行融合，并将融合后的结果送入重构模块细化特征，通过上采样得到一幅 HR 图像，称为残差图像。最后将残差图像添加到直接上采样目标帧中得到最终结果。
- DNLN 方法设计了基于可变形卷积和非局部网络 (Wang 等，2018d) 的对齐模块和非局部注意模块。对齐模块使用原始可变形卷积内的层次化特征融合模块 (hierarchical feature fusion block，HFFB)(Hui 等，2020) 生成卷积参数。此外，DNLN 通过级联的方式利用了多个可变形卷积，使得帧间对齐更加精确。非局部注意模块以目标帧和对齐的相邻帧为输入，通过非局部操作生成引导注意的特征。
- TDAN 方法对目标帧和邻近帧进行形变卷积，得到相应的偏移量。然后根据偏移量对相邻帧进行变形，使其与目标帧对齐。

#### 1.1.2 非对齐超分辨算法

与对齐方法不同，未对齐方法在重建前不进行帧对齐，分为**空间未对齐**和**时空未对齐**两种。

##### 空间非对齐方法

空间非对齐方法直接将输入帧输入到 2 维卷积网络中进行空间特征提取、融合和超分辨率操作，不进行帧间的运动估计和运动补偿等对齐操作。

- VSRRes-Net 通过对抗性训练解决视频超分辨率问题，由鉴别器决定输出的是生成图像还是真实图像，使生成器产生更接近真实图像的结果。

##### 时空未对齐方法

时空未对齐方法的特点是同时利用输入视频中的时空信息进行超分辨任务

- 动态滤波器 (dynamic upsampling filter，DUF)。DUF(Jo 等，2018) 采用动态滤波器结构，执行滤波和上采样操作，与 3 维卷积学习的时空信息相结合，避免了运动估计和运动补偿。为了增强超分辨率结果的高频细节，DUF 使用网络估计目标帧的残差图，一帧的最终输出结果是残差映射和经过动态上采样滤波器处理的帧的总和。此外，DUF 提出一种基于时间轴的视频数据增强，对不同时间间隔内按顺序或倒序采样视频帧，得到不同运动速度和方向的视频。
- 3 维超分网络 (3-dimensional super resolution network，3DSRnet)(Kim 等，2019) 使用 3D 卷积提取连续视频帧之间的时空信息用于视频超分辨率任务。随着网络的深入，3 维卷积后的特征图的深度也会变浅。为了保留深度和时序信息，3DSRNet 采用扩展操作，即在连续帧的开始和结束分别增加一帧。同时提出一种实际应用中场景变化的方法，采用浅分类网络判断输入的连续帧，有效解决了场景变化导致的性能下降问题。

循环卷积神经网络 (recurrent convolutional neural network, RCNN) 在处理时序数据 ( 如自然语言、 视频和音频等） 时具有很强的时间依赖性。一种直接的方法是使用 RCNN 处理视频序列。基于这一思想，提出了双向循环卷积网络 (bidirectional recurrent convolutional network，BRCN) (Huang 等，2018) 、残差递归卷积网络 (residual recursive convolution network，RRCN) (Li 等，2019a) 、残差可变时空卷积 (residual invertible spatio-temporal network，RISTN)(Zhu 等，2019b) 和时空卷积网络 (spatial-temporal convolution network，STCN) (Guo 和 Chao，2017) 等 RCNN 方法实现视频超分辨率。

- BRCN 利用 RCNN 适合处理序列数据的优势处理视频中连续帧之间的依赖关系，包含前向和后向两个网络，两个网络结构相似但处理顺序不同。前向网络中，隐含层各节点的输入有 3 个，分别是前一层当前时刻 i、上一时刻 i－1 的输出和当前层中前一个节点的输出，分别用于提取空间相关性和连续帧之间的时间相关性。
- RRCN 是一个学习残差图像的双向递归神经网络，提出一种非同步的全循环卷积网络，非同步指多个连续视频帧输入但只有中间帧需要超分辨重建。采用局部—全局—全变量组合 (global local total variation，GLG-TV) 方法 (Drulea 和 Nedevschi，2011) 对目标帧及其相邻帧进行运动估计和补偿。
- RISTN 基于可逆网络 (Jacobsen 等，2018) 设计了残差可逆块用于提取空间信息的有效视频帧，利用 LSTM 提取时空特性，由时间模块、空间模块和重构模块 3 部分组成。空间模块主要由多个平行残差可逆单元组成，其输出作为时态模块的输入。在时间模块中，提取时空信息后，采用稀疏融合策略有选择地融合特征。最后，在重构模块中通过反卷积重建目标帧得到高分辨结果。
- STCN 是一种不需要运动估计和运动补偿的端到端视频超分辨率方法，利用 LSTM 算法提取帧内的时间信息 (Hochreiter 和 Schmidhuber，1997)，与 RISTN 类似，该网络由空间模块、时间模块和重构模块 3 部分组成。
- PFNL 武汉大学、哈尔滨工业大学和鹏城实验室联合提出的渐进非局部残差融合 ( progressive fusion of non local network，PFNL) (Yi 等， 2019) 采用非局部残块提取时空特征，采用渐进融合残差块 ( progressive fusion of residual block，PFRB) 融合时空特征。最后，通过跳接操作将双三次插值向上采样的输入帧和亚像素卷积层的输出进行接合，得到最终的超分辨率结果
- 复旦大学提出的网络与普通的运动估计和运动补偿技术不同，将低分辨率的未对齐视频帧和前一帧的高分辨率输出直接作为网络的输入以恢复高频细节，保持时间一致性 (Yan 等，2019a)。

非对齐网络比较简单，超分辨重建效果也很有限，说明在利用多帧进行视频超分辨的过程中，帧间信息融合非常重要，对帧间融合的方法尚需进一步研究。

#### 1.1.3 视频插帧

- Meyer 等人 (2018) 基于相位的运动表示提出了 PhaseNet 结构，对运动模糊或闪动变化产生了比较鲁棒的结果，但不能有效重建详细的纹理。
- 核方法在 2017 年是一个研究热点，Niklaus 等人 (2017a，b) 连续在 ICCV 和 CVPR 会议上提出了基于核的方法，为每个像素估计一个自适应卷积核。基于核的方法可以产生合理的结果，但是不能处理大运动场景。
- 为了有效利用运动信息，Niklaus 和 Liu(2018) 使用前向变形技术从连续的两帧中生成了中间帧，然而前向扭曲矫正存在像素缺失和重叠。因此，大多数基于流的算法都是基于反向扭曲矫正的。为了使用反向扭曲，需要估计中间运动 ( 即中间帧的运动向量）。

### 1.2 视频恢复

视频恢复是视频处理的关键任务之一，对视频主客观质量提升和下游视觉分析任务具有至关重要的作用。从成像设备捕捉到的降质图像中恢复出富有细节的清晰场景图像是一个值得长期研究的问题，降质模型包括模糊、噪声和天气效应等。

在过去的几年中，用于从静态/动态场景的视频恢复算法已经探索并形式化描述了降质模型的很多固有特性。这些算法主要分为 4 类：基于时域的算法、基于频域的算法、基于低秩和稀疏性的算法以及基于深度学习的算法。

#### 基于时域的方法

- Garg 和 Nayar 最早尝试从视频中去除雨痕，并提出直接增加曝光时间或减小摄像机景深的方法，但无法处理靠近摄像机的快速移动物体，并且如果控制视频质量不发生显著下降，则无法通过此方法调整摄像机设置 (Tripathi 和 Mukhopadhyay,2014)。利用时空相关模型描述雨水的动态特性，基于物理的运动模糊模型解释雨的光度特性，通过利用连续帧之间的差异消除雨痕。
- Park 和 Lee(2008) 提出估计像素的强度，通过卡尔曼滤波器递归恢复视频，在具有固定背景的视频中表现良好。
- Brewer 和 Liu(2008) 借鉴成像过程中的光学和物理特性，提出首先识别出显示短时强度峰值的受雨影响区域，然后用连续帧中的平均值替换受雨影响的像素，能够区分由雨引起的灰度变化与由场景运动引起的灰度变化，然而对检测重叠的形状各异的雨痕造成的大雨并不适用。
- 为了同时处理动态背景和相机运动，Bossu 等人 (2011) 利用高斯混合模型 (Gaussian mixture model，GMM) 和几何矩估计雨痕的方向直方图。
- 受贝叶斯理论启发，Tripathi 和 Mukhopadhyay(2011) 依靠降雨的时间特性建立雨痕去除概率模型。不足：由于受雨影响的像素和无雨像素的灰度变化因波形的对称性而异，因此使用灰度波动范围和扩展不对称性两个统计特征区分雨痕与无雨运动物体。
- 为了进一步减少连续帧的使用，Tripathi 和 Mukhopadhyay(2012) 转向采用时空过程，与依靠降雨的时间特性建立的雨痕去除概率模型 (Tripathi 和 Mukhopadhyay，2011) 相比，检测准确度较低，但具有更好的感知质量。

- Zhang 和 Patel(2017) 嵌入雨的时域和色度特性，并利用 K-means 聚类从视频中区分背景和雨痕。这个方法在处理小雨和大雨以及对焦/不对焦雨时效果很好。然而，由于背景的时间平均，该方法经常趋于使图像模糊。
- Zhao 等人 (2008) 利用雨痕的时空特征设计了用于检测和去除降雨的直方图模型，该模型嵌入了简洁、低复杂度的 K-means 聚类算法 (Zhang 等，2006)。

#### 基于频域的方法

- Barnum 等人利用模糊的高斯模型近似估计了雨滴和频域滤波导致的模糊效果，模拟雨/雪导致的能见度下降。适用于具有场景运动和摄像机运动的视频，并且可以有效地分析重复的降雨模式。不足：模糊的高斯模型不能总是覆盖不够锐利的雨痕，当雨痕的频率成分不按顺序排列时，基于频率的检测方式常常会出错

#### 基于低秩和稀疏的方法

- 为了克服基于朴素最大值后验方法的局限性，同时避免启发式边缘预测步骤，一些学者设计了有效的图像先验，如归一化稀疏性先验 (Krishnan 等，2011) 和 L0 正则先验 (Zoran 和 Weiss，2011) 以去除视频中的模糊效应。
- Chen 和 Hsu(2013) 从雨痕的相似性和重复性出发，提出了一个从矩阵到张量结构的低秩模型，以捕获时空相关的雨痕特性。
- 为了处理高度动态的场景 ( Garg 和 Nayar 2004; Park 和 Lee,2008)，Chen 和 Hsu(2013) 设计了基于动态场景运动的分割算法，利用光度和色度约束进行雨水检测以及雨痕动态特性建模，可以在像素复原过程中自适应地利用空间和时间信息，但是仍然无法很好地适应相机抖动 (Ren 等，2017)。
- Kim 等人 (2015) 提出从当前帧中减去时域上对齐的帧以获得初始降雨图，然后通过支持向量机将其分解为两种基本矢量。
- 为了处理有显著噪声和离群值的低质视频，Hu 等人 (2018b) 改进了现有方法以提升重建视频处理离群值时的鲁棒性。

- 考虑到大雨和动态场景，Ren 等人 (2017) 将雨痕分为稀疏层和稠密层，并将运动物体和稀疏降雨条纹的检测形式转化为多标签马尔可夫随机场，将稠密的雨痕建模高斯分布。
- Jiang 等人 (2017，2019) 提出一种新颖的基于张量的视频雨痕去除方法，全面分析雨痕和无雨视频的判别固有特性。具体来说，雨滴沿雨滴方向稀疏且平滑，干净的视频沿雨水垂直的方向具有平滑度，沿时间方向具有全局和局部相关性。
- Wei 等人 (2017) 将雨层编码为基于块的高斯混合，通过整合运动对象的时空平滑配置和背景场景的低秩结构，提出一种简洁的模型去除雨痕，能够适应更大范围的降雨变化。
- 受 Zhang 和 Patel(2017) 工作的启发，Li 等人 (2018b) 考虑了视频中雨痕的两个内在特征，即重复的局部图案稀疏地散布在视频的不同位置和由于它们出现在距摄像机的距离不同的位置上导致的多尺度特性，提出了多尺度卷积稀疏编码模型 (multi scale-convolutional sparse coding，MS-CSC) ，类似于 Wei 等人 (2017) 的工作，分别使用 L1 和总变分 (total variation，TV) 规范特征图的稀疏性和运动对象层的平滑度。这种编码方式使得模型能够从雨视频中适当地提取自然雨痕。

#### 基于深度网络的方法

- Chen 等人 (2018a) 提出了一个 CNN 框架用于视频去雨，可以处理带有不透明雨痕遮挡的暴雨。该方法采用超像素作为基本处理单元，能够对具有高度复杂和动态场景的视频内容进行对齐和遮挡消除。

- 通过探索利用视频中的时间冗余信息，Liu 等人 (2018) 建立了一个混合降雨模型描述雨痕和遮挡，利用深度 RNN(recurrent neural network) 设计了联合递归去雨和重建网络 ( joint recurrent rain removal and restoration network，J4R-Net)，无缝集成了降雨分类、基于空间纹理外观的去雨和基于时序一致性的背景帧细节重建，通过动态检测视频上下文环境实现去雨，设计了动态路由残差循环网络 (dynamic recurrent rain removal network，D3R-Net) 和用于去除视频雨水的空间时间残差学习模块。
- Yang 等人 (2019b) 建立了一个双流正则化约束的两级递归网络，以进行视频合成降雨合成模型的逆恢复过程。同时，考虑到相邻帧高度相关可视为同一场景的不同版本且雨痕沿时间维度随机分布，Yang 等人 (2019a) 构建了一个两阶段的自学习去雨网络，充分利用时域相关性和一致性来消除雨痕。

## 2. 视频压缩技术

### 2. 1 混合框架中的传统技术

传统视频编码采用基于块划分的混合编码框架，包括帧内预测、帧间预测、变换、量化、熵编码和环路滤波等技术模块。

#### 编码块划分

H.264/AVC 采用基于 16x16 的块划分，H.265/HEVC 中采用了四叉树划分结构，H.266/VVC 中，采纳了高通公司 (Chen 等人，2018a) 提出的四叉树、三叉树和二叉树联合的多级划分方式，有效提高了编码框架的灵活性。

- 区别于之前的对称四叉树、二叉树划分，Wang 等人 (2019b) 在四叉树、二叉树划分的基础上提出了一种非对称的三叉树划分方式以适应更高分辨率、更多样的视频内容。
- Fu 等人 (2019) 提出了非对称划分方式 (unsymmetrical quad tree，UQT)，可以划分出四叉树、二叉树 (quad tree plus binary tree，QTBT) 和扩展四叉树 ( extended quad tree，EQT) 无法划分出的形状。
- 为了更好地拟合编码单元中信号的变化规律，清华大学提出了一种“帧内导出树”划分技术 ( Wang 等，2019c)，将一个帧内编码单元划分成两个或四个预测单元，同时规定了相应预测单元对应的变换单元的划分方式。

#### 帧内预测

利用邻近块之间的空域相关性来消除空域冗余，HEVC 中的帧内预测包含平面 (planar) 预测、直流 (direct current，DC) 预测和角度预测等模式。在帧内预测部分，预测像素滤波技术得到了较多关注。

- Said 等 (2016) 提出基于位置的帧内预测组合 ( position dependent intra prediction combination，PDPC)，使用边界参考像素以及滤波后的边界参考像素对传统平面预测、直流预测和角度预测模式的结果进行修正，以降低预测失真。
- Fan 等人 (2019) 提出了一种帧内预测滤波方式，通过对一定范围内的边界像素使用左边界或上边界参考像素对预测值进行加权滤波，有效减少了预测噪声带来的影响。
- 腾讯公司提出了一种多层次帧内像素滤波技术 (Wang 等，2019e)，有别于传统的针对参考像素的滤波，该方法根据视频信号位置、与参考像素距离决定滤波方式。
- （跨分量预测技术）Li 等人 (2020a) 利用亮度参考边界和色度参考边界信息构建线性预测模型，有效利用分量间的相关性以降低分量间的冗余。
- 针对屏幕内容视频，Xu 等人 (2016) 提出了帧内块拷贝技术，允许编码单元将当前帧内的已编码块作为预测块，大幅提升编码效率。

#### 帧间预测

利用邻近帧之间的时域相关性来消除时域冗余：运动矢量编码消耗的比特数制约着压缩性能，如何导出高质量、低销的运动矢量一直是行业关注的焦点

- Zhang 等人 (2018a) 提出一种运动矢量精度的自适应算法，与 HEVC 中固定 1/4 像素的运动矢量精度不同，该方法为运动矢量设置了整像素、4 像素和 1/4 像素等多种可选项，通过率失真优化的方法进行编码端决策，提升运动矢量的表示能力。
- Xiu 等人 (2018) 提出一种高级时域运动矢量预测技术 (advanced temporal motion vector prediction，ATMVP)，对编码单元进行细分，针对每个编码单元在每个参考方向上导出多组运动矢量预测信息，通过这些运动信息对当前编码单元内的子块分别进行运动补偿，提升预测的准确度。
- 以往的帧间技术模块仅考虑平移的运动模型。Li 等人 (2015) 提出一种仿射变换运动补偿预测方法，对每个子块计算其在仿射运动场中的运动矢量，从而进行子块的运动补偿，可以有效提升具有缩放、旋转、透视和其他不规则运动场景的编码性能。
- Zhang 等人 (2020a) 提出一种交织仿射变换运动补偿方法，根据两种不同的划分模板将编码块划分为子块并进行仿射运动补偿，然后加权求和得到最终预测块。
- Li 等人 (2019b) 通过对已编码区域的运动信息建模，提出一种基于历史信息的运动矢量预测方式，利用非局部相似性的原理获取更多非局部的运动矢量候选。
- Fang 等人 (2020) 提出一种基于子块的运动矢量角度预测方法，预设了 5 种角度，按照定义好的角度方向寻找每个子块对应的运动矢量。
- Chen 等人 (2018b) 提出的解码端运动矢量修正技术对双向预测的两个运动矢量通过双边匹配进行进一步优化。
- Jin 等人 (2007) 提出一种帧间帧内联合预测方式，最终的预测块由两种预测方式加权得到，融合帧内预测和帧间预测的结果可以达到更优的像素预测。

#### 变换

作用是去除残差信号的统计相关性，变换过程是可逆的：HEVC 中对残差信号进行一次变换，主要包含整数离散余弦变换和整数离散正弦变换两种变换方式。

- Koo 等人 (2019) 在 VVC 中提出一种二次变换技术——低频非分离变换 (low-frequency non-separable transform，LFNST)，可以使残差信号能量进一步集中，有效减少残差编码消耗的比特数。
- 针对帧间预测残差的分布特性，华为提出一种子块变换技术 (Zhao 等，2019b)，假设预测残差分布在残差块的局部区域，仅针对残差块的一个子块进行变换处理，从而提升压缩性能。
- Wang 等人 (2018a) 对帧间预测残差分布特性进行分析，提出基于位置的变换技术，考虑到编码单元中不同位置的帧间预测残差分布特性，对行变换和列变换分别使用两种变换核，这种基于位置的绑定方式能有效适应不同位置帧间残差的分布规律。
- Zhang 等人 (2020b) 提出一种隐择变换技术，为当前残差块预设了两种变换核，通过率失真优化决策过程选择更优的变换核，选择结果并不在码流中传输，而是通过符号隐藏方式标识。

#### 量化

量化是变换后对变换系数的处理，也是压缩失真的主要来源（量化不可逆，会造成失真）。将变换系数划分为不同的区间，每个区间用一个标号代表，标号数量小于原始数据量，由此达到压缩的目的。

- Schwarz 等人 (2018) 提出一种上下文依赖量化 (dependent quantization，DQ) 方式，此方法与 HEVC 中常用的独立标量量化相比，将变换系数在向量空间中进行更加密集地压缩，可以有效减小原始变换系数与量化后系数之间的差值，从而降低压缩失真。

#### 熵编码

用于去除统计域的冗余，将编码控制数据、量化变换系数、帧内预测数据、运动数据和滤波器控制数据等编码为二进制数进行存储和传输。

- 不同于传统的系数组概念，Lyu 等人 (2020) 提出一种基于扫描区域的系数编码方案，使用一组常数控制量化系数非零的位置，使用率失真优化方法选择最优扫描区域，码率和失真之间达到较好的平衡。同时，编码区域内非零系数时，采取从右下到左上的反 Z 扫描，采用分层编码和多套上下文提升压缩效率，上下文模型根据系数在扫描区域的相对位置、扫描区域面积和通道进行分组。

#### 环路滤波

滤波是去除压缩失真的关键技术，可以明显提高重建视频的主客观质量，提高视频压缩的效率。混合框架中的滤波技术与传统图像处理领域中基于先验模型的算法进行了大量交叉研究，性能取得了显著提升。

- VVC 中，Karczewicz 等人 (2017) 提出基于几何变换的自适应环路滤波技术，根据图像亮度分量的梯度信息进行聚类，对每种类别的像素点使用临近位置的点进行自适应滤波，从而最小化原始图像与重建图像之间的均方误差。
- Misra 等人 (2019) 探究视频不同分量之间的相关性，利用维纳滤波原理，提出跨分量的自适应环路滤波技术，利用结构信息保存更加完好的亮度分量，对色度分量进行滤波，大幅提升了色度分量的压缩性能。
- Zhang 等人 (2015) 提出一种非局部结构相似性滤波技术，通过统计局部多个像素发生失真得出的规律特性推断更优的全局优化策略，虽然复杂度较高但效果明显，全局优化处理能够带来明显的效率提升。
- Jian 等人 (2020) 提出一种基于像素纹理方向特性的滤波技术，通过纹理特性得到更精细的分类，在分类结果上进行不同的偏移值补偿，从而有效降低量化失真。

### 2. 2 混合框架中的深度学习技术

随着混合编码框架的发展完善，压缩效率不断提高，已成为支撑视频产业不断繁荣的基础。但传统视频编码遇到了性能提升的瓶颈，原因在于各个模块一般基于人工设计的统计先验模型，而实际应用中的视频通常内容多样，无法通过简单设计的模块高效表达。而深度学习技术可以从大量数据中学习复杂表征，拟合复杂的非线性函数，进行精准预测。因此，基于深度学习技术设计和优化视频编码模块具有巨大潜力。

#### 帧内预测

- Pfaff 等人 (2018) 采用全连接网络进行帧内预测，利用当前块的上下文信息为不同的预测模式训练不同的网络，并且根据上下文，额外训练一个网络预测不同模式的概率。
- Li 等人 (2018c) 提出一种全连接网络用于帧内预测，对于当前块，使用其左侧、上侧以及左上重建像素作为帧内预测上下文信息输入神经网络，预测出当前块，并将该网络预测作为一种新的模式，与 HEVC 已有的 35 种帧内模式进行率失真优化。
- Cui 等人 (2017) 提出一种帧内预测卷积神经网络，对 HEVC 编码器的预测块进行预测增强处理，并联合每一个预测块的左侧、上侧以及左上的区域作为帧内预测上下文信息联合输入神经网络。
- 与卷积网络不同，Hu 等人 (2019) 用当前编码块的空域重构像素作为自回归模型的上下文信息，采用循环神经网络的方法渐进式生成帧内预测信息，解决帧内预测中当前块左上与右下侧上下
  文信息不对称的问题。

#### 帧间预测

基于深度学习的帧间预测主要研究**如何高效利用视频帧间的时域相关性**以及**如何将时域与空域进行融合**，重点关注卷积神经网络对帧间预测运动补偿以及参考帧的扩展研究。

- Choi 和 Bajic(2020) 将基于神经网络的插帧技术用于视频编码的帧间预测，使用已经编码的帧通过神经网络预测出当前帧，并将该预测帧作为一个虚拟参考帧使用，从而高效地去除时间冗余。
- Huo 等人 (2018) 在时域运动补偿的基础上结合空域相关性，提出使用卷积神经网络对帧间预测结果进行增强，使用待预测块周围的重建信息作为上下文可以提高帧间预测质量。
- Yan 等人 (2017) 使用卷积神经网络进行分像素插值，对如何获得分像素训练数据进行研究，提出了先对高分辨率图像进行模糊，然后从模糊图像中采样像素的获取数据方法。并在后续工作 (Yan 等，2018) 中提出可以将分像素运动补偿视为视频帧间的回归问题，用分像素运动估计对齐当前帧和参考帧，将当前帧作为分像素，参考帧作为整像素。

#### 上下采样

当传输带宽受到限制时，通常的做法是降低编码前的视频分辨率，并提高解码后的视频分辨率。这种做法称为基于下采样和上采样的编码技术。

- Afonso 等人 (2018) 提出了一种联合空间和像素值进行下采样再使用卷积神经网络进行上采样的方法，在编码器端，通过传统方法实现空间下采样，用支持向量机决定是否对每帧执行下采样。在解码器端用卷积网络将解码出的低分辨率视频上采样到原始分辨率。
- Li 等人 (2018a) 和 Lin 等人 (2019) 分别提出了块自适应分辨率编码 (blockbased adaptive resolution coding，BARC) 框架用于 I 帧和 P、B 帧，将下采样后编码和直接编码进行率失真优化决策。
- Li 等人 (2019d) 提出一种全新的正则化损失，并验证了正则化损失在联合训练图像编码上下采样网络时非常有效。

#### 变换

- 针对帧间预测残差的分布特性，华为公司提出一种子块变换技术 (Zhao 等，2019b)，假设预测残差分布在残差块的局部区域，仅针对残差块的一个子块进行变换处理，从而提升压缩性能。
- Wang 等人 (2018a) 对帧间预测残差分布特性进行分析，提出基于位置的变换技术，考虑到编码单元中不同位置的帧间预测残差分布特性，对行变换和列变换分别使用两种变换核，这种基于位置的绑定方式能有效适应不同位置帧间残差的分布规律。 
- Zhang 等人 (2020b) 提出一种隐择变换技术，为当前残差块预设了两种变换核。通过率失真优化决策过程选择更优的变换核，选择结果并不在码流中传输，而是通过符号隐藏方式标识。

#### 熵编码

- Puri 等人 (2017) 提出使用卷积神经网络估计不同变换模式的概率分布，提高了变换模式编码的效率。
- 随后，Pfaff 等人 (2018) 进一步在 VVC 标准技术研究过程中提出使用全连接神经网络分析视频的纹理特征，估计帧内不同预测模式的概率分布，提高了帧内预测模式的编码效率。
- Song 等人 (2017) 提出通过分析视频纹理估计不同帧内预测模式的概率分布的方法提高帧内预测模式编码的效率。与 Pfaff 等人 (2018) 工作的不同点在于，Song 等人 (2017) 使用的是卷积神经网络而不是全连接神经网络。
- Ma 等人 (2018a) 使用神经网络预测变换系数的概率分布，特别是直流变换系数的概率分布，提高了变换系数编码的效率。使用卷积神经网络分析周围块的纹理特征，可以比传统视频编码更加准确地估计当前块变换系数的概率分布。

#### 滤波

基于神经网络的滤波方法可以显著提高编码效率。滤波方法根据是否影响后续编码分为**环内滤波技术**和**后处理技术**。

##### 环内滤波

- Park 和 Kim(2016) 提出了一个 3 层卷积神经网络用于压缩视频环路滤波，针对高低码率训练了两个神经网络模型并根据量化步长选择使用不同的模型。
- Kang 等人 (2017) 提出使用块划分信息提高针对 HEVC 编码视频的环路滤波效率。
- Meng 等人 (2018) 在 HEVC 的去块效应滤波和样本自适应偏移模块后使用长短时记忆神经网络解码视频帧进行滤波，同时联合使用了块划分信息。
- Zhang 等人 (2018b) 针对帧内模式编码帧、单向预测模式编码帧、双向预测模式编码帧以及不同的量化步长范围训练的神经网络进行环路滤波。
- Dai 等人 (2018) 在原始 VRCNN 的基础上增加了网络的深度，并应用于 HEVC 的环路滤波，明显提高了 HEVC 压缩视频的主客观质量。
- Jia 等人 (2019) 训练了多个神经网络用于 HEVC 的环路滤波，并训练了解码端分类网络用于模型的选择，避免了传输模型选择信息。

##### 后处理技术

- Kim 等人 (2020) 指出在实际应用中压缩视频的量化步长通常是未知的，为此设计了神经网络用于估计压缩视频的量化步长，并据此选择对应的神经网络模型进行滤波，明显提高了后处理效率。
- Huang 等人 (2020) 提出使用更大的图像块进行训练以提高后处理神经网络的性能，并使用块划分和帧内预测模式作为辅助信息，进一步增强后处理的效果。
- Dai 等人 (2017b) 提出一个 4 层的可变尺寸重建卷积神经网络 (variable-kernel restoration convolution neural net，VRCNN) 用于 HEVC 帧内编码的后处理。VRCNN 采用可变尺寸的滤波器设计，并采用残差连接以简化训练过程，很好地提高了 HEVC 编码的效率。
- Yang 等人 (2019b) 提出 HEVC 的后处理模型，并针对帧内模式和帧间模式使用不同的神经网络模型，进一步提高了后处理的性能。
- Jin 等人 (2018) 提出在均方误差损失函数之外使用判别器损失函数训练神经网络模型以提高主观质量。
- Li 等人 (2017) 提出传递边信息到解码端以提高后处理神经网络性能的方法。
- Yang 等人 (2018) 和 Wang 等人 (2018c) 提出联合使用相邻帧提高当前帧的后处理效果。
- He 等人 (2018) 提出使用块划分信息提高后处理神经网络的性能。
- Ma 等人 (2018b) 指出将预测信息和残差信息分别输入神经网络可以提高后处理的性能。
- Song 等人 (2018) 提出将量化步长与解码帧一起输入神经网络可以提高后处理的性能。

#### 编码优化

神经网络为解决复杂编码优化问题提供了新思路，已广泛用于编码过程中的模式决策问题。基于深度学习的编码工具又称为编码优化工具，**作用是编码加速和码率控制等，目标是提高编码效率。国际上对编码优化的研究主要集中于将深度网络模型与编码单元划分决策相结合**。

- Kim 等人 (2019) 、Paul 等人 (2020) 、Galpin 等人 (2019) 和 Su 等人 (2019a) 使用深度神经网络加快视频编码过程中的 CU(coding unit) 划分过程。Su 等人 ( 2019b) 使用神经网络快速选择变换核以加速 AV1 的编码过程。

- Kuang 等人 (2020) 和 Zhao 等人 (2019a) 在屏幕视频编码场景下，使用深度神经网络预测编码模式，大幅加快了屏幕编码速度。
- Chen 等人 (2020b) 使用深度神经网络提取局部方向纹理特征预测块划分和帧内预测模式，实现了 75% 的编码加速。
- Song 等人 (2017) 提出根据纹理信息和量化步长估计帧内预测模式，从而加速 HEVC 的帧内编码过程。
- Zhang 等人 (2019) 通过分析纹理特征加速块划分过程。
- Li 等人 (2020b) 提出使用剪枝的方法加快神经网络的运行，并使用加快后的神经网络加速
  HEVC 的编码单元 (coding unit，CU) 划分过程，实现了实时编码。
- Li 等人 (2019c) 提出使用强化学习的方法加速块划分。
- Tang 等人 (2019) 和 Jin 等人 (2017) 使用神经网络加速 VVC 的块划分过程。
- Ren 等人 (2019) 、Liu 等人 (2016) 和 Xu 等人 (2018) 使用神经网络加速 HEVC 的块划分。
- Huang 等人 (2019) 使用神经网络同时预测编码和预测单元的划分方式实现加速。

除上述关于编码单元模式决策的研究之外，深度学习编码研究还可应用于码率控制。 

- Li 等人 (2017) 依据 R-lambda 模型，提出使用 CNN 预测 HEVC 中编码树 (coding tree unit，CTU) 级别的码率控制参数，从而实现更加精确的码率控制。
- Lu 等人 (2020c) 依据 R-QP(rate-quantization parameter) 模型，提出使用深度神经网络估计编码树单元级量化步长，实现更精准的码率控制。
- Xing 等人 (2019) 提出使用深度神经网络实现码率控制。
- Hu 等人 (2018a) 提出使用强化学习的方法预测 HEVC 帧内编码的量化步长。

### 2. 3 端到端深度学习视频压缩

从 2017 年开始，国际上越来越多的研究人员开始致力于构建端到端的深度学习视频压缩方案。该框架所有模块都是基于深度神经网络实现，可以直接端到端优化率失真目标函数，更容易实现全局最优。

端到端视频压缩根据应用场景分为两类：随机切入场景和低延时场景。

#### 随机切入场景

主要基于帧内插的方式进行运动补偿。

- Wu 等人 (2018) 提出了第一个基于帧内插模型的视频压缩方案。该方案的关键帧 (I 帧） 通过端到端图像压缩模型进行压缩，剩下的帧 (B 帧）通过基于帧内插的模型以分层的方式进 行压缩，框架性能与 H.264 相当。
- Djelouah 等人 (2019) 提出一个更加高效的基于帧内插的视频压缩方案。首先使用光流网络提取前后向参考帧相对于当前帧的原始运动场，然后将原始运动场与对齐的参考帧 (warped frame) 和原始帧一起输入自编码器进行压缩，解码得到的运动场和融合系数 (blending coefficients) 通过内插方式得到预测帧。然后在隐空间 (latent space) 进行残差的提取和编码。该方案在峰值信噪比 (peak-signal-noise-ratiom，PSNR) 上的压缩性能与 H.265 相当。
- Park 和 Kim(2019) 使用基于帧内插的双向编码结构，并且在编码端和解码端同时引入运动估计网络，从而不再传输运动信息，在低分辨率视频上的压缩性能与 H.265 相当。
- Yang 等人 (2020a) 提出包含 3 个质量层的分层双向预测视频压缩方案，结合使用回归的质量增强网络，取得了与 H.265 相近的压缩性能。
- Yilmaz 和 Tekalp(2020) 提出一个端到端优化的分层双向预测视频压缩方案，在 PSNR 上的压缩性能接近 H.265。
- 里斯本大学 Pessoa 等人 (2020) 的方案将视频压缩问题看成一个“空-时”域自编码器的率失真优化问题，从而避免了显式的运动估计和补偿。
- Habibian 等人 (2019) 提出基于 3D 自编码器的模型，结合基于自回归先验的熵模型同时压缩一段连续的视频帧，整个系统针对率失真损失函数进行端到端优化，在多尺度结构相似度 ( multi-scale structural similarity，MS-SSIM) 上的压缩性能接近 H.265。

#### 低延时场景

主要基于帧外插的方式进行运动补偿。

- 2018 年，Rippel 等人 (2019) 提出首个面向低延时的端到端视频压缩方案。在解码器端使用隐状态 (latent state) 保存历史帧的信息，并使用生成网络生成运动场和残差的重建，设计了空域码率控制方法减小误差累积，在 MS-SSIM 上性能与 H.265 相当。
- Agustsson 等人 (2020) 使用自编码器基于前一个参考帧和当前原始帧提取原始的尺度空间流 (scale-space flow)，并进行压缩编码，解码得到的尺度空间流结合参考帧的高斯金字塔通过三线性插值 (trilinear interpolation) 操作得到当前帧的预测，剩下的残差使用另外一个自编码器进行压缩，该方案的压缩性能与 H.265 相当。
- Yang 等人 (2020b) 提出使用回归的自编码器和熵模型进行视频压缩，取得了与 H.265 相近的压缩性能。
- Golinski 等人 (2020) 提出一个基于自编码器的端到端视频压缩方案，在解码端使用反馈回归模块将提取的历史隐变量信息反馈回编码端，且显式地使用运动估计模块辅助运动信息的提取和压缩，该方案在 MS-SSIM 上的压缩性能超过了 H.265。

- Chen 等人 (2017) 首次提出基于神经网络的视频压缩方案，但压缩性能不及 H.264。后来提出另一个基于块的视频压缩方案 (Chen 等，2020a)，性能与 H.264 相当。
- Lu 等人 (2019) 提出了第一个端到端视频压缩方案。该方案可以看成是传统视频压缩方案的深度学习版本，在 PSNR 和 MS-SSIM 上的压缩性能分别与 H.264 和 H.265 相当。由于灵活性和高性能，该方案成为本领域基线方案，常在后续工作中引用。
- Liu 等人 (2019) 提出使用空域和时域的先验去除帧内纹理、运动场和残差的空域和时域冗余，构建了一个面向低延时场景的端到端视频压缩方案，并在后续工作 (Liu 等，2020a) 中结合了时域先验、空域自回归先验和空域超先验来压缩运动信息，在 MS-SSIM 指标压缩性能上超过了 Lu 等人 (2019) 的方法。
- 之后，Liu 等人 (2020b) 在上一个工作的基础上，提出使用多尺度的运动补偿模块，进一步提升了压缩性能。
- Lin 等人 (2020) 在 Lu 等人 (2019) 方案的基础上，提出了基于多参考帧预测的 4 个模块（运动场预测模块、运动场改善模块、运动补偿模块和残差改善模块）来提升帧间预测性能，相比 Lu 等人 (2019) 的方法，该方案在同样的码率下，PSNR 提高了近 1dB，达到了与 H.265 相当的水平。
- 最近，Lu 等人 (2020a，2020b) 在 Lu 等人 (2019) 的基础上扩展了两个工作，一是使用自适应量化层减小了可变码率编码的模型参数，同时使用运动场和残差改善模块来压缩运动场和残差，进一步提升了压缩性能；二是使用多帧的率失真损失函数来减小误差传播以及设计了在线编码端参数更新算法。这两个策略都有效提升了压缩性能。
- Hu 等人 (2020) 在 Lu 等人 (2019) 的方案上引入帧级和块级的分辨率自适应运动场编码模式，为每个视频帧自适应地在帧级和块级选择合适的分辨率编码。
- 国内的图鸭信息科技有限公司参与了 CVPR2020 Workshop 中的 P 帧编码竞赛，并提出一个端到端 P 帧压缩方案 (Wu 等，2020)，使用自编码器基于参考帧、当前帧和原始运动场同时提取、压缩并解码出重建的运动场和残差，然后使用空域偏移卷积 (spatially-displaced convolution) 生成当前帧的预测，最后与残差相加得到重建帧。考虑到低码率端的量化失真，使用了后处理模块提升压缩性能。

### 2. 4 标准进展

#### 国际

国际标准组织 ITU 和 ISO 制定了一系列基于混合编码框架的视频压缩标准。

2015 年，运动图像专家组和视频压缩专家组联合成立 JVET( joint video exploration /expert team) 工作组，开启了新一代视频压缩标准制定工作，参与单位包括高通、联发科、 三星、华为和腾讯等公司，高校和科研机构包括德国范霍夫海因里希赫兹研究所、北京大学、中国科技大学、浙江大学和亚琛大学等。 

2018 年 4 月，JVET 正式将下一代视频压缩标准命名为多用途视频编码 (versatile video coding，VVC) ，并于 2020 年 7 月正式发布标准草案，在 PSNR 指标下，压缩效率相比于上一代国际标准 H.265/HEVC 提升约 36.6%。VVC 标准针对混合编码框架的每一个模块都设计了全新的压缩技术，显著提升了压缩效率。

同时，MPEG 组织中的三星、华为、高通和 Divideon 等公司牵头制定了 MPEG-5 EVC(essential video coding) 标准，主要面向超高清、高动态范围和广色域视频内容。EVC 标准的制定方法尝试了不同于以前的标准化制定过程。

1. 选择专利期限超过 20 年的技术或有免版税声明的技术来定义该标准；
2. 在基本工具集上定义了一些其他工具，每个工具在压缩性能方面都有显著改进；
3. 每一个附加的工具都是隔离的，可以独立于其他工具进行开关控制；
4. 鼓励技术赞助者提交与专利许可或出版有关的自愿声明；
5. 定义了分析机制，以便允许不同模式可以包含不同的工具。

此外，为了适应互联网应用以及设计开源和专利政策友好的编解码器，多家科技巨头联合成立了开放媒体联盟 (alliance for open-media，AOM)，致力于推广和研发多媒体的视频编解码技术，为下一代多媒体体验创造新机遇。AOM 联盟于 2018 年初正式推出了 AV1 视频压缩标准。受益于联盟多数成员是与视频行业紧密相连的互联网公司、硬件设备厂商、内容供应商和主流浏览器厂商等，行业优势使得 AV1 基本做到了主流平台的全覆盖，形成从内容端、产品端到芯片端的完整生态链。

#### 国内

数字音视频编解码技术标准工作组 (audio video coding standard，AVS) 于 2017 年 12 月决定开展下一代视频编码标准 ( 即 AVS3 标准） 的制定，分为两阶段；

- 第 1 阶段从 2018 年 3 月到 2019 年 6 月，制定面向复杂度优先的应用，性能相较于 2014 年制定完成的上一代视频编码标准 AVS2 提升约 30%；
- 第 2 阶段从 2019 年 6 月到 2021 年 3 月，目标是编码效率超过 VVC 标准。

AVS3 标准采纳了包括块划分、帧内帧间预测、 变换量化、系数编码、环路滤波、针对屏幕内容的技术以及针对监控视频的技术等 40 余项技术。

## 3. 多视点/立体视频压缩

3DoF(degree of freedom) 是全景视频，3DoF+视频是在全景之外，还支持用户在 3 个空间维度上有限范围的变化，一个典型的例子就是坐在椅子上观看场景，允许头部在一定范围内运动。增加运动自由度后，更符合人感知场景的真实体验，同时带来双目立体视差。

从 H.264/AVC 时期就开始有多视点视频编码 (multiview video coding，MVC) 的研究，发展出了一些视间预测的技术，使得多个视点之间可以相互参考。3D-HEVC 是一个具有标志性意义的 3 维视频编码标准，采纳了许多可以有效提升编码效率的关键技术。

- 纹理图编码工具包括邻块视差矢量导出 (neighbor block derived vector, NBDV)、视间残差预测、视点合成预测 (view synthesis prediction, VSP) 等。 
- 深度图编码工具包括视差预测、深度建模模式 (depth modeling model, DMM ) 等。 

在 2018 年的 3DTV 会议上，Fachada 等人 (2018) 提出一种基于深度图的虚拟视点合成技术，可以运用于 6 自由度 (6DoF) 和 360 视频 (3DoF+) 的立体全景视频中，通过增加参考视图的数量克服了诸如遮挡、相机轴的切向曲面和低质量深度图中的瑕疵等问题。

国内，AVS 工作组针对分辨率提升、动态范围提升和全景视角等新兴需求和挑战建立了 AVS-3D 视频编码框架，具体在编码端编码稀疏的若干视点，在解码端通过视点合成技术生成任意数量的虚拟视点。针对立体视频各视点之间存在较强的内容相关性这一特点，以及深度视频通常呈现分片均匀、边缘锐利的特征，提出研究高效的视间预测编码技术去除视间冗余，并提出面向视点合成的深度编码技术，提升合成视点质量，从而进一步提升压缩效率。

## 4. 国内外研究进展比较

近年来国内外学术机构和工业界对视频处理与压缩技术关注度显著提高：

- 由于视频大数据的应用场景和用户需求正在发生巨变；
- 由于人工智能技术的飞速发展引领了新一轮技术革新。

#### 视频处理技术

- 视频处理领域的早期工作主要由国外学者和研究机构展开；
- 2016 年前后，国内学者逐渐发力，相关研究开始逐渐占据主流并贡献了大量的优越方法；
- 随着在深度学习在视频处理领域的广泛应用，国内部分团队已实现国际领先水平，同时针对不同前沿学科之间的交叉研究进行了深入探索。

#### 视频压缩技术

- 当前国际国内研究单位针对混合视频压缩框架的研究主要集中于局部模块优化以及性能提升。
- 现有视频压缩研究局面已发生根本性改变，由欧美日韩公司主导部分国内企业与高校辅助参与变为华为、高通、三星、腾讯、字节跳动和德国赫兹研究所等机构齐头并进的局面。
- 近年来国内外华人参与视频压缩技术研究的比例逐年上升，北京大学、中国科学技术大学、浙江大学和哈尔滨工业大学等高校对视频压缩新技术和新方向的探索同样越发深入，视频压缩技术研究的重心逐渐由欧美地区转向东亚地区。
- 对于混合框架中的深度学习编码，国内研究机构是该方向的先驱者，在各个编码模块均进展显著，并由此引发了工业界和学术研究机构重新审视深度学习在视频压缩领域的应用。 高通、Technicolor、联发科和夏普等公司持续跟进了深度学习视频压缩以及标准化进程。 
- 从 2017 年开始，端到端视频压缩研究工作逐年增加，国内研究结构主要针对压缩效率提升开展工作，较少涉及复杂度优化。而国外研究机构主要针对可变码率模型和模型压缩、模型定点化等方面进行探索。
- 新一代混合框架的视频压缩标准目前呈现“三足鼎立”的态势，主要有国际电信联盟和国际标准化组织推出的 H. 26x 系列标准、中国 AVS 工作组研制的 AVS 系列标准以及 AOM 联盟提出的 AV1 标准，这些标准技术框架具有一定相似性但技术细节各有千秋，**主要差异体现在对各自的应用场景设计了独特的压缩算法和优化方法**。
- 相较于 HEVC，VVC、EVC、AVS3(HPM) 和 AV1 等 4 个标准在客观性能上均有较大提升，AVS3 与 VVC 相比还存在性能差距，仍有继续探索和提升的空间。

### 5. 发展趋势与展望

#### 视频处理

深度学习工具全面颠覆了传统方法，开创了视频处理的新纪元。通过引入具有全场景自适应性和泛化特性的深度网络模型，视频的主客观质量得到了显著提升，在多种任务上突破了传统方法固有的系统性效率瓶颈和性能缺陷，取 得了飞跃式发展。

#### 视频压缩

新一代视频压缩标准的制定大幅提高了视频压缩效率，下一阶段将着重开展针对新一代标准的优化工作。

基于深度学习的视频编码将成为视频压缩效率提高的最大助力，面向下游机器视觉任务的视频编码将成为研究热点，联合面向视频信号保真度的压缩处理与视频语义层面的内容分析可以推动视频产业的发展迈向新高峰。更高 质量视觉效果和高效率视觉表达之间将不再是单独研究的个体，融合类脑视觉系统及编码机理的视频处理与压缩技术将是未来研究的重要领域之一。