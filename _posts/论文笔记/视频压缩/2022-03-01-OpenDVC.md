---
title: "OpenDVC"
subtitle: "OpenDVC: An Open Source Implementation of the DVC Video Compression Method"
layout: post
author: "L Hondong"
header-img: "img/post-bg-5.jpg"
mathjax: true
tags:
  - 笔记
---

# OpenDVC

OpenDVC: An Open Source Implementation of the DVC Video Compression Method

DVC 的 TensorFlow 开源实现！

[开源](https://github.com/RenYang-home/OpenDVC) 

[知乎原作者](https://zhuanlan.zhihu.com/p/151807493?from_voters_page=true)

Ren Yang, Luc Van Gool, Radu Timofte

## 摘要

DVC 是首个端到端优化的深度学习视频压缩方法，在深度视频压缩领域常被视为基准算法。OpenDVC 则是瑞士苏黎世联邦理工学院杨韧等人使用 Tensorflow 复现了 DVC 并开源了代码（不单是复现，还对 DVC 做了优化）。

本文算是个技术报告，主要讲了复现 DVC 的一些细节以及训练策略，跟原始 DVC 还是有些不同的，下面下简要总结下。

DVC 原文中仅有 PSNR 优化的模型，我们的 OpenDVC 开源代码中不仅复现 DVC 的 PSNR 优化模型，还提供 MS-SSIM 优化的 DVC 模型。我们希望开源模型能够为未来的研究者提供便利，并且希望 OpenDVC 的 MS-SSIM 模型能够为其他针对 MS-SSIM 优化的视频压缩方法在性能比较时提供更有说服力的基准。

#### OpenDVC 与 DVC 的不同点

1. 除复现 DVC 优化 PSNR 的模型外，还提供额外提供了优化 MS-SSIM 的 DVC 模型；
2. 运动压缩网络中上下采样 4 倍，原始 DVC 是 5 倍；
3. 残差压缩网络中用 5x5 的卷积替换了 3x3 的卷积，原因是残差中包含的信息比光流中要多。 

#### 训练策略总结

1. 先训练运动估计网络（原始 DVC 中直接采用光流网络的预训练参数）；
2. 然后把运动压缩加入训练；
3. 再训练运动补偿模块；
4. 所有网络联合训练。

注意：不同阶段用的 loss 不同！ 

## 1. Instruction

在这篇技术报告中，作者介绍了深度视频压缩（DVC）[9] 方法的开源 Tensorflow[1] 实现。DVC[9] 是第一个端到端的优化学习视频压缩方法，与 x265 的低延迟 P（LDP）very fast 设置相比，具有更好的 MS-SSIM 性能，并且 PSNR 性能与 x265（LDP very fast）相当。在撰写此报告时，已有几种视频压缩方法 [5，6，8，15，16] 优于 DVC[9]，但目前都还没有提供开源代码。作者希望 OpenDVC 代码能够为以后的开发提供一个有用的模型，并为以后对基于学习的视频压缩的研究提供便利。与原来只针对 PSNR 进行优化的 DVC 不同，本文不仅发布了以 OpenDVC（PSNR）表示的 PSNR 优化的复现，而且还发布了 MS-SSIM 优化的模型 OpenDVC（MS-SSIM）。

OpenDVC（MS-SSIM）模型为 MS-SSIM 优化的方法提供了更具说服力的基线，这只能与过去的 PSNR 优化的 DVC[9] 进行比较。OpenDVC 源代码和预训练的模型在 https://github.com/RenYang-home/OpenDVC。

## 2. Implementation

在本节中，将描述 OpenDVC 的实现，该实现遵循图 1 所示的 DVC[9] 框架。DVC 的高层架构是由手工制作的视频编码标准 [13，12] 驱动的，即采用运动补偿来减少时间冗余，并使用两个压缩网络分别压缩运动信息和残差信息。在下面的图 1 中，介绍了 OpenDVC 的每个模块的实现。 

<div align=center><img src="/images/OpenDVC-2022-02-14-21-34-24.png" alt="OpenDVC-2022-02-14-21-34-24" style="zoom:50%;" /></div>

### Motion estimation

DVC 利用金字塔网络 [11] 来估计当前帧和先前压缩帧之间的运动，如图 1 中的“Optical Flow Net”模块所示。金字塔结构的大接收野有利于 DVC 处理大的运动。在 OpenDVC 中，运动估计网络由 Tensorflow 在文件 motion.py 中基于金字塔网络 [11] 的 PyTorch 实现 [10]。按照 [11] 中描述的设置使用 5 级金字塔网络。每级有 5 个 kernal size 为 7×7 的卷积层，滤波器数目分别为 32，64，32，16 和 2。如图 1 所示，估计的运动 $v_t$是从金字塔网络输出的，在 OpenDVC_test_video.py 中表示为 flow_tensor.

### Motion compression

作者按照 [9] 来使用 [2] 的自动编码器对估计的运动进行压缩。编码器部分由 4 个有 x2 下采样的卷积层组成，前三层使用 GDN 的激活函数 [2]。在解码器部分，有 4 个有×2 上采样的对应卷积层，并且前三层使用逆 GDN[2] 的激活函数。

在运动压缩中，将解码器所有层（最后一层除外）的 filter 大小设置为 3×3，filter 数目设置为 128，最后一层 filter 数目为 2，以重建 2 通道运动向量。用于运动压缩的编码器和解码器实现为 CNN_img.py 中的 MV_analysis 和 MV_synthesis 函数。

与采用超先验熵模型（hyperprior entropy model）[3] 的 DVC[9] 不同，OpenDVC 使用了分解式熵模型（factorized entropy model ）[2]。因此，OpenDVC 对输入分辨率的要求较低，即 DVC 要求输入的高度和宽度为 32 的倍数，而 OpenDVC 仅需要高度和宽度为 16 的倍数。更重要的是，替换 hyperprior 模型为 factorized 模型不会导致性能明显下降（详见第 4 节）。

### Motion compensation

如 DVC[9] 中所述，首先通过压缩的运动信息 flow_hat 转换参考帧，然后运动补偿网络将参考帧 Y0_com、转换的参考帧 Y1_warp（In OpenDVC, we use the backward warping, which is implemented as tf.contrib.image.dense image warp in Tensorflow 1.12.）和压缩的运动信息 flow_hat 作为输入来生成运动补偿帧 Y1_MC。OpenDVC 中的运动补偿网络按照[附录](https://arxiv.org/abs/1812.00101.) [9] 中所示的体系结构。详细的网络如图 2 所示，其中所有层的 filter size 均为 3×3。除最后一层的 filter 数目为 3 之外，其余每层的 filter 数目均设置为 64。 $\uparrow$ 2 和 $\downarrow$ 2 表示步长为 2 的上采样和下采样， $\bigoplus$ 表示逐元素相加。 

<div align=center><img src="/images/OpenDVC-2022-02-14-21-38-05.png" alt="OpenDVC-2022-02-14-21-38-05" style="zoom:50%;" /></div>

### Residual compression

在运动补偿之后，可以将残差作为补偿后的参考帧与当前原始帧之间的差来获得。在 OpenDVC 中，使用与运动压缩相同的方法压缩残差。唯一的区别是，在自动编码器中使用大小为 5×5 的 filters 进行残差压缩，而不是在运动压缩中使用的 3×3。原因是残差比运动 [9] 包含更多的信息并且消耗更多的比特率，并且更大的 filter size 提高了自动编码器的表示能力。最后，将残差加到补偿后的参考帧上，得到重构后的压缩帧。

## 3. Training

在此技术报告中，使用与 DVC[9] 相同的符号，如图 1 所示。这些符号的定义及其在 OpenDVC 代码 OpenDVC_test_video.py 中的相应变量名称在表 1 中列出。 

<div align=center><img src="/images/OpenDVC-2022-02-14-21-38-34.png" alt="OpenDVC-2022-02-14-21-38-34" style="zoom:50%;" /></div>

OpenDVC 网络在 Vimeo-90k[14] 数据集上以渐进方式进行训练。首先，使用下面损失函数训练运动估计网络：

$$\mathcal L_{ME}=D(x_t,W(\hat{x}_{t-1},v_t)) \tag1$$

其中 $W$ 是 backward warping 操作。在运动估计网络收敛之后，进一步将运动压缩网络加入训练，其损失包括被压缩运动 warped 的参考帧的失真和用于压缩 $\hat{m}_t$ 的比特率，即：

$$\mathcal L_{M}= \lambda\cdot D(x_t,W(\hat{x}_{t-1},\hat{v}_t))+R(\hat{m}_t) \tag2$$

其中 $\lambda$ 来平衡速率和失真，R 代表由熵模型估计的比特率 [2]。然后，运动补偿网络的训练通过下面损失：

$$ \mathcal L_{MC}=\lambda\cdot D(x_t,\bar{x}_t)+R(\hat{m}_t) \tag3$$

 当 $L_{MC}$会合时，整个网络将以端到端的方式联合训练，而损失是 

$$\mathcal L=\lambda \cdot D(x_t,\hat{x}_t)+R(\hat{m}_t)+R(\hat{y}_t) \tag4$$

对于所有损失函数 (1)(2)(3）和 (4)，学习率最初设置为 $10^{−4}$。当通过最后的损失（4）训练整个网络时，学习率在收敛后降低 10 倍，直到$\ 10^{−6}$。

在 OpenDVC 中，首先按照 DVC[9] 训练 PSNR 优化模型，其中失真 D 为均方误差（MSE），$\lambda$ = 256，512，1024 和 2048。

然后，仅使用最终损失函数 (4)（D=1-MS-SSIM）对 MS-SSIM 模型进行微调。分别从预先训练的 $\lambda$ = 256，512，1024 和 2048 的 PSNR 模型中微调了 $\lambda$ = 8，16，32 和 64 的 MS-SSIM 模型。

注意，使用 BPG[4] 压缩 OpenDVC 中 PSNR 模型的 I 帧，并使用学习的图像压缩方法 [7] 压缩 MS-SSIM 模型的 I 帧。具体而言，将 QP = 37，32，27 和 22 的 BPG 用于 $\lambda$ =256，512，1024 和 2048 的 PSNR 模型。$\lambda$ =8，16，32 和 64 的 MS-SSIM 模型使用 [7]，质量等级分布为 2，3，5 和 7。

## 4. Performance

OpenDVC 源代码的视频压缩性能与 DVC 原文中结果相似，如下图所示。我们的 OpenDVC (PSNR) 模型在 PSNR 和 MS-SSIM 性能上均与 DVC 基本相当，我们的 OpenDVC (MS-SSIM) 模型在 MS-SSIM 性能上明显优于原 DVC 方法。

与 DVC 论文中的结果相比，OpenDVC 的率-失真性能如图 3 所示 [9]。可以看出，OpenDVC (PSNR) 模型在 PSNR 和 MS-SSIM 性能上均与 DVC 基本相当，OpenDVC (MS-SSIM) 模型在 MS-SSIM 性能上明显优于原 DVC 方法。 注意，图 3 直接使用 DVC 的结果，[9] 中报告了 x265（very fast）和 x264（very fast）。 

<div align=center><img src="/images/OpenDVC-2022-02-14-21-43-50.png" alt="OpenDVC-2022-02-14-21-43-50" style="zoom:50%;" /></div>

## 5. Our latest works

作者的课题组专注于深度学习视频压缩方法的研究，在该领域也有一些最新的研究成果：

- Hierarchical Learned Video Compression (HLVC) [2] 发表于 CVPR 2020，
  - [论文链接](https://arxiv.org/abs/2003.01966)
  - [项目主页](https://github.com/RenYang-home/HLVC)。

- Recurrent Learned Video Compression (RLVC) [3]，RLVC 方法的性能也于上面图 3 中展示。
  - [论文链接](https://arxiv.org/abs/2006.13560)
