# Learning Scalable $\ell_{\infty}$-constrained Near-lossless Image Compression via Joint Lossy Image and Residual Compression

[代码地址](https://github.com/BYchao100/Scalable-Near-lossless-Image-Compression)

2021 CVPR 中含金量相对高的图像压缩论文，工作量很大，把后处理内容做的很全。个人更愿意把这部分工作归于图像压缩的后处理工作，可以很好的与其他的 idea 耦合。

## 一、简介

我们提出了一种联合有损图像和残差用于学习的压缩框架**近无损图像压缩**。通过有损图像压缩获得原始图像的有损重建，并均匀量化相应的残差以满足给定的误差界限。假设误差界为零，即无损图像压缩，根据变分自动编码器制定了压缩有损图像和原始残差的联合优化问题，并通过端到端训练来解决联合优化问题。为了实现误差范围大于零的可扩展压缩，通过学习量化误差的概率模型，而不是训练多个网络。并且纠正了由训练和推理之间的**上下文不匹配**引起的导出概率模型的偏差。最后，量化的残差根据偏差校正概率模型进行编码，并与压缩有损图像的比特流连接。

实质重点在于，如何在更低码率的情况下，传输后续增强所需要的高频信息，以及如何控制这部分高频信息的量化达到可伸缩编码的效果。

## 二、内容

### 2.1 现有方法缺陷

1. 目前还没有很好的后处理方案能够奏效，实际上在端到端的压缩领域，解码端够复杂的情况下，是不需要**常规的**后处理网络，因为解码器本身承担一定的后处理工作。
2. 通过控制后处理的误差容许范围达到整体压缩性能的伸缩性，达到可伸缩编码的效果。
3. 校正了由于训练过程和测试过程中，上下文概率不匹配的问题，进一步提高了性能。

### 2.2 整体框架流程

整体框架图如下：  

<div align=center><img src="/assets/ScalableNear-lossless-2022-05-01-15-59-28.png" alt="ScalableNear-lossless-2022-05-01-15-59-28" style="zoom:50%;" /></div>

其中，淡紫色部分是一般性的端到端图像压缩的框架，本文作者 follow 了谷歌的工作，先通过一般的有损压缩框架得到重构数据，这部分数据相对源数据是有损的，而如何更好地传输这部分有损数据，是本文的关键。橙色模块是概率建模，而黄色模块则是条件触发模块，当进行无损失压缩时，则直接通过橙色模块进行概率建模，当进行有损压缩时，则会触发黄色模块（偏置矫正模块），完成对于需要传输的残差信息的建模工作。总的来说流程如下：

1. 利用现有的有损压缩器得到重构数据。
2. 用原始数据和重构数据做减法，求得因为压缩损失的残差信息，记为 $r$，并且根据是否进行无损工作以及量化粗细控制参数得到量化后的残差信息 $\hat{r}$。
3. 利用重构信息和量化后的残差信息对 $\hat{r}$ 进行概率建模，用于熵编码。

### 2.3 量化工作

$$
\hat{r}_{i, c}=\operatorname{sgn}\left(r_{i, c}\right)(2 \tau+1)\left\lfloor\left(\left|r_{i, c}\right|+\tau\right) /(2 \tau+1)\right\rfloor
$$

上述公式表示对 $r$ 进行量化工作，假设当 $\tau$ 等于 0 的时候， $\hat{r}$ 等于 $r$ 取整，直观上好像是有信息损失的，但是实际上， $r=x-\tilde{x}$ 本身是在整数域上进行的，所以 $\tau=0$ 时没有任何信息损失，并且这个公式比较直观地代表了 $bin= 2*\tau+1$ 地量化区间，通过 $\tau$ 来控制残差数据 $r$ 由于量化操作损失的信息量。并且由于这部分量化工作不可微分，在训练过程中采用添加等 bin 的均匀噪声的形式。

### 2.4 可伸缩编码方案

在端到端领域，可伸缩编码和可变速率应该是一个概念的，即使用单个模型就能达到多个码率效果的作用，而不像原来的一个模型只能对应一个码率点，如果需要多个码率的话，需要多个训练多个网络。区别于码率控制的概念：码率控制在于编码器决定为每帧视频分配多少比特的工具，**通过某种方式确定编码参数使得编码器能将编码对象压缩到指定大小的码率**，前者只要要求速率可变，后者要求编码到指定速率。

本文采用的伸缩编码方案如下：

1. 采用紫色模块的编解码网络作为获得重构图像的初始解，换个角度思考，可以将这部分网络是为传统编码的预测器作用，这里进行预测编码。
2. 预测后得到残差系数，对残差系数进行量化，通过 $\tau$ 控制量化步长，控制残差系数的内容损失，步长越大，内容损失越大，步长越小，内容损失越小，这部分和传统编码的思想及其相似。
3. 对量化后的残差系数进行熵编码，需要进行熵率建模。由于对同一信息进行不同量化步长的处理，导致残差系数的信息损失差距比较大，一般的神经网络不能很好地适应这种信息损失差距，所以会导致泛化性能较差，因为为了弥补这一性能上地损失，作者使用了 Conditional Conv 取代一般地 Conv 进行卷积运算。

伸缩编码通过量化的形式实现的：

<div align=center><img src="/assets/ScalableNear-lossless-2022-05-01-16-04-34.png" alt="ScalableNear-lossless-2022-05-01-16-04-34" style="zoom:50%;" /></div>
 
当 $\tau$ 等于 1 时，量化的 bin=3，具体量化如上图所示，所以此时如果计算每个量化后的残差系数的概率情况计算如下：

$$
\hat{p}_{\boldsymbol{\theta}}\left(\hat{r}_{i, c} \mid r_{i,<c}, u_{i}, C_{r_{i}}\right)=\sum_{v=\hat{r}_{i, c}-\tau}^{\hat{r}_{i, c}+\tau} p_{\boldsymbol{\theta}}\left(v \mid r_{i,<c}, u_{i}, C_{r_{i}}\right)
$$

### 2.5 建模工作

#### 2.5.1 有损模式建模

<div align=center><img src="/assets/ScalableNear-lossless-2022-05-01-15-59-28.png" alt="ScalableNear-lossless-2022-05-01-15-59-28" style="zoom:50%;" /></div>

着重介绍这部分的建模工作，左边是无损压缩下的建模，右边是有损压缩下的建模，先行介绍左侧的无损下的建模原理。  

$\hat{r}$ 如上所介绍的为量化后的残差系数，也是需要写进码流进行传输的。$\mu$ 则是通过原始有损框架中的重构数据学习得到的，控制通道为 64，宽度和长度与原图一致。 $C_r$ 是 $\hat{r}$ 经过 5x5 的 Mask 卷积得到的，平采样且通道转换为 64。

得到输入后，接下来对上述两个输入进行 concat，具体操作如下：

<div align=center><img src="/assets/ScalableNear-lossless-2022-05-01-16-06-16.png" alt="ScalableNear-lossless-2022-05-01-16-06-16" style="zoom:50%;" /></div>

输出建模四个建模参数，对其进行离散混合逻辑斯蒂建模，其中（a）中的每个估计参数估计组件如（b）所示，之所以采用 1x1 卷积核而不是 3x3 卷积核，是由于在这里要使用类似于 Minnen2018[1] 的自回归技术，保证每个解码点的信息来源仅限于已解码的信息，具体技术不做赘述，可参考 Joint Autoregressive and Hierarchical Priors for Learned Image Compression，中间层卷积核的输出通道为 128，最后一层输出 3xK 个通道，其中 K 设置为 5，这里解释一下为什么是 3xK 个通道：因为原始的残差信息是（3，W , H）的数据，本文对其中的每一个点都建立数量为 5 的离散混合逻辑斯蒂模型，所以需要 3xk 个通道输出，并且每个混合模型有 3 个系数（$\pi,\mu,\sigma$），实际上一般的建模工作到这里就可以了，已经完成了建模的功能了，但是本文做了进一步的优化，即还有一个 $\beta$ 系数，接下来介绍 $\beta$ 系数的作用：  

$$
\begin{array}{r}
\tilde{\mu}_{i, 1}^{k}=\mu_{i, 1}^{k}, \quad \tilde{\mu}_{i, 2}^{k}=\mu_{i, 2}^{k}+\beta_{i, 1} \cdot r_{i, 1} \\
\tilde{\mu}_{i, 3}^{k}=\mu_{i, 3}^{k}+\beta_{i, 2} \cdot r_{i, 1}+\beta_{i, 3} \cdot r_{i, 2}
\end{array}
$$

简单来说这里包含了一系列的自回归操作，即利用已经解码的点对正在解码的点进行一个微调，而 $\beta$ 就是这个微调系数，其中如图，k 是表示第几个混合逻辑斯蒂的参数，i 表示二维空域的位置，1，2，3 则表示通道维度的下标，即这里利用已经解码的通道来对正在解码的通道进行 refine，具体的 refine 规则则如上图，对原始的得到的 $\mu$ 参数进行加权和， $\beta$ 是微调系数，又可以是权重系数。经过 $\beta$ 调整后的建模参数则是最终的熵模型的参数。

其建模公式如下：  

$$
p_{\boldsymbol{\theta}}\left(r_{i, c} \mid r_{i,<c}, u_{i}, C_{r_{i}}\right) \sim \sum_{k=1}^{K} \pi_{i, c}^{k} \operatorname{logistic}\left(\tilde{\mu}_{i, c}^{k}, \sigma_{i, c}^{k}\right)
$$

建模后的概率计算如下：

$$
\sum_{k=1}^{K} \pi_{i, c}^{k}\left[S\left(\frac{r_{i, c}^{+}-\tilde{\mu}_{i, c}^{k}}{\sigma_{i, c}^{k}}\right)-S\left(\frac{r_{i, c}^{-}-\tilde{\mu}_{i, c}^{k}}{\sigma_{i, c}^{k}}\right)\right]
$$

$$
r_{i, c}^{+}=r_{i, c}+0.5 \\
r_{i, c}^{-}=r_{i, c}-0.5 
$$

其中 S 表示标准的 sigmoid 的 cdf 函数，最终得到每个残差系数的概率情况，此时完成了在无损压缩的情况下，残差系数的建模工作，实际上这部分工作对于有损压缩也能 work，并且我的理解是 work 的性能也不会差，但是进一步作者认为这部分工作在有损压缩条件下还有提升空间。

#### 2.5.1 有损模式建模

有损模式下的建模工作问题其难度在于后续的可伸缩编码方式对于残差系数的处理，这部分会导致输入的高频分量的残差系数的内容复杂度幅度很大，从而导致 entropy model 的性能变低，这里借鉴了 [Lee](https://ieeexplore.ieee.org/document/9008820) 的思路，具体采用了一种 Conditional Conv 的方式，而具体的模型结构整体与上述的无损模式下的网络结构一直：  

<div align=center><img src="/assets/ScalableNear-lossless-2022-05-01-16-11-34.png" alt="ScalableNear-lossless-2022-05-01-16-11-34" style="zoom:50%;" /></div> 

即通过 $\tau$ 编码成独热向量，然后经过全连接层生成权重与原始的图像进行作用，因为 $\tau$ 一定程度上能够揭示输入内容的复杂性，所以先验地给卷积核输入这一信息能够增加泛化能力。

### 2.6 损失函数

$$
\mathcal{L}(\boldsymbol{\theta}, \boldsymbol{\phi})=R_{\hat{\mathbf{y}}, \hat{\mathbf{z}}}+R_{\mathbf{r}}+\lambda \cdot D_{l s}
$$

整体上和原来的形式差不多，遵循 $l=R+\lambda * D$, 速率项包含了基线框架中的 $\mathbb{R}_{y}$ 和 $\mathbb{R}_{z}$ 外, 还增加了残差系数的码流 $\mathbb{R}_{r}$​。在失真项上表达式如下：

$$
D_{l s}(\mathbf{x}, \tilde{\mathbf{x}})=\mathbb{E}_{p(\mathbf{x})} \mathbb{E}_{i, c}\left(x_{i, c}-\tilde{x}_{i, c}\right)^{2}
$$

感觉表达的就是 MSE 的意思，关于这里的失真公式，并不是很能理解好。需要注意的时，这里的失真对比并不是原始图像和最终的重构图像的失真，而是原图和紫色模块的输出图像的失真。并且根据作者实验情况， $\lambda$ 参数选择为 0.03. 理论上，在做无损压缩得时候，可以将失真项权重设置为 0，这个很合理，但是并不适用于这个近无损框架下的情况，因此还是设置了失真项的权重。

## 三、实验结果

对比几种无损压缩方案，本文提出的算法：

<div align=center><img src="/assets/ScalableNear-lossless-2022-05-01-16-13-50.png" alt="ScalableNear-lossless-2022-05-01-16-13-50" style="zoom:50%;" /></div>

对比近无损算法：  

<div align=center><img src="/assets/ScalableNear-lossless-2022-05-01-16-14-16.png" alt="ScalableNear-lossless-2022-05-01-16-14-16" style="zoom:50%;" /></div>

对比高比特率下的方案：  

<div align=center><img src="/assets/ScalableNear-lossless-2022-05-01-16-15-00.png" alt="ScalableNear-lossless-2022-05-01-16-15-00" style="zoom:100%;" /></div>

不太清楚在近无损情况下的性能是否能和有损压缩进行同级别对比，在 0.8bpsp 的时候跟 Minner 低了接近 2db。